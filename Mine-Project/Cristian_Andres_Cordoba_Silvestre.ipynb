{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "from tensorflow import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) uint8\n",
      "(60000,) uint8\n",
      "(10000, 28, 28) uint8\n",
      "(10000,) uint8\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(Y_train.shape, Y_train.dtype)\n",
    "print(X_test.shape, X_test.dtype)\n",
    "print(Y_test.shape, Y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(imagen, title):\n",
    "    plt.figure()\n",
    "    plt.suptitle(title)\n",
    "    plt.imshow(imagen, cmap = \"Reds\")\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(3):\n",
    "    title = \"Mostrando imagen X_train[\" + str(i) + \"]\"\n",
    "    title = title + \" -- Y_train[\" + str(i) + \"] = \" + str(Y_train[i])\n",
    "    show_image(X_train[i], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_X(X, title, xscale, yscale):\n",
    "    plt.title(title)\n",
    "    plt.plot(X)\n",
    "    plt.xscale(xscale)\n",
    "    plt.yscale(yscale)\n",
    "    plt.show()\n",
    "\n",
    "# Example values for fila and columna\n",
    "fila = 1\n",
    "columna = 1\n",
    "\n",
    "features_fila_col = X_train[:, fila, columna]\n",
    "print(len(np.unique(features_fila_col)))\n",
    "\n",
    "title = \"Valores en (\" + str(fila) + \", \" + str(columna) + \")\"\n",
    "xscale = \"linear\"  # Define the xscale\n",
    "yscale = \"linear\"  # Define the yscale\n",
    "\n",
    "plot_X(features_fila_col, title, xscale, yscale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1A: DecisionStump y ADABoost Binario sin mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def balance_training_dataset(digit, X_train, y_train):\n",
    "    # Find indices of the target digit and calculate how many there are\n",
    "    target_indices = np.where(y_train == digit)[0]\n",
    "    num_target_samples = len(target_indices)\n",
    "    #print(f\"Total elements for target digit {digit}: {num_target_samples}\")\n",
    "\n",
    "    # Determine how many samples each non-target digit should have\n",
    "    num_samples_per_other_digit = num_target_samples // 9\n",
    "    #print(f\"Each non-target digit will have {num_samples_per_other_digit} samples.\")\n",
    "\n",
    "    # Initialize lists to collect balanced dataset samples\n",
    "    X_train_balanced = []\n",
    "    y_train_balanced = []\n",
    "\n",
    "    # Add target digit samples to the balanced dataset\n",
    "    X_train_balanced.extend(X_train[target_indices])\n",
    "    y_train_balanced.extend(y_train[target_indices])\n",
    "\n",
    "    # Collect samples for each non-target digit class to balance the dataset\n",
    "    for i in range(10):  # There are 10 digit classes (0-9)\n",
    "        if i == digit:\n",
    "            continue  # Skip the target digit\n",
    "        indices = np.where(y_train == i)[0]\n",
    "        if len(indices) >= num_samples_per_other_digit:\n",
    "            balanced_indices = np.random.choice(indices, num_samples_per_other_digit, replace=False)\n",
    "        else:\n",
    "            balanced_indices = np.random.choice(indices, num_samples_per_other_digit, replace=True)\n",
    "        X_train_balanced.extend(X_train[balanced_indices])\n",
    "        y_train_balanced.extend([i] * num_samples_per_other_digit)\n",
    "        #print(f\"Collected {len(balanced_indices)} samples for digit {i}.\")\n",
    "\n",
    "    # Convert lists to numpy arrays for training\n",
    "    X_train_balanced = np.array(X_train_balanced)\n",
    "    y_train_balanced = np.array(y_train_balanced)\n",
    "\n",
    "    # Convert labels to binary (1 for the specified digit, -1 for all others)\n",
    "    y_train_binary_balanced = np.where(y_train_balanced == digit, 1, -1)\n",
    "\n",
    "    # Shuffle the balanced training set\n",
    "    shuffle_indices = np.random.permutation(len(X_train_balanced))\n",
    "    X_train_balanced = X_train_balanced[shuffle_indices]\n",
    "    y_train_binary_balanced = y_train_binary_balanced[shuffle_indices]\n",
    "\n",
    "    return X_train_balanced, y_train_binary_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, img_shape): # Inicializamos la clase\n",
    "        self.feature_index = (np.random.randint(0, img_shape[0]), np.random.randint(0, img_shape[1])) # Elegimos un ndice de caracterstica aleatorio en 2D\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.img_shape = img_shape # Inicializamos la forma de la imagen\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index[0], self.feature_index[1]] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, verbose=False): # Creamos la funcin fit\n",
    "        n_samples, img_rows, img_cols = X.shape # Obtenemos el nmero de muestras y el tamao de la imagen\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        for t in range(self.T): # Para cada iteracin\n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): # Para cada clasificador dbil\n",
    "                clf = DecisionStump((img_rows, img_cols)) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index[0], clf.feature_index[1]]), max(X[:, clf.feature_index[0], clf.feature_index[1]])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {t + 1}/{self.T}: error = {min_error}, alpha = {best_clf.alpha}') # Mostramos el error y el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_on_mnist\n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train) # Convertimos las etiquetas a binarias\n",
    "    \n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "\n",
    "    adaboost = AdaBoost(T=T, A=A) # Creamos el clasificador AdaBoost\n",
    "    adaboost.fit(X_train_balanced, Y_train_binary_balanced, verboseParam) # Ajustamos el clasificador AdaBoost\n",
    "    y_pred = adaboost.predict(X_test) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy:.4f}\") # Mostramos la precisin\n",
    "\n",
    "    return y_test_binary, np.sign(y_pred), accuracy # Devolvemos las etiquetas verdaderas, las predicciones, y la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    all_true_labels = [] # Inicializamos las etiquetas verdaderas\n",
    "    all_pred_labels = [] # Inicializamos las predicciones\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        y_test_binary, y_pred, accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        all_true_labels.extend(y_test_binary) # Guardamos las etiquetas verdaderas\n",
    "        all_pred_labels.extend(y_pred) # Guardamos las predicciones\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "\n",
    "        if verboseParam: # Si verboseParam es True\n",
    "            print(f\"Confusion Matrix for digit {digit}:\") # Mostramos la matriz de confusin para cada dgito\n",
    "            print_confusion_matrix(y_test_binary, y_pred) # Mostramos la matriz de confusin para cada dgito\n",
    "\n",
    "    if verboseParam: # Si verboseParam es True\n",
    "        print(\"Overall Confusion Matrix:\") # Mostramos la matriz de confusin general\n",
    "        print_confusion_matrix(all_true_labels, all_pred_labels) # Mostramos la matriz de confusin general\n",
    "\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "\n",
    "\n",
    "def print_confusion_matrix(true_labels, pred_labels): # Creamos la funcin para mostrar la matriz de confusin\n",
    "    num_classes = 2 # Nmero de clases (1 y -1)\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int) # Inicializamos la matriz de confusin\n",
    "\n",
    "    for t, p in zip(true_labels, pred_labels): # Para cada par de etiquetas verdaderas y predicciones\n",
    "        matrix[int((t + 1) / 2), int((p + 1) / 2)] += 1 # Actualizamos la matriz de confusin\n",
    "\n",
    "    print(matrix) # Imprimimos la matriz de confusin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3233278955954325, alpha = 0.3692599271489911\n",
      "Classifier 2/50: error = 0.33087128418231926, alpha = 0.3521235057931913\n",
      "Classifier 3/50: error = 0.3123386271005803, alpha = 0.3946042917592571\n",
      "Classifier 4/50: error = 0.3796237013928949, alpha = 0.24557286223375022\n",
      "Classifier 5/50: error = 0.3946566529606794, alpha = 0.21388982942292314\n",
      "Classifier 6/50: error = 0.3937908807599272, alpha = 0.21570249940252553\n",
      "Classifier 7/50: error = 0.3961251003681726, alpha = 0.21081849259739288\n",
      "Classifier 8/50: error = 0.3888819080704038, alpha = 0.22600724878952066\n",
      "Classifier 9/50: error = 0.41876775998958615, alpha = 0.1639169536959356\n",
      "Classifier 10/50: error = 0.3881972361557875, alpha = 0.2274481990522173\n",
      "Classifier 11/50: error = 0.370799939510158, alpha = 0.26439329832635833\n",
      "Classifier 12/50: error = 0.4128962390149723, alpha = 0.17600262243608708\n",
      "Classifier 13/50: error = 0.4012828270515625, alpha = 0.20006141905112365\n",
      "Classifier 14/50: error = 0.4237266778118641, alpha = 0.1537467231026621\n",
      "Classifier 15/50: error = 0.41678359138398036, alpha = 0.1679955970668164\n",
      "Classifier 16/50: error = 0.4310195881750065, alpha = 0.1388462352947471\n",
      "Classifier 17/50: error = 0.4494783661360805, alpha = 0.10138926494893134\n",
      "Classifier 18/50: error = 0.44359450646021914, alpha = 0.11329323095674926\n",
      "Classifier 19/50: error = 0.38469612135853926, alpha = 0.2348312649152796\n",
      "Classifier 20/50: error = 0.41756830782867016, alpha = 0.16638188468172985\n",
      "Classifier 21/50: error = 0.46592316544900325, alpha = 0.068259486994384\n",
      "Classifier 22/50: error = 0.4187181412156804, alpha = 0.16401888328921405\n",
      "Classifier 23/50: error = 0.44728707414158203, alpha = 0.10581906638490816\n",
      "Classifier 24/50: error = 0.3987441310803892, alpha = 0.2053503233938377\n",
      "Classifier 25/50: error = 0.43643212150382604, alpha = 0.12782746400542394\n",
      "Classifier 26/50: error = 0.4312224784231461, alpha = 0.13843260523206877\n",
      "Classifier 27/50: error = 0.42198802003902636, alpha = 0.15730883493488013\n",
      "Classifier 28/50: error = 0.46769835702442497, alpha = 0.0646933874325796\n",
      "Classifier 29/50: error = 0.4315746088815924, alpha = 0.13771483247006922\n",
      "Classifier 30/50: error = 0.45030405959100694, alpha = 0.09972112356318012\n",
      "Classifier 31/50: error = 0.4238755817982336, alpha = 0.15344183405771783\n",
      "Classifier 32/50: error = 0.4198831070799075, alpha = 0.16162663331096902\n",
      "Classifier 33/50: error = 0.4396038819375201, alpha = 0.1213849171014392\n",
      "Classifier 34/50: error = 0.44971650881146996, alpha = 0.10090809004665326\n",
      "Classifier 35/50: error = 0.43090442048764466, alpha = 0.13908104735768076\n",
      "Classifier 36/50: error = 0.43078620693760533, alpha = 0.13932208539178598\n",
      "Classifier 37/50: error = 0.478042114954963, alpha = 0.043944034704622006\n",
      "Classifier 38/50: error = 0.4426794888138121, alpha = 0.11514724588895982\n",
      "Classifier 39/50: error = 0.4576289676256575, alpha = 0.08494579366831162\n",
      "Classifier 40/50: error = 0.463880575451427, alpha = 0.0723649023059858\n",
      "Classifier 41/50: error = 0.47185186013020514, alpha = 0.056355865800425176\n",
      "Classifier 42/50: error = 0.4655933124062046, alpha = 0.0689223017005431\n",
      "Classifier 43/50: error = 0.4541459827723533, alpha = 0.09196643896562494\n",
      "Classifier 44/50: error = 0.4474452916538141, alpha = 0.10549908556228929\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_adaboost_on_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdigit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverboseParam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ejecutamos AdaBoost\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 76\u001b[0m, in \u001b[0;36mrun_adaboost_on_mnist\u001b[1;34m(digit, T, A, verboseParam)\u001b[0m\n\u001b[0;32m     73\u001b[0m y_test_binary \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_test \u001b[38;5;241m==\u001b[39m digit, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Convertimos las etiquetas a binarias\u001b[39;00m\n\u001b[0;32m     75\u001b[0m adaboost \u001b[38;5;241m=\u001b[39m AdaBoost(T\u001b[38;5;241m=\u001b[39mT, A\u001b[38;5;241m=\u001b[39mA) \u001b[38;5;66;03m# Creamos el clasificador AdaBoost\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43madaboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_binary_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverboseParam\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Ajustamos el clasificador AdaBoost\u001b[39;00m\n\u001b[0;32m     77\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m adaboost\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m# Realizamos las predicciones\u001b[39;00m\n\u001b[0;32m     78\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y_test_binary \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39msign(y_pred)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test_binary) \u001b[38;5;66;03m# Calculamos la precisin\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 40\u001b[0m, in \u001b[0;36mAdaBoost.fit\u001b[1;34m(self, X, Y, verbose)\u001b[0m\n\u001b[0;32m     38\u001b[0m clf\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;28mmin\u001b[39m(X[:, clf\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m0\u001b[39m], clf\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m1\u001b[39m]]), \u001b[38;5;28mmax\u001b[39m(X[:, clf\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m0\u001b[39m], clf\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m1\u001b[39m]])) \u001b[38;5;66;03m# Elegimos un umbral aleatorio\u001b[39;00m\n\u001b[0;32m     39\u001b[0m clf\u001b[38;5;241m.\u001b[39mpolarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Elegimos una polaridad\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Realizamos las predicciones\u001b[39;00m\n\u001b[0;32m     41\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(w[Y \u001b[38;5;241m!=\u001b[39m predictions]) \u001b[38;5;66;03m# Calculamos el error\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m: \u001b[38;5;66;03m# Si el error es mayor que 0.5\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m, in \u001b[0;36mDecisionStump.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     13\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Obtenemos el nmero de muestras\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_column \u001b[38;5;241m=\u001b[39m X[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;66;03m# Obtenemos la columna de la caracterstica\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Inicializamos las predicciones\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolarity \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \u001b[38;5;66;03m# Si la polaridad es 1\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     predictions[X_column \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Crislt\\anaconda3\\envs\\SIPrac2Python310\\lib\\site-packages\\numpy\\core\\numeric.py:192\u001b[0m, in \u001b[0;36mones\u001b[1;34m(shape, dtype, order, like)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ones_with_like(like, shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    191\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order)\n\u001b[1;32m--> 192\u001b[0m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_on_mnist(digit=3, T=50, A=20, verboseParam=True)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Classifier 1/50: error = 0.24913465597298445, alpha = 0.5516163979297461\n",
      "Classifier 2/50: error = 0.26173488239526776, alpha = 0.5184854527997216\n",
      "Classifier 3/50: error = 0.20405596280566596, alpha = 0.6805672971370658\n",
      "Classifier 4/50: error = 0.24518690827531978, alpha = 0.5622246735424318\n",
      "Classifier 5/50: error = 0.2676456349514324, alpha = 0.5033003269638706\n",
      "Classifier 6/50: error = 0.361613650793689, alpha = 0.2841836420353433\n",
      "Classifier 7/50: error = 0.368896030379911, alpha = 0.268477887304487\n",
      "Classifier 8/50: error = 0.36219122066490966, alpha = 0.28293310657497056\n",
      "Classifier 9/50: error = 0.2717139222892868, alpha = 0.4929720890706858\n",
      "Classifier 10/50: error = 0.3809115058625324, alpha = 0.24284057267988773\n",
      "Classifier 11/50: error = 0.3373197656391109, alpha = 0.33763061632395003\n",
      "Classifier 12/50: error = 0.40198771139856443, alpha = 0.19859489183358817\n",
      "Classifier 13/50: error = 0.36875781448507894, alpha = 0.26877475088222463\n",
      "Classifier 14/50: error = 0.3894196349710566, alpha = 0.22487620376095516\n",
      "Classifier 15/50: error = 0.43037861713815173, alpha = 0.14015328661503848\n",
      "Classifier 16/50: error = 0.38723540683452673, alpha = 0.22947402169618952\n",
      "Classifier 17/50: error = 0.4018861159514155, alpha = 0.1988062112297625\n",
      "Classifier 18/50: error = 0.39307785237477044, alpha = 0.21719641761442413\n",
      "Classifier 19/50: error = 0.4244172324947175, alpha = 0.15233301295070986\n",
      "Classifier 20/50: error = 0.4164588103069442, alpha = 0.1686637390024152\n",
      "Classifier 21/50: error = 0.413636211526989, alpha = 0.17447676246096333\n",
      "Classifier 22/50: error = 0.3888160570003385, alpha = 0.22614579777038044\n",
      "Classifier 23/50: error = 0.42807353442037577, alpha = 0.14485771808014475\n",
      "Classifier 24/50: error = 0.4177213976005232, alpha = 0.166067167008167\n",
      "Classifier 25/50: error = 0.4099375724529275, alpha = 0.18211172741717938\n",
      "Classifier 26/50: error = 0.4058327563939518, alpha = 0.19060984493832936\n",
      "Classifier 27/50: error = 0.4240042863300877, alpha = 0.1531783273053716\n",
      "Classifier 28/50: error = 0.38137938471729566, alpha = 0.24184877260183987\n",
      "Classifier 29/50: error = 0.44750167730702783, alpha = 0.10538505580749687\n",
      "Classifier 30/50: error = 0.41489879057547663, alpha = 0.17187511370237019\n",
      "Classifier 31/50: error = 0.4335431427175743, alpha = 0.1337048038994582\n",
      "Classifier 32/50: error = 0.4194409108095055, alpha = 0.16253446315235917\n",
      "Classifier 33/50: error = 0.4336274470002476, alpha = 0.13353316703251975\n",
      "Classifier 34/50: error = 0.4394817328433124, alpha = 0.12163283999535847\n",
      "Classifier 35/50: error = 0.4533404514634106, alpha = 0.0935914096809058\n",
      "Classifier 36/50: error = 0.4402745757076185, alpha = 0.1200238908459449\n",
      "Classifier 37/50: error = 0.4597120027974413, alpha = 0.08075105648615603\n",
      "Classifier 38/50: error = 0.45064435733596164, alpha = 0.09903378441288219\n",
      "Classifier 39/50: error = 0.45035391086767157, alpha = 0.09962042725413947\n",
      "Classifier 40/50: error = 0.432579342899446, alpha = 0.13566758345610966\n",
      "Classifier 41/50: error = 0.453866309181175, alpha = 0.09253055960436676\n",
      "Classifier 42/50: error = 0.4456025704384602, alpha = 0.10922717715149752\n",
      "Classifier 43/50: error = 0.4487297936648955, alpha = 0.10290208539354798\n",
      "Classifier 44/50: error = 0.44356764102491175, alpha = 0.11334765477211738\n",
      "Classifier 45/50: error = 0.43770500883284846, alpha = 0.12524070989404223\n",
      "Classifier 46/50: error = 0.4545705322652596, alpha = 0.0911102052095186\n",
      "Classifier 47/50: error = 0.4562643220099869, alpha = 0.08769547379059692\n",
      "Classifier 48/50: error = 0.4089967193039096, alpha = 0.18405721682990653\n",
      "Classifier 49/50: error = 0.4547776247004478, alpha = 0.0906925884602417\n",
      "Classifier 50/50: error = 0.46422429841732504, alpha = 0.07167388453848042\n",
      "Accuracy for digit 0: 0.9636\n",
      "Confusion Matrix for digit 0:\n",
      "[[8674  346]\n",
      " [  18  962]]\n",
      "Running AdaBoost for digit: 1\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2661128828895647, alpha = 0.5072173173092297\n",
      "Classifier 2/50: error = 0.304843301710223, alpha = 0.4121697027159028\n",
      "Classifier 3/50: error = 0.27914804636870877, alpha = 0.47434575399009443\n",
      "Classifier 4/50: error = 0.29276629012521194, alpha = 0.4409932652799557\n",
      "Classifier 5/50: error = 0.3091209088799841, alpha = 0.40211617018503654\n",
      "Classifier 6/50: error = 0.31073234969520136, alpha = 0.3983488638291405\n",
      "Classifier 7/50: error = 0.350761766539305, alpha = 0.3078462308751507\n",
      "Classifier 8/50: error = 0.29806921836804545, alpha = 0.42825453068559116\n",
      "Classifier 9/50: error = 0.2902886590838845, alpha = 0.44699126049976834\n",
      "Classifier 10/50: error = 0.3884453201788844, alpha = 0.22692597815085278\n",
      "Classifier 11/50: error = 0.3081693206893111, alpha = 0.4043459340013006\n",
      "Classifier 12/50: error = 0.3703343244518218, alpha = 0.26539141371434444\n",
      "Classifier 13/50: error = 0.329255222566863, alpha = 0.3557777502264625\n",
      "Classifier 14/50: error = 0.4282518180564685, alpha = 0.14449363525904413\n",
      "Classifier 15/50: error = 0.3510517882687336, alpha = 0.30720957942889077\n",
      "Classifier 16/50: error = 0.3658361805400481, alpha = 0.27506083610579607\n",
      "Classifier 17/50: error = 0.36480937766012633, alpha = 0.2772750911067399\n",
      "Classifier 18/50: error = 0.411419856209037, alpha = 0.17904942974611923\n",
      "Classifier 19/50: error = 0.36134728259734644, alpha = 0.2847606653579488\n",
      "Classifier 20/50: error = 0.3710590964768722, alpha = 0.2638379797477159\n",
      "Classifier 21/50: error = 0.4059657161388357, alpha = 0.19033416076433024\n",
      "Classifier 22/50: error = 0.43260179968810075, alpha = 0.1356218384111778\n",
      "Classifier 23/50: error = 0.40251342506033905, alpha = 0.1975016821311896\n",
      "Classifier 24/50: error = 0.4020688483064494, alpha = 0.19842613894750047\n",
      "Classifier 25/50: error = 0.41735866565144686, alpha = 0.1668129142116338\n",
      "Classifier 26/50: error = 0.37936530338823604, alpha = 0.24612152823608624\n",
      "Classifier 27/50: error = 0.41561275867216746, alpha = 0.17040494466165174\n",
      "Classifier 28/50: error = 0.39143784169273854, alpha = 0.22063616198474975\n",
      "Classifier 29/50: error = 0.43115708567744837, alpha = 0.1385659155387821\n",
      "Classifier 30/50: error = 0.40315508171479775, alpha = 0.19616800256296676\n",
      "Classifier 31/50: error = 0.43769636988787725, alpha = 0.1252582602500365\n",
      "Classifier 32/50: error = 0.41335626530862946, alpha = 0.17505393047850862\n",
      "Classifier 33/50: error = 0.4191857761477449, alpha = 0.1630583758810841\n",
      "Classifier 34/50: error = 0.41208817383778296, alpha = 0.17766982022701613\n",
      "Classifier 35/50: error = 0.4243331913072662, alpha = 0.15250503047358066\n",
      "Classifier 36/50: error = 0.4177835211948643, alpha = 0.16593946436041054\n",
      "Classifier 37/50: error = 0.41872526912608543, alpha = 0.16400424053893098\n",
      "Classifier 38/50: error = 0.4422889539317092, alpha = 0.11593878960702254\n",
      "Classifier 39/50: error = 0.4361058292647009, alpha = 0.1284908258661925\n",
      "Classifier 40/50: error = 0.4055457789767254, alpha = 0.1912049733022114\n",
      "Classifier 41/50: error = 0.4291082597656962, alpha = 0.14274517698823921\n",
      "Classifier 42/50: error = 0.42280466042991294, alpha = 0.15563523794455184\n",
      "Classifier 43/50: error = 0.43834940677321105, alpha = 0.12393180577118687\n",
      "Classifier 44/50: error = 0.4403844470419336, alpha = 0.11980097332514829\n",
      "Classifier 45/50: error = 0.4495898387878501, alpha = 0.1011640250746799\n",
      "Classifier 46/50: error = 0.436428139289049, alpha = 0.12783555929133303\n",
      "Classifier 47/50: error = 0.4094503693739387, alpha = 0.1831189913351555\n",
      "Classifier 48/50: error = 0.45105647072449306, alpha = 0.09820151560053765\n",
      "Classifier 49/50: error = 0.4269194316054238, alpha = 0.14721550206423814\n",
      "Classifier 50/50: error = 0.43478165666862134, alpha = 0.13118406921653958\n",
      "Accuracy for digit 1: 0.9614\n",
      "Confusion Matrix for digit 1:\n",
      "[[8497  368]\n",
      " [  18 1117]]\n",
      "Running AdaBoost for digit: 2\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Classifier 1/50: error = 0.31671701913393757, alpha = 0.38445020148252074\n",
      "Classifier 2/50: error = 0.3339056469520649, alpha = 0.34528643634376954\n",
      "Classifier 3/50: error = 0.380033811711996, alpha = 0.24470235723964742\n",
      "Classifier 4/50: error = 0.29128885873371757, alpha = 0.44456630483702214\n",
      "Classifier 5/50: error = 0.38457661956386113, alpha = 0.23508370729323153\n",
      "Classifier 6/50: error = 0.33713912895384734, alpha = 0.3380347148555171\n",
      "Classifier 7/50: error = 0.3792039678959762, alpha = 0.2464641714870625\n",
      "Classifier 8/50: error = 0.35764705562095545, alpha = 0.2927956440775066\n",
      "Classifier 9/50: error = 0.38787330912496504, alpha = 0.22813025439922596\n",
      "Classifier 10/50: error = 0.3947782382471756, alpha = 0.21363537702323102\n",
      "Classifier 11/50: error = 0.36281817553574613, alpha = 0.2815766192541462\n",
      "Classifier 12/50: error = 0.3687820553580765, alpha = 0.26872268238085256\n",
      "Classifier 13/50: error = 0.3759787479560812, alpha = 0.2533259025236723\n",
      "Classifier 14/50: error = 0.40548647249128633, alpha = 0.19132797864774032\n",
      "Classifier 15/50: error = 0.4022481379169578, alpha = 0.1980532823562951\n",
      "Classifier 16/50: error = 0.3865035049110851, alpha = 0.23101680737103458\n",
      "Classifier 17/50: error = 0.3862191960370569, alpha = 0.2316163969191589\n",
      "Classifier 18/50: error = 0.43216653187463666, alpha = 0.13650859067243043\n",
      "Classifier 19/50: error = 0.4120558625615871, alpha = 0.17773650502823257\n",
      "Classifier 20/50: error = 0.4319306873710541, alpha = 0.13698915551303104\n",
      "Classifier 21/50: error = 0.4109643822126352, alpha = 0.17999005195864753\n",
      "Classifier 22/50: error = 0.40566184270779926, alpha = 0.19096426642920133\n",
      "Classifier 23/50: error = 0.43255170482571204, alpha = 0.13572388368413973\n",
      "Classifier 24/50: error = 0.4506760834165569, alpha = 0.09896970830058051\n",
      "Classifier 25/50: error = 0.43645892648507845, alpha = 0.1277729736595249\n",
      "Classifier 26/50: error = 0.4318498985468988, alpha = 0.13715378803817715\n",
      "Classifier 27/50: error = 0.43225090910386443, alpha = 0.13633667596913568\n",
      "Classifier 28/50: error = 0.44215658544088965, alpha = 0.1162071094200122\n",
      "Classifier 29/50: error = 0.4301632728669036, alpha = 0.14059251757643157\n",
      "Classifier 30/50: error = 0.45149206805279085, alpha = 0.09732196800997334\n",
      "Classifier 31/50: error = 0.43578679879822046, alpha = 0.12913953308012605\n",
      "Classifier 32/50: error = 0.44207942665200195, alpha = 0.1163635231454825\n",
      "Classifier 33/50: error = 0.4520267058123766, alpha = 0.09624264537247636\n",
      "Classifier 34/50: error = 0.4468251886325153, alpha = 0.10675331243794561\n",
      "Classifier 35/50: error = 0.468368143285325, alpha = 0.06334831674040008\n",
      "Classifier 36/50: error = 0.45303996970854454, alpha = 0.09419768700311028\n",
      "Classifier 37/50: error = 0.4615482826358661, alpha = 0.07705558081555149\n",
      "Classifier 38/50: error = 0.4532591775910896, alpha = 0.09375538791118154\n",
      "Classifier 39/50: error = 0.4449296081962034, alpha = 0.1105894259565697\n",
      "Classifier 40/50: error = 0.4698586344913813, alpha = 0.060355913273891185\n",
      "Classifier 41/50: error = 0.45241373788644956, alpha = 0.09546144757574442\n",
      "Classifier 42/50: error = 0.4480676522563565, alpha = 0.10424062488688761\n",
      "Classifier 43/50: error = 0.4570657394060005, alpha = 0.08608050753578239\n",
      "Classifier 44/50: error = 0.4611661221287024, alpha = 0.07782449463894255\n",
      "Classifier 45/50: error = 0.449596410357641, alpha = 0.10115074698439368\n",
      "Classifier 46/50: error = 0.45640992873531316, alpha = 0.08740202254129559\n",
      "Classifier 47/50: error = 0.45735098382870043, alpha = 0.08550580929878834\n",
      "Classifier 48/50: error = 0.45996453134351556, alpha = 0.08024271966544656\n",
      "Classifier 49/50: error = 0.47102614933108294, alpha = 0.05801269388027431\n",
      "Classifier 50/50: error = 0.4570233775890432, alpha = 0.08616586113733674\n",
      "Accuracy for digit 2: 0.9080\n",
      "Confusion Matrix for digit 2:\n",
      "[[8143  825]\n",
      " [  95  937]]\n",
      "Running AdaBoost for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3380913539967376, alpha = 0.33590570611729764\n",
      "Classifier 2/50: error = 0.3366851063609716, alpha = 0.33905086947356855\n",
      "Classifier 3/50: error = 0.3229623355144947, alpha = 0.3700955987444104\n",
      "Classifier 4/50: error = 0.32220818486801284, alpha = 0.3718211549058446\n",
      "Classifier 5/50: error = 0.4019797842110039, alpha = 0.1986113798213467\n",
      "Classifier 6/50: error = 0.3882852759254997, alpha = 0.2272628599586444\n",
      "Classifier 7/50: error = 0.3735877922025428, alpha = 0.2584278017481026\n",
      "Classifier 8/50: error = 0.3586677925674031, alpha = 0.2905754978467489\n",
      "Classifier 9/50: error = 0.4006569918883907, alpha = 0.20136419464137575\n",
      "Classifier 10/50: error = 0.4246197004628349, alpha = 0.15191863336065908\n",
      "Classifier 11/50: error = 0.40446109463821545, alpha = 0.19345558416743186\n",
      "Classifier 12/50: error = 0.4097647590349762, alpha = 0.18246896713768637\n",
      "Classifier 13/50: error = 0.4209479950374728, alpha = 0.15944149661872722\n",
      "Classifier 14/50: error = 0.3884948328236524, alpha = 0.226821767802912\n",
      "Classifier 15/50: error = 0.3906412754322013, alpha = 0.2223087240864288\n",
      "Classifier 16/50: error = 0.4006345409644899, alpha = 0.20141094232399204\n",
      "Classifier 17/50: error = 0.4408588152582842, alpha = 0.11883866522863099\n",
      "Classifier 18/50: error = 0.405432905792633, alpha = 0.19143908423447561\n",
      "Classifier 19/50: error = 0.42275531931619204, alpha = 0.15573633142544865\n",
      "Classifier 20/50: error = 0.4508287028514911, alpha = 0.09866147920314727\n",
      "Classifier 21/50: error = 0.42870999850200575, alpha = 0.14355813401481304\n",
      "Classifier 22/50: error = 0.43051489114070174, alpha = 0.13987536056791383\n",
      "Classifier 23/50: error = 0.427579763226836, alpha = 0.14586627481430087\n",
      "Classifier 24/50: error = 0.4239015292735616, alpha = 0.15338870808215874\n",
      "Classifier 25/50: error = 0.4198356607473641, alpha = 0.16172402805421818\n",
      "Classifier 26/50: error = 0.4278854455166018, alpha = 0.1452418661252783\n",
      "Classifier 27/50: error = 0.4182198313030582, alpha = 0.16504272640297013\n",
      "Classifier 28/50: error = 0.4407428190071139, alpha = 0.11907395607989964\n",
      "Classifier 29/50: error = 0.4350364632899324, alpha = 0.13066567049197683\n",
      "Classifier 30/50: error = 0.4044494108607908, alpha = 0.19347983733128263\n",
      "Classifier 31/50: error = 0.4516170499172226, alpha = 0.09706963542106335\n",
      "Classifier 32/50: error = 0.4250508611364791, alpha = 0.15103637382343416\n",
      "Classifier 33/50: error = 0.4499961335295574, alpha = 0.10034315876837252\n",
      "Classifier 34/50: error = 0.4645652969215306, alpha = 0.07098841152308602\n",
      "Classifier 35/50: error = 0.4424508415589449, alpha = 0.11561065511078993\n",
      "Classifier 36/50: error = 0.44667551886135703, alpha = 0.10705608607118032\n",
      "Classifier 37/50: error = 0.43054062805706017, alpha = 0.13982287344136532\n",
      "Classifier 38/50: error = 0.4368738310881847, alpha = 0.1269296333522172\n",
      "Classifier 39/50: error = 0.4593534047926928, alpha = 0.08147298143037796\n",
      "Classifier 40/50: error = 0.46545509363534454, alpha = 0.06920005979551756\n",
      "Classifier 41/50: error = 0.44574151549824936, alpha = 0.10894596703314735\n",
      "Classifier 42/50: error = 0.445122025745445, alpha = 0.11019988179271539\n",
      "Classifier 43/50: error = 0.4490591024258648, alpha = 0.10223651455506462\n",
      "Classifier 44/50: error = 0.44808409105887576, alpha = 0.10420738884911905\n",
      "Classifier 45/50: error = 0.45406609804306497, alpha = 0.09212756592269906\n",
      "Classifier 46/50: error = 0.45928261987215646, alpha = 0.0816154947234163\n",
      "Classifier 47/50: error = 0.4550241906422843, alpha = 0.09019541167890086\n",
      "Classifier 48/50: error = 0.45477996264895115, alpha = 0.09068787399975059\n",
      "Classifier 49/50: error = 0.46831059790233853, alpha = 0.06346387083005635\n",
      "Classifier 50/50: error = 0.4622103187714336, alpha = 0.07572376684274457\n",
      "Accuracy for digit 3: 0.8927\n",
      "Confusion Matrix for digit 3:\n",
      "[[8002  988]\n",
      " [  85  925]]\n",
      "Running AdaBoost for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.32174955062911925, alpha = 0.37287158204545046\n",
      "Classifier 2/50: error = 0.33395398745768523, alpha = 0.34517776726105465\n",
      "Classifier 3/50: error = 0.27102529082594395, alpha = 0.4947134490389044\n",
      "Classifier 4/50: error = 0.32713336901772916, alpha = 0.36058959743819735\n",
      "Classifier 5/50: error = 0.3052300888264907, alpha = 0.4112574228571354\n",
      "Classifier 6/50: error = 0.38512331057668825, alpha = 0.23392908619198632\n",
      "Classifier 7/50: error = 0.34512169619452454, alpha = 0.3202761625470315\n",
      "Classifier 8/50: error = 0.3792655202078139, alpha = 0.24633344040565855\n",
      "Classifier 9/50: error = 0.376829492674454, alpha = 0.25151367884485826\n",
      "Classifier 10/50: error = 0.3838392278403042, alpha = 0.23664206786472877\n",
      "Classifier 11/50: error = 0.42276091837860497, alpha = 0.15572485952095333\n",
      "Classifier 12/50: error = 0.349229803266259, alpha = 0.3112132058776094\n",
      "Classifier 13/50: error = 0.40828396674233214, alpha = 0.1855319584742846\n",
      "Classifier 14/50: error = 0.39802340830024907, alpha = 0.20685387093417257\n",
      "Classifier 15/50: error = 0.4152848107918887, alpha = 0.17108014832460633\n",
      "Classifier 16/50: error = 0.41888261285388045, alpha = 0.16368102962068537\n",
      "Classifier 17/50: error = 0.4459444676915885, alpha = 0.10853524406912728\n",
      "Classifier 18/50: error = 0.4023538001928184, alpha = 0.1978335690616271\n",
      "Classifier 19/50: error = 0.40729546750648915, alpha = 0.187578564718587\n",
      "Classifier 20/50: error = 0.40978219309509534, alpha = 0.18243292537875322\n",
      "Classifier 21/50: error = 0.3976270031026478, alpha = 0.20768123090174612\n",
      "Classifier 22/50: error = 0.4145501745377157, alpha = 0.17259323425352238\n",
      "Classifier 23/50: error = 0.4326547964057182, alpha = 0.1355138849968877\n",
      "Classifier 24/50: error = 0.41656122789828554, alpha = 0.16845302873032506\n",
      "Classifier 25/50: error = 0.41938595390034206, alpha = 0.16264730832495936\n",
      "Classifier 26/50: error = 0.4331813079101974, alpha = 0.1344415600860451\n",
      "Classifier 27/50: error = 0.43317622566259895, alpha = 0.13445190942360496\n",
      "Classifier 28/50: error = 0.4176260879510898, alpha = 0.1662630980874829\n",
      "Classifier 29/50: error = 0.41704914192868037, alpha = 0.1674494150247227\n",
      "Classifier 30/50: error = 0.45842288057734826, alpha = 0.08334669812622046\n",
      "Classifier 31/50: error = 0.44695105829418585, alpha = 0.10649870019969636\n",
      "Classifier 32/50: error = 0.4409386085186662, alpha = 0.11867681739402662\n",
      "Classifier 33/50: error = 0.44832500736967784, alpha = 0.10372032954794531\n",
      "Classifier 34/50: error = 0.45088168198361467, alpha = 0.0985544873063172\n",
      "Classifier 35/50: error = 0.4662477211726034, alpha = 0.06760737529591206\n",
      "Classifier 36/50: error = 0.4190828629283504, alpha = 0.16326973073660916\n",
      "Classifier 37/50: error = 0.4422547330711786, alpha = 0.11600815599313843\n",
      "Classifier 38/50: error = 0.45489096852781374, alpha = 0.09046403586956071\n",
      "Classifier 39/50: error = 0.4615355056153394, alpha = 0.07708128693667758\n",
      "Classifier 40/50: error = 0.44613269075771256, alpha = 0.10815436166549455\n",
      "Classifier 41/50: error = 0.43982180839693796, alpha = 0.12094263419376532\n",
      "Classifier 42/50: error = 0.4603903146336175, alpha = 0.0793857167624596\n",
      "Classifier 43/50: error = 0.4273050793666524, alpha = 0.14642746022166403\n",
      "Classifier 44/50: error = 0.42311518522028835, alpha = 0.15499908564442305\n",
      "Classifier 45/50: error = 0.4535382461300873, alpha = 0.09319235995180941\n",
      "Classifier 46/50: error = 0.44932935126050166, alpha = 0.10169037806392858\n",
      "Classifier 47/50: error = 0.44399560805303706, alpha = 0.11248076137416732\n",
      "Classifier 48/50: error = 0.44234569568055315, alpha = 0.11582377536582131\n",
      "Classifier 49/50: error = 0.4579093463138023, alpha = 0.08438100721664393\n",
      "Classifier 50/50: error = 0.4535300432894408, alpha = 0.0932089085518206\n",
      "Accuracy for digit 4: 0.9040\n",
      "Confusion Matrix for digit 4:\n",
      "[[8116  902]\n",
      " [  58  924]]\n",
      "Running AdaBoost for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3538149275763448, alpha = 0.301155989738253\n",
      "Classifier 2/50: error = 0.3415293886858613, alpha = 0.32824307867497377\n",
      "Classifier 3/50: error = 0.3911614645359793, alpha = 0.22121633717146905\n",
      "Classifier 4/50: error = 0.3665772842168362, alpha = 0.27346431325684833\n",
      "Classifier 5/50: error = 0.42561575411696695, alpha = 0.14988081830927633\n",
      "Classifier 6/50: error = 0.39777460555397637, alpha = 0.2073731286830634\n",
      "Classifier 7/50: error = 0.4111360484958636, alpha = 0.17963549838581983\n",
      "Classifier 8/50: error = 0.3995923876213271, alpha = 0.20358189092209408\n",
      "Classifier 9/50: error = 0.38561415716481573, alpha = 0.23289293125475558\n",
      "Classifier 10/50: error = 0.39487119396623294, alpha = 0.21344085866019075\n",
      "Classifier 11/50: error = 0.37263254624259845, alpha = 0.2604698080731825\n",
      "Classifier 12/50: error = 0.41817896868478266, alpha = 0.1651266992011107\n",
      "Classifier 13/50: error = 0.3988577007395194, alpha = 0.20511348185647893\n",
      "Classifier 14/50: error = 0.41683857650067935, alpha = 0.16788249601722077\n",
      "Classifier 15/50: error = 0.4281273977440619, alpha = 0.14474771680745255\n",
      "Classifier 16/50: error = 0.43649137006194305, alpha = 0.12770702193768074\n",
      "Classifier 17/50: error = 0.4129219817890746, alpha = 0.1759495259789523\n",
      "Classifier 18/50: error = 0.42658502705855417, alpha = 0.14789897925092646\n",
      "Classifier 19/50: error = 0.4221478056563575, alpha = 0.15698130684750294\n",
      "Classifier 20/50: error = 0.4050489224670766, alpha = 0.19223566171317555\n",
      "Classifier 21/50: error = 0.41098874218917447, alpha = 0.1799397369862297\n",
      "Classifier 22/50: error = 0.44233767970544535, alpha = 0.11584002338090224\n",
      "Classifier 23/50: error = 0.40042158477566814, alpha = 0.20185440642655375\n",
      "Classifier 24/50: error = 0.46248455630034213, alpha = 0.07517216370571411\n",
      "Classifier 25/50: error = 0.4718302902644692, alpha = 0.05639914279354219\n",
      "Classifier 26/50: error = 0.4289834490051613, alpha = 0.1429999286910853\n",
      "Classifier 27/50: error = 0.4357776384590959, alpha = 0.12915816103948521\n",
      "Classifier 28/50: error = 0.43114236410459306, alpha = 0.13859592775945642\n",
      "Classifier 29/50: error = 0.439917789493392, alpha = 0.12074785499355314\n",
      "Classifier 30/50: error = 0.4462817375727366, alpha = 0.10785277729809384\n",
      "Classifier 31/50: error = 0.45417485516331857, alpha = 0.0919082047208581\n",
      "Classifier 32/50: error = 0.4362700580218135, alpha = 0.1281569298796724\n",
      "Classifier 33/50: error = 0.4481962010827545, alpha = 0.1039807304598283\n",
      "Classifier 34/50: error = 0.451437679441583, alpha = 0.09743177995019214\n",
      "Classifier 35/50: error = 0.45694959511061595, alpha = 0.08631452631328819\n",
      "Classifier 36/50: error = 0.4509949781231123, alpha = 0.09832569214308699\n",
      "Classifier 37/50: error = 0.4662465384736696, alpha = 0.06760975152230213\n",
      "Classifier 38/50: error = 0.4623518858068054, alpha = 0.07543901227143412\n",
      "Classifier 39/50: error = 0.4427989145051283, alpha = 0.11490522029199778\n",
      "Classifier 40/50: error = 0.4562582532536995, alpha = 0.08770770489928043\n",
      "Classifier 41/50: error = 0.46699053475319435, alpha = 0.06611509657468781\n",
      "Classifier 42/50: error = 0.4421500710408647, alpha = 0.11622031497575955\n",
      "Classifier 43/50: error = 0.4511180693706811, alpha = 0.09807712794043051\n",
      "Classifier 44/50: error = 0.4437694175905065, alpha = 0.11293891350750082\n",
      "Classifier 45/50: error = 0.4640242776107799, alpha = 0.07207599633579631\n",
      "Classifier 46/50: error = 0.4533227009846902, alpha = 0.09362722263243667\n",
      "Classifier 47/50: error = 0.4659021825115666, alpha = 0.06830164882831775\n",
      "Classifier 48/50: error = 0.4434683674551583, alpha = 0.11354876829446096\n",
      "Classifier 49/50: error = 0.4563246233186294, alpha = 0.08757394259065936\n",
      "Classifier 50/50: error = 0.460506166535285, alpha = 0.07915255397302992\n",
      "Accuracy for digit 5: 0.8777\n",
      "Confusion Matrix for digit 5:\n",
      "[[7987 1121]\n",
      " [ 102  790]]\n",
      "Running AdaBoost for digit: 6\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Classifier 1/50: error = 0.26633420674499175, alpha = 0.506650832828978\n",
      "Classifier 2/50: error = 0.3313488001307041, alpha = 0.3510454756282179\n",
      "Classifier 3/50: error = 0.34762616688966896, alpha = 0.3147450459256844\n",
      "Classifier 4/50: error = 0.3128671630361113, alpha = 0.393374465085694\n",
      "Classifier 5/50: error = 0.33972172305802995, alpha = 0.33226727842626136\n",
      "Classifier 6/50: error = 0.3242392924040578, alpha = 0.367178615186731\n",
      "Classifier 7/50: error = 0.3822580671656768, alpha = 0.2399874183626999\n",
      "Classifier 8/50: error = 0.3516461857403775, alpha = 0.30590552046388303\n",
      "Classifier 9/50: error = 0.3462036819601496, alpha = 0.3178842922331946\n",
      "Classifier 10/50: error = 0.395913741070834, alpha = 0.21126031924964414\n",
      "Classifier 11/50: error = 0.3289055661368997, alpha = 0.35656959318994164\n",
      "Classifier 12/50: error = 0.4008866321779324, alpha = 0.2008860836845363\n",
      "Classifier 13/50: error = 0.412445567819816, alpha = 0.1769323259532488\n",
      "Classifier 14/50: error = 0.31109415793468626, alpha = 0.3975044888389986\n",
      "Classifier 15/50: error = 0.38210334983257666, alpha = 0.240315044659709\n",
      "Classifier 16/50: error = 0.3989283034832122, alpha = 0.20496625623974368\n",
      "Classifier 17/50: error = 0.43004629485478096, alpha = 0.14083113654209697\n",
      "Classifier 18/50: error = 0.39589721966453695, alpha = 0.21129485911231394\n",
      "Classifier 19/50: error = 0.3999613314506868, alpha = 0.20281311478829503\n",
      "Classifier 20/50: error = 0.41191784503523443, alpha = 0.17802136659126536\n",
      "Classifier 21/50: error = 0.38751424391517364, alpha = 0.22888654003668907\n",
      "Classifier 22/50: error = 0.36394196235579646, alpha = 0.2791477011850083\n",
      "Classifier 23/50: error = 0.37063688405025674, alpha = 0.26474277337517754\n",
      "Classifier 24/50: error = 0.420510591116394, alpha = 0.1603388600957386\n",
      "Classifier 25/50: error = 0.42826396816188805, alpha = 0.14446882424602972\n",
      "Classifier 26/50: error = 0.3742139278554486, alpha = 0.25709047065007073\n",
      "Classifier 27/50: error = 0.4157292765860446, alpha = 0.17016508592897822\n",
      "Classifier 28/50: error = 0.428819669267154, alpha = 0.14333424809291753\n",
      "Classifier 29/50: error = 0.41873992479259003, alpha = 0.16397413386085516\n",
      "Classifier 30/50: error = 0.41839791196601106, alpha = 0.16467679704163454\n",
      "Classifier 31/50: error = 0.42598182076165614, alpha = 0.1491321979070302\n",
      "Classifier 32/50: error = 0.418907057392815, alpha = 0.16363081940194604\n",
      "Classifier 33/50: error = 0.4149944269218795, alpha = 0.17167814135454676\n",
      "Classifier 34/50: error = 0.43587708064254993, alpha = 0.12895594567709973\n",
      "Classifier 35/50: error = 0.43189436747068954, alpha = 0.13706316776860375\n",
      "Classifier 36/50: error = 0.4253643998772145, alpha = 0.15039494394451278\n",
      "Classifier 37/50: error = 0.41447899546132694, alpha = 0.172739878982236\n",
      "Classifier 38/50: error = 0.4098384189913489, alpha = 0.18231669172382972\n",
      "Classifier 39/50: error = 0.4158280938861397, alpha = 0.16996168011120866\n",
      "Classifier 40/50: error = 0.45166965391173663, alpha = 0.09696343408180046\n",
      "Classifier 41/50: error = 0.4341759984915985, alpha = 0.13241655001024868\n",
      "Classifier 42/50: error = 0.44487725832999536, alpha = 0.11069541263513655\n",
      "Classifier 43/50: error = 0.447397554244261, alpha = 0.10559562794978587\n",
      "Classifier 44/50: error = 0.4409766688044664, alpha = 0.11859962038720574\n",
      "Classifier 45/50: error = 0.43613949361486226, alpha = 0.12842238004396495\n",
      "Classifier 46/50: error = 0.42591806391171017, alpha = 0.14926257116779762\n",
      "Classifier 47/50: error = 0.4263230079890711, alpha = 0.1484346062536778\n",
      "Classifier 48/50: error = 0.42832692632025515, alpha = 0.1443402639357424\n",
      "Classifier 49/50: error = 0.45933583028930786, alpha = 0.08150836436933996\n",
      "Classifier 50/50: error = 0.45351335726675535, alpha = 0.09324257147613975\n",
      "Accuracy for digit 6: 0.9464\n",
      "Confusion Matrix for digit 6:\n",
      "[[8551  491]\n",
      " [  45  913]]\n",
      "Running AdaBoost for digit: 7\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Classifier 1/50: error = 0.27791523665096995, alpha = 0.4774131847381361\n",
      "Classifier 2/50: error = 0.30766641650033083, alpha = 0.40552588181963933\n",
      "Classifier 3/50: error = 0.3190169968723131, alpha = 0.3791464819390574\n",
      "Classifier 4/50: error = 0.3016009092218388, alpha = 0.4198430258408045\n",
      "Classifier 5/50: error = 0.29901647613383986, alpha = 0.42599285340513704\n",
      "Classifier 6/50: error = 0.3097770538328445, alpha = 0.4005808990258315\n",
      "Classifier 7/50: error = 0.34586943516184676, alpha = 0.3186228115014616\n",
      "Classifier 8/50: error = 0.3715199207915575, alpha = 0.26285092316963293\n",
      "Classifier 9/50: error = 0.39886239613587443, alpha = 0.2051036904262619\n",
      "Classifier 10/50: error = 0.3616723575442552, alpha = 0.2840564926230347\n",
      "Classifier 11/50: error = 0.3195569595944443, alpha = 0.37790429031991696\n",
      "Classifier 12/50: error = 0.34944544199724625, alpha = 0.31073885934979373\n",
      "Classifier 13/50: error = 0.4179137337464196, alpha = 0.16567181392730457\n",
      "Classifier 14/50: error = 0.3841833373300907, alpha = 0.23591470699382489\n",
      "Classifier 15/50: error = 0.4279961425715473, alpha = 0.14501577609819533\n",
      "Classifier 16/50: error = 0.4272703354534043, alpha = 0.14649844934823017\n",
      "Classifier 17/50: error = 0.41872545285716356, alpha = 0.16400386310409037\n",
      "Classifier 18/50: error = 0.39207529023023185, alpha = 0.21929857666518637\n",
      "Classifier 19/50: error = 0.425099590249331, alpha = 0.15093667691482557\n",
      "Classifier 20/50: error = 0.4172431371570203, alpha = 0.1670504699091702\n",
      "Classifier 21/50: error = 0.3901426122014453, alpha = 0.22335639732715884\n",
      "Classifier 22/50: error = 0.41851108748253163, alpha = 0.16444426085316222\n",
      "Classifier 23/50: error = 0.42160898917219675, alpha = 0.15808590532400135\n",
      "Classifier 24/50: error = 0.45490842294339906, alpha = 0.0904288406851012\n",
      "Classifier 25/50: error = 0.4391371168745737, alpha = 0.12233237853167195\n",
      "Classifier 26/50: error = 0.4238061276342203, alpha = 0.15358404172641138\n",
      "Classifier 27/50: error = 0.41346450191845824, alpha = 0.17483076426973676\n",
      "Classifier 28/50: error = 0.4158657591890611, alpha = 0.1698841534096369\n",
      "Classifier 29/50: error = 0.42543457998248413, alpha = 0.1502513880438206\n",
      "Classifier 30/50: error = 0.3989463441426888, alpha = 0.20492863804219533\n",
      "Classifier 31/50: error = 0.45155906361367726, alpha = 0.09718670554487181\n",
      "Classifier 32/50: error = 0.41672096432649985, alpha = 0.1681244223121645\n",
      "Classifier 33/50: error = 0.40669515441213044, alpha = 0.1888222209475415\n",
      "Classifier 34/50: error = 0.4121902165583039, alpha = 0.177459232231357\n",
      "Classifier 35/50: error = 0.4073492682519494, alpha = 0.18746713488007613\n",
      "Classifier 36/50: error = 0.4333576597230153, alpha = 0.13408246022464299\n",
      "Classifier 37/50: error = 0.4205381767706803, alpha = 0.16028225872557267\n",
      "Classifier 38/50: error = 0.42806058196426716, alpha = 0.14488417048823013\n",
      "Classifier 39/50: error = 0.39192559203862454, alpha = 0.21961262517889993\n",
      "Classifier 40/50: error = 0.43391406318696457, alpha = 0.1329496975227814\n",
      "Classifier 41/50: error = 0.42660797022938285, alpha = 0.14785208216948698\n",
      "Classifier 42/50: error = 0.4458957623917389, alpha = 0.10863380771928088\n",
      "Classifier 43/50: error = 0.4404730260498542, alpha = 0.11962126435042399\n",
      "Classifier 44/50: error = 0.4493672764232761, alpha = 0.10161374126290058\n",
      "Classifier 45/50: error = 0.4541734092105091, alpha = 0.09191112112438465\n",
      "Classifier 46/50: error = 0.4352779530403129, alpha = 0.13017442911133842\n",
      "Classifier 47/50: error = 0.43935879475576545, alpha = 0.1218823793135389\n",
      "Classifier 48/50: error = 0.4389895279070778, alpha = 0.12263200688318572\n",
      "Classifier 49/50: error = 0.4516242495456439, alpha = 0.0970551000807902\n",
      "Classifier 50/50: error = 0.45771247992088493, alpha = 0.08477756335900069\n",
      "Accuracy for digit 7: 0.9431\n",
      "Confusion Matrix for digit 7:\n",
      "[[8469  503]\n",
      " [  66  962]]\n",
      "Running AdaBoost for digit: 8\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3032219468421502, alpha = 0.4160009465235836\n",
      "Classifier 2/50: error = 0.31064711034259507, alpha = 0.39854787089753424\n",
      "Classifier 3/50: error = 0.35176528929813816, alpha = 0.30564433854356154\n",
      "Classifier 4/50: error = 0.3186785433910192, alpha = 0.3799256685003679\n",
      "Classifier 5/50: error = 0.3737581730256105, alpha = 0.25806380468684526\n",
      "Classifier 6/50: error = 0.3572952044212316, alpha = 0.2935615853069823\n",
      "Classifier 7/50: error = 0.39583731407883793, alpha = 0.21142010266070813\n",
      "Classifier 8/50: error = 0.405712777838806, alpha = 0.19085863795524843\n",
      "Classifier 9/50: error = 0.4115216776939772, alpha = 0.17883919601084322\n",
      "Classifier 10/50: error = 0.42280188785497463, alpha = 0.15564091850383868\n",
      "Classifier 11/50: error = 0.42150265534096165, alpha = 0.1583039396752795\n",
      "Classifier 12/50: error = 0.3810969368170649, alpha = 0.2424474439620702\n",
      "Classifier 13/50: error = 0.4284161264531851, alpha = 0.14415812572839543\n",
      "Classifier 14/50: error = 0.40239251297002, alpha = 0.19775307474155676\n",
      "Classifier 15/50: error = 0.4236407649920579, alpha = 0.15392264719303184\n",
      "Classifier 16/50: error = 0.43848316464161086, alpha = 0.12366016924813998\n",
      "Classifier 17/50: error = 0.3974661267603708, alpha = 0.2080170850386516\n",
      "Classifier 18/50: error = 0.41670145719155394, alpha = 0.16816455005012426\n",
      "Classifier 19/50: error = 0.4308187915100574, alpha = 0.13925564367698245\n",
      "Classifier 20/50: error = 0.46666221110902917, alpha = 0.06677464720124776\n",
      "Classifier 21/50: error = 0.44543207162067944, alpha = 0.10957227225974152\n",
      "Classifier 22/50: error = 0.44771811421218355, alpha = 0.10494737675909403\n",
      "Classifier 23/50: error = 0.45100279683861605, alpha = 0.09830990306690886\n",
      "Classifier 24/50: error = 0.4447307647897122, alpha = 0.11099201422003016\n",
      "Classifier 25/50: error = 0.45169433229992373, alpha = 0.09691361204134648\n",
      "Classifier 26/50: error = 0.43708721599682215, alpha = 0.1264959745026156\n",
      "Classifier 27/50: error = 0.4672406352400002, alpha = 0.06561272255209295\n",
      "Classifier 28/50: error = 0.46308427028343147, alpha = 0.07396605374328002\n",
      "Classifier 29/50: error = 0.447109080443038, alpha = 0.10617906859249605\n",
      "Classifier 30/50: error = 0.4559456045373202, alpha = 0.08833785968865365\n",
      "Classifier 31/50: error = 0.4548209764625738, alpha = 0.0906051705204509\n",
      "Classifier 32/50: error = 0.4606130816197338, alpha = 0.07893738498466277\n",
      "Classifier 33/50: error = 0.45852646752281717, alpha = 0.08313808534652206\n",
      "Classifier 34/50: error = 0.4343749527833608, alpha = 0.1320116451294119\n",
      "Classifier 35/50: error = 0.4510763104154072, alpha = 0.09816145249458258\n",
      "Classifier 36/50: error = 0.45704192948318556, alpha = 0.08612848130755545\n",
      "Classifier 37/50: error = 0.4657282160728069, alpha = 0.06865121572570293\n",
      "Classifier 38/50: error = 0.4754093464510601, alpha = 0.04922101800004929\n",
      "Classifier 39/50: error = 0.46719782173029256, alpha = 0.06569871921235873\n",
      "Classifier 40/50: error = 0.4572600091975686, alpha = 0.08568909494899155\n",
      "Classifier 41/50: error = 0.4371485699779236, alpha = 0.12637129452221438\n",
      "Classifier 42/50: error = 0.46207178392913073, alpha = 0.07600243418471504\n",
      "Classifier 43/50: error = 0.4445050373756909, alpha = 0.11144907662104604\n",
      "Classifier 44/50: error = 0.4615455932290794, alpha = 0.0770609916316768\n",
      "Classifier 45/50: error = 0.46716403340503043, alpha = 0.0657665882676299\n",
      "Classifier 46/50: error = 0.4569501954290024, alpha = 0.08631331670942444\n",
      "Classifier 47/50: error = 0.47676458561472956, alpha = 0.04650432401157849\n",
      "Classifier 48/50: error = 0.46792482710633576, alpha = 0.06423856229527891\n",
      "Classifier 49/50: error = 0.4683342074668818, alpha = 0.06341646140519545\n",
      "Classifier 50/50: error = 0.4722175542536879, alpha = 0.0556221823897359\n",
      "Accuracy for digit 8: 0.8827\n",
      "Confusion Matrix for digit 8:\n",
      "[[7964 1062]\n",
      " [ 111  863]]\n",
      "Running AdaBoost for digit: 9\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Classifier 1/50: error = 0.34694906707009554, alpha = 0.31623856803259814\n",
      "Classifier 2/50: error = 0.3196770898942195, alpha = 0.3776280804289519\n",
      "Classifier 3/50: error = 0.3492175765452309, alpha = 0.3112401054004033\n",
      "Classifier 4/50: error = 0.3960338083598703, alpha = 0.21100931995955965\n",
      "Classifier 5/50: error = 0.3222102878547126, alpha = 0.37181634016519655\n",
      "Classifier 6/50: error = 0.39656626665582073, alpha = 0.20989653719489268\n",
      "Classifier 7/50: error = 0.3995866343633909, alpha = 0.20359388098603462\n",
      "Classifier 8/50: error = 0.42167174195876256, alpha = 0.15795723960099248\n",
      "Classifier 9/50: error = 0.35119441115660477, alpha = 0.30689658434297645\n",
      "Classifier 10/50: error = 0.38170347971887086, alpha = 0.2411620362432857\n",
      "Classifier 11/50: error = 0.3736442190636641, alpha = 0.2583072454865131\n",
      "Classifier 12/50: error = 0.42910547702305424, alpha = 0.14275085665379503\n",
      "Classifier 13/50: error = 0.4272535168968412, alpha = 0.14653281372530183\n",
      "Classifier 14/50: error = 0.4151313964153892, alpha = 0.17139606234509436\n",
      "Classifier 15/50: error = 0.4330286875910839, alpha = 0.1347523640447135\n",
      "Classifier 16/50: error = 0.41589164440442306, alpha = 0.16983087490026785\n",
      "Classifier 17/50: error = 0.435258001954975, alpha = 0.13021501148062586\n",
      "Classifier 18/50: error = 0.43160538256039627, alpha = 0.13765211098412794\n",
      "Classifier 19/50: error = 0.4076074576640789, alpha = 0.18693244781548024\n",
      "Classifier 20/50: error = 0.43086288452723953, alpha = 0.13916573756250067\n",
      "Classifier 21/50: error = 0.4298247307316051, alpha = 0.1412831404026728\n",
      "Classifier 22/50: error = 0.4282649949028755, alpha = 0.14446672760696588\n",
      "Classifier 23/50: error = 0.4437065765907746, alpha = 0.1130662072562487\n",
      "Classifier 24/50: error = 0.45571522631753625, alpha = 0.08880224007232912\n",
      "Classifier 25/50: error = 0.44080793707316945, alpha = 0.11894186670416955\n",
      "Classifier 26/50: error = 0.42394413204439363, alpha = 0.15330148320225107\n",
      "Classifier 27/50: error = 0.4430245628796655, alpha = 0.11444796259626124\n",
      "Classifier 28/50: error = 0.42033246090913345, alpha = 0.16070437946141264\n",
      "Classifier 29/50: error = 0.4334787085626079, alpha = 0.1338359920340105\n",
      "Classifier 30/50: error = 0.43664004507913345, alpha = 0.12740480756794842\n",
      "Classifier 31/50: error = 0.4527429415507537, alpha = 0.0947970639217096\n",
      "Classifier 32/50: error = 0.4285721742923244, alpha = 0.14383951368355957\n",
      "Classifier 33/50: error = 0.4455143587278627, alpha = 0.10940571725951907\n",
      "Classifier 34/50: error = 0.46798516866613193, alpha = 0.06411738142165209\n",
      "Classifier 35/50: error = 0.4507203553275095, alpha = 0.0988802951447137\n",
      "Classifier 36/50: error = 0.44880241537291454, alpha = 0.1027553007905805\n",
      "Classifier 37/50: error = 0.46147090682291747, alpha = 0.07721125497383267\n",
      "Classifier 38/50: error = 0.4374630714366857, alpha = 0.1257322442808375\n",
      "Classifier 39/50: error = 0.4585648005913411, alpha = 0.08306088856978314\n",
      "Classifier 40/50: error = 0.4662405806299307, alpha = 0.06762172177003627\n",
      "Classifier 41/50: error = 0.4438563973549632, alpha = 0.11276272912932213\n",
      "Classifier 42/50: error = 0.46743768255130524, alpha = 0.06521693914736931\n",
      "Classifier 43/50: error = 0.46342597839422894, alpha = 0.07327892649645237\n",
      "Classifier 44/50: error = 0.46132507931964545, alpha = 0.07750465880417017\n",
      "Classifier 45/50: error = 0.449573796016976, alpha = 0.10119644021265746\n",
      "Classifier 46/50: error = 0.45658961264582526, alpha = 0.08703991388702802\n",
      "Classifier 47/50: error = 0.43816607144032926, alpha = 0.12430415416870813\n",
      "Classifier 48/50: error = 0.45618199640977974, alpha = 0.08786139689937152\n",
      "Classifier 49/50: error = 0.4555851719599359, alpha = 0.08906441145363334\n",
      "Classifier 50/50: error = 0.45010112686249104, alpha = 0.10013105518980059\n",
      "Accuracy for digit 9: 0.8735\n",
      "Confusion Matrix for digit 9:\n",
      "[[7814 1177]\n",
      " [  88  921]]\n",
      "Overall Confusion Matrix:\n",
      "[[82217  7783]\n",
      " [  686  9314]]\n",
      "Accuracies for all digits: {0: 0.9636, 1: 0.9614, 2: 0.908, 3: 0.8927, 4: 0.904, 5: 0.8777, 6: 0.9464, 7: 0.9431, 8: 0.8827, 9: 0.8735}\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = run_adaboost_for_all_digits(T=50, A=50, verboseParam=True) # Ejecutamos AdaBoost para todos los dgitos\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1B: Experimentacin con los parmetros T y A del mtodo AdaboostBinario.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.4628957365977207, alpha = 0.07434519843759638\n",
      "Classifier 2/10: error = 0.34708045323833114, alpha = 0.315948654596807\n",
      "Classifier 3/10: error = 0.40080411365102037, alpha = 0.20105787676990772\n",
      "Classifier 4/10: error = 0.31605683840722487, alpha = 0.3859763755615967\n",
      "Classifier 5/10: error = 0.4227801395499033, alpha = 0.1556854776221575\n",
      "Classifier 6/10: error = 0.40472991456243146, alpha = 0.19289763027887163\n",
      "Classifier 7/10: error = 0.30785843321425194, alpha = 0.40507523295273934\n",
      "Classifier 8/10: error = 0.3720842832706053, alpha = 0.26164277588999596\n",
      "Classifier 9/10: error = 0.34219570422202106, alpha = 0.32676232807509764\n",
      "Classifier 10/10: error = 0.36888067270218583, alpha = 0.2685108706281465\n",
      "Accuracy for digit 0: 0.8419\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.20092866188265102, alpha = 0.6902501483026792\n",
      "Classifier 2/10: error = 0.2894774867351705, alpha = 0.4489615526888148\n",
      "Classifier 3/10: error = 0.4488714685261558, alpha = 0.1026157331219131\n",
      "Classifier 4/10: error = 0.4629594675875566, alpha = 0.07421703186837131\n",
      "Classifier 5/10: error = 0.4377931088596554, alpha = 0.12506173560994047\n",
      "Classifier 6/10: error = 0.3042598206408828, alpha = 0.41354713769661994\n",
      "Classifier 7/10: error = 0.35586671689684884, alpha = 0.29667469794710927\n",
      "Classifier 8/10: error = 0.4048278800039143, alpha = 0.19269432590466204\n",
      "Classifier 9/10: error = 0.3290510408601708, alpha = 0.3562400944713894\n",
      "Classifier 10/10: error = 0.32942448038741134, alpha = 0.35539459745642005\n",
      "Accuracy for digit 0: 0.9045\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.29480793583790643, alpha = 0.4360730587995071\n",
      "Classifier 2/10: error = 0.3560468428600887, alpha = 0.29628184135462016\n",
      "Classifier 3/10: error = 0.30967009437904736, alpha = 0.4008310440566515\n",
      "Classifier 4/10: error = 0.38265641433106534, alpha = 0.2391441188605612\n",
      "Classifier 5/10: error = 0.27308708357260314, alpha = 0.48950797676688634\n",
      "Classifier 6/10: error = 0.3756373655973902, alpha = 0.2540535597664194\n",
      "Classifier 7/10: error = 0.24855631844987514, alpha = 0.5531634056357645\n",
      "Classifier 8/10: error = 0.31958504849505653, alpha = 0.37783970191396427\n",
      "Classifier 9/10: error = 0.39722178265105595, alpha = 0.2085272795251313\n",
      "Classifier 10/10: error = 0.4037065063990476, alpha = 0.19502242002984896\n",
      "Accuracy for digit 0: 0.8814\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.25977205571971296, alpha = 0.5235768168079478\n",
      "Classifier 2/10: error = 0.4542614893173838, alpha = 0.09173347146564632\n",
      "Classifier 3/10: error = 0.2945338352120708, alpha = 0.4367324619471028\n",
      "Classifier 4/10: error = 0.32702246713316513, alpha = 0.3608415350040119\n",
      "Classifier 5/10: error = 0.42440926725809025, alpha = 0.15234931600461665\n",
      "Classifier 6/10: error = 0.2155033156874635, alpha = 0.646033024941861\n",
      "Classifier 7/10: error = 0.2838654254158382, alpha = 0.4626839153647844\n",
      "Classifier 8/10: error = 0.3610277835970531, alpha = 0.28545302763003283\n",
      "Classifier 9/10: error = 0.4309439664652201, alpha = 0.13900041649243502\n",
      "Classifier 10/10: error = 0.41511475903627326, alpha = 0.1714303244116316\n",
      "Accuracy for digit 0: 0.8510\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.14022794428028718, alpha = 0.9066990150135659\n",
      "Classifier 2/10: error = 0.25112396093275297, alpha = 0.5463133910828647\n",
      "Classifier 3/10: error = 0.3441233125786739, alpha = 0.32248636735314545\n",
      "Classifier 4/10: error = 0.26912125747052473, alpha = 0.49954275878103205\n",
      "Classifier 5/10: error = 0.31653921140791985, alpha = 0.3848610805890895\n",
      "Classifier 6/10: error = 0.34156257375081844, alpha = 0.32816929877802475\n",
      "Classifier 7/10: error = 0.3285245864145877, alpha = 0.3574328606777744\n",
      "Classifier 8/10: error = 0.441436283487759, alpha = 0.11766750282879583\n",
      "Classifier 9/10: error = 0.43394449895691817, alpha = 0.13288774419350555\n",
      "Classifier 10/10: error = 0.43075162519216215, alpha = 0.13939260078777793\n",
      "Accuracy for digit 0: 0.9000\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.35010552975939213, alpha = 0.30928768673277657\n",
      "Classifier 2/10: error = 0.2521192781283831, alpha = 0.5436706004116014\n",
      "Classifier 3/10: error = 0.24924452783422502, alpha = 0.5513227707133499\n",
      "Classifier 4/10: error = 0.31767702377957496, alpha = 0.38223394978909286\n",
      "Classifier 5/10: error = 0.3121211306315744, alpha = 0.3951107043125988\n",
      "Classifier 6/10: error = 0.2388241095625273, alpha = 0.5795685618976517\n",
      "Classifier 7/10: error = 0.3458641011699666, alpha = 0.3186345996963057\n",
      "Classifier 8/10: error = 0.30026626613015284, alpha = 0.42301512376200867\n",
      "Classifier 9/10: error = 0.3420515313229403, alpha = 0.3270826054713916\n",
      "Classifier 10/10: error = 0.43115287013124404, alpha = 0.13857450956138126\n",
      "Accuracy for digit 0: 0.9190\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.23039257070493885, alpha = 0.6030479346765654\n",
      "Classifier 2/10: error = 0.34849004908564735, alpha = 0.31284149696488894\n",
      "Classifier 3/10: error = 0.3106897445887502, alpha = 0.3984483295986136\n",
      "Classifier 4/10: error = 0.30524476515563626, alpha = 0.41122281989731196\n",
      "Classifier 5/10: error = 0.32617853735382574, alpha = 0.362760145698851\n",
      "Classifier 6/10: error = 0.320015848155916, alpha = 0.37684948578341704\n",
      "Classifier 7/10: error = 0.37200389241206117, alpha = 0.26181482526967365\n",
      "Classifier 8/10: error = 0.2583551370030852, alpha = 0.5272676843077732\n",
      "Classifier 9/10: error = 0.3582374377552559, alpha = 0.29151119695345984\n",
      "Classifier 10/10: error = 0.36970044000596336, alpha = 0.26675107110252927\n",
      "Accuracy for digit 0: 0.8783\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.28695652173913044, alpha = 0.4551058427947659\n",
      "Classifier 2/10: error = 0.3416320438558116, alpha = 0.32801485802066593\n",
      "Classifier 3/10: error = 0.3756237007585435, alpha = 0.254082691878691\n",
      "Classifier 4/10: error = 0.24432685031536705, alpha = 0.5645510306801319\n",
      "Classifier 5/10: error = 0.3856000648154616, alpha = 0.23292267270834968\n",
      "Classifier 6/10: error = 0.2606996068980638, alpha = 0.5211677554844789\n",
      "Classifier 7/10: error = 0.41785525640855575, alpha = 0.16579201052470158\n",
      "Classifier 8/10: error = 0.41594915586333614, alpha = 0.1697125047689853\n",
      "Classifier 9/10: error = 0.38298275233610735, alpha = 0.2384535111941944\n",
      "Classifier 10/10: error = 0.3685257838001478, alpha = 0.26927321630077344\n",
      "Accuracy for digit 0: 0.8915\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/10: error = 0.28172224567327986, alpha = 0.46796734867650813\n",
      "Classifier 2/10: error = 0.2948942869647859, alpha = 0.43586539804809465\n",
      "Classifier 3/10: error = 0.2716183572475879, alpha = 0.4932135812377903\n",
      "Classifier 4/10: error = 0.3841134200934144, alpha = 0.23606247457586788\n",
      "Classifier 5/10: error = 0.28750478312488714, alpha = 0.4537668508499629\n",
      "Classifier 6/10: error = 0.3577656676779526, alpha = 0.2925375140305815\n",
      "Classifier 7/10: error = 0.27681340168550117, alpha = 0.4801618192631363\n",
      "Classifier 8/10: error = 0.37852683608888094, alpha = 0.24790287942194486\n",
      "Classifier 9/10: error = 0.36816296082957495, alpha = 0.2700529214400569\n",
      "Classifier 10/10: error = 0.4236152529268447, alpha = 0.1539748901904162\n",
      "Accuracy for digit 0: 0.8979\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/7: error = 0.22422963275643737, alpha = 0.6205929422937464\n",
      "Classifier 2/7: error = 0.24875786611223455, alpha = 0.5526240083633832\n",
      "Classifier 3/7: error = 0.30778330653806485, alpha = 0.4052515310474575\n",
      "Classifier 4/7: error = 0.3076966599281954, alpha = 0.40545489239323523\n",
      "Classifier 5/7: error = 0.290733320604847, alpha = 0.44591258359861846\n",
      "Classifier 6/7: error = 0.3576395471560776, alpha = 0.29281198568613886\n",
      "Classifier 7/7: error = 0.3284546395222244, alpha = 0.3575914098771768\n",
      "Accuracy for digit 0: 0.9029\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/7: error = 0.2844238075137189, alpha = 0.46131133788489814\n",
      "Classifier 2/7: error = 0.26556569693252186, alpha = 0.5086191453995705\n",
      "Classifier 3/7: error = 0.2551975540496637, alpha = 0.5355405213782487\n",
      "Classifier 4/7: error = 0.2320059527643971, alpha = 0.5985094760085722\n",
      "Classifier 5/7: error = 0.3034882254614195, alpha = 0.4153709421418506\n",
      "Classifier 6/7: error = 0.30770889019737935, alpha = 0.4054261857761514\n",
      "Classifier 7/7: error = 0.35169698125386806, alpha = 0.3057941261493331\n",
      "Accuracy for digit 0: 0.8678\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/7: error = 0.28425495989869143, alpha = 0.4617262162697128\n",
      "Classifier 2/7: error = 0.23257971346170453, alpha = 0.596900796357294\n",
      "Classifier 3/7: error = 0.3370528369644401, alpha = 0.3382277943973163\n",
      "Classifier 4/7: error = 0.3816341688793117, alpha = 0.24130888265331263\n",
      "Classifier 5/7: error = 0.2858390705144486, alpha = 0.45783968311402934\n",
      "Classifier 6/7: error = 0.17986506355396703, alpha = 0.7586309800428784\n",
      "Classifier 7/7: error = 0.30776061836556917, alpha = 0.4053047775737371\n",
      "Accuracy for digit 0: 0.8801\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/9: error = 0.28205994090333486, alpha = 0.46713323872488977\n",
      "Classifier 2/9: error = 0.28699092040475427, alpha = 0.45502178772069435\n",
      "Classifier 3/9: error = 0.3360366940198783, alpha = 0.3405032616657132\n",
      "Classifier 4/9: error = 0.3767167702389445, alpha = 0.2517537026283902\n",
      "Classifier 5/9: error = 0.28643857661228367, alpha = 0.4563721997751753\n",
      "Classifier 6/9: error = 0.26994816262297666, alpha = 0.497442795606388\n",
      "Classifier 7/9: error = 0.3192343081405178, alpha = 0.37864642025946404\n",
      "Classifier 8/9: error = 0.40861933018681873, alpha = 0.184837965868249\n",
      "Classifier 9/9: error = 0.36097917231498267, alpha = 0.2855583928309566\n",
      "Accuracy for digit 0: 0.8658\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/9: error = 0.2815533980582524, alpha = 0.46838463150085624\n",
      "Classifier 2/9: error = 0.31723530127728605, alpha = 0.38325325740376454\n",
      "Classifier 3/9: error = 0.2848051162899919, alpha = 0.46037496304763365\n",
      "Classifier 4/9: error = 0.372647921333062, alpha = 0.2604369243277671\n",
      "Classifier 5/9: error = 0.3382689243744138, alpha = 0.3355090148540676\n",
      "Classifier 6/9: error = 0.2514294877262214, alpha = 0.5455014102986222\n",
      "Classifier 7/9: error = 0.25961946458585483, alpha = 0.5239736648281333\n",
      "Classifier 8/9: error = 0.40013073249437336, alpha = 0.20246020947757976\n",
      "Classifier 9/9: error = 0.3778030193523291, alpha = 0.24944189233768546\n",
      "Accuracy for digit 0: 0.8858\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/9: error = 0.3309413254537781, alpha = 0.351965332904134\n",
      "Classifier 2/9: error = 0.2383511717082999, alpha = 0.5808702481790748\n",
      "Classifier 3/9: error = 0.18571787762969916, alpha = 0.7390390789637448\n",
      "Classifier 4/9: error = 0.24305852345640286, alpha = 0.5679918444193458\n",
      "Classifier 5/9: error = 0.32311064686970914, alpha = 0.3697564989160576\n",
      "Classifier 6/9: error = 0.3214305499864938, alpha = 0.3736026651990345\n",
      "Classifier 7/9: error = 0.40198000598095546, alpha = 0.19861091855413088\n",
      "Classifier 8/9: error = 0.4247984864749693, alpha = 0.15155276531733972\n",
      "Classifier 9/9: error = 0.3455388183153765, alpha = 0.31935364132768784\n",
      "Accuracy for digit 0: 0.8953\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/11: error = 0.2845082313212326, alpha = 0.4611039543452619\n",
      "Classifier 2/11: error = 0.2939633938205963, alpha = 0.43810591864536513\n",
      "Classifier 3/11: error = 0.3302432389399579, alpha = 0.35354256623988356\n",
      "Classifier 4/11: error = 0.1633760643072435, alpha = 0.8166599911778079\n",
      "Classifier 5/11: error = 0.2870629417465779, alpha = 0.4548458190143534\n",
      "Classifier 6/11: error = 0.3398392679975095, alpha = 0.33200528695815057\n",
      "Classifier 7/11: error = 0.3234346317174224, alpha = 0.3690160211100029\n",
      "Classifier 8/11: error = 0.3890860259424588, alpha = 0.22557784414583748\n",
      "Classifier 9/11: error = 0.3994708750359191, alpha = 0.2038351412200579\n",
      "Classifier 10/11: error = 0.36090499074802257, alpha = 0.28571919365468595\n",
      "Classifier 11/11: error = 0.3943275178940292, alpha = 0.21457877681469598\n",
      "Accuracy for digit 0: 0.9102\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/11: error = 0.26120726044744624, alpha = 0.5198516135776687\n",
      "Classifier 2/11: error = 0.2272817172586198, alpha = 0.6118621209944339\n",
      "Classifier 3/11: error = 0.24996135814851272, alpha = 0.5494091944477544\n",
      "Classifier 4/11: error = 0.2736679950139871, alpha = 0.4880457712734299\n",
      "Classifier 5/11: error = 0.3556991619559059, alpha = 0.2970402169064234\n",
      "Classifier 6/11: error = 0.3352019011218494, alpha = 0.34237517175146526\n",
      "Classifier 7/11: error = 0.31040899347536477, alpha = 0.399103957895045\n",
      "Classifier 8/11: error = 0.37151456677988187, alpha = 0.2628623882466291\n",
      "Classifier 9/11: error = 0.3835869166274012, alpha = 0.2371755464819034\n",
      "Classifier 10/11: error = 0.3126211168612524, alpha = 0.39394683791074725\n",
      "Classifier 11/11: error = 0.3249656060862844, alpha = 0.36552214702913977\n",
      "Accuracy for digit 0: 0.9213\n",
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/11: error = 0.24027015618404396, alpha = 0.5755994800497891\n",
      "Classifier 2/11: error = 0.313992586993306, alpha = 0.3907595281494993\n",
      "Classifier 3/11: error = 0.2751610347886483, alpha = 0.484296502838604\n",
      "Classifier 4/11: error = 0.30109479208664947, alpha = 0.4210449914027287\n",
      "Classifier 5/11: error = 0.2242555965825591, alpha = 0.6205183155264563\n",
      "Classifier 6/11: error = 0.32263672637654794, alpha = 0.3708403589636892\n",
      "Classifier 7/11: error = 0.3860608323996493, alpha = 0.23195044681760002\n",
      "Classifier 8/11: error = 0.345625592444446, alpha = 0.3191617948642697\n",
      "Classifier 9/11: error = 0.34857338322643383, alpha = 0.31265798795765914\n",
      "Classifier 10/11: error = 0.3421399365478355, alpha = 0.32688620723734463\n",
      "Classifier 11/11: error = 0.39728038941070826, alpha = 0.20840489790868102\n",
      "Accuracy for digit 0: 0.9158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def experiment_adaboost_fixed_T(T_fixed, A_values, repetitions=3, verboseParam=False):\n",
    "    accuracies = []\n",
    "    execution_times = []\n",
    "\n",
    "    for A in A_values:\n",
    "        acc = []\n",
    "        exec_time = []\n",
    "        for _ in range(repetitions):\n",
    "            start_time = time.time()\n",
    "            y_test_binary, y_pred, accuracy = run_adaboost_on_mnist(digit=0, T=T_fixed, A=A, verboseParam=verboseParam)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            acc.append(accuracy)\n",
    "            exec_time.append(end_time - start_time)\n",
    "\n",
    "        avg_accuracy = np.mean(acc)\n",
    "        avg_execution_time = np.mean(exec_time)\n",
    "        accuracies.append(avg_accuracy)\n",
    "        execution_times.append(avg_execution_time)\n",
    "\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(A_values, accuracies, marker='o')\n",
    "    plt.xlabel('A values')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title(f'Accuracy vs A (T fixed at {T_fixed})')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(A_values, execution_times, marker='o')\n",
    "    plt.xlabel('A values')\n",
    "    plt.ylabel('Average Execution Time (s)')\n",
    "    plt.title(f'Execution Time vs A (T fixed at {T_fixed})')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def experiment_adaboost_fixed_A(A_fixed, T_values, repetitions=3, verboseParam=False):\n",
    "    accuracies = []\n",
    "    execution_times = []\n",
    "\n",
    "    for T in T_values:\n",
    "        acc = []\n",
    "        exec_time = []\n",
    "        for _ in range(repetitions):\n",
    "            start_time = time.time()\n",
    "            y_test_binary, y_pred, accuracy = run_adaboost_on_mnist(digit=0, T=T, A=A_fixed, verboseParam=verboseParam)\n",
    "            end_time = time.time()\n",
    "\n",
    "            acc.append(accuracy)\n",
    "            exec_time.append(end_time - start_time)\n",
    "\n",
    "        avg_accuracy = np.mean(acc)\n",
    "        avg_execution_time = np.mean(exec_time)\n",
    "        accuracies.append(avg_accuracy)\n",
    "        execution_times.append(avg_execution_time)\n",
    "\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(T_values, accuracies, marker='o')\n",
    "    plt.xlabel('T values')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title(f'Accuracy vs T (A fixed at {A_fixed})')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(T_values, execution_times, marker='o')\n",
    "    plt.xlabel('T values')\n",
    "    plt.ylabel('Average Execution Time (s)')\n",
    "    plt.title(f'Execution Time vs T (A fixed at {A_fixed})')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    T_fixed = 10\n",
    "    A_values = [7,9,11]\n",
    "\n",
    "    experiment_adaboost_fixed_T(T_fixed, A_values, repetitions=3, verboseParam=True)\n",
    "\n",
    "    A_fixed = 20\n",
    "    T_values = [7,9,11]\n",
    "\n",
    "    experiment_adaboost_fixed_A(A_fixed, T_values, repetitions=3, verboseParam=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tareas 1C y 1D: ADABoost Binario con mejoras y ADABoost Multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclase con ADABoosti Binario sin Mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, img_shape): # Inicializamos la clase\n",
    "        self.feature_index = (np.random.randint(0, img_shape[0]), np.random.randint(0, img_shape[1])) # Elegimos un ndice de caracterstica aleatorio en 2D\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.img_shape = img_shape # Inicializamos la forma de la imagen\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index[0], self.feature_index[1]] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, verbose=False): # Creamos la funcin fit\n",
    "        n_samples, img_rows, img_cols = X.shape # Obtenemos el nmero de muestras y el tamao de la imagen\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        for t in range(self.T): # Para cada iteracin\n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): # Para cada clasificador dbil\n",
    "                clf = DecisionStump((img_rows, img_cols)) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index[0], clf.feature_index[1]]), max(X[:, clf.feature_index[0], clf.feature_index[1]])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {t + 1}/{self.T}: error = {min_error}, alpha = {best_clf.alpha}') # Mostramos el error y el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_on_mnist\n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train) # Convertimos las etiquetas a binarias\n",
    "    \n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "\n",
    "    adaboost = AdaBoost(T=T, A=A) # Creamos el clasificador AdaBoost\n",
    "    adaboost.fit(X_train_balanced, Y_train_binary_balanced, verboseParam) # Ajustamos el clasificador AdaBoost\n",
    "    y_pred = adaboost.predict(X_test) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.34714518760195756, alpha = 0.3158058322736267\n",
      "Classifier 2/50: error = 0.36796932830051177, alpha = 0.270469168169948\n",
      "Classifier 3/50: error = 0.3370920938596431, alpha = 0.33813995352945947\n",
      "Classifier 4/50: error = 0.3148494368692173, alpha = 0.38877203388214243\n",
      "Classifier 5/50: error = 0.37587230151594, alpha = 0.2535527651281336\n",
      "Classifier 6/50: error = 0.38498509723751073, alpha = 0.23422093724265342\n",
      "Classifier 7/50: error = 0.3242788244229575, alpha = 0.3670884068554559\n",
      "Classifier 8/50: error = 0.4136410835871504, alpha = 0.17446671870390446\n",
      "Classifier 9/50: error = 0.37883727012217994, alpha = 0.2472431729742662\n",
      "Classifier 10/50: error = 0.40100058962730856, alpha = 0.20064885799099302\n",
      "Classifier 11/50: error = 0.3793765279376258, alpha = 0.24609769172093365\n",
      "Classifier 12/50: error = 0.41660251352889754, alpha = 0.1683680933490235\n",
      "Classifier 13/50: error = 0.4095264643905765, alpha = 0.18296164516403815\n",
      "Classifier 14/50: error = 0.422145364021368, alpha = 0.1569863114522053\n",
      "Classifier 15/50: error = 0.44009731573075805, alpha = 0.12038355795802705\n",
      "Classifier 16/50: error = 0.39841914815406776, alpha = 0.2060281780697976\n",
      "Classifier 17/50: error = 0.43537841797271426, alpha = 0.12997008054035986\n",
      "Classifier 18/50: error = 0.416527864449941, alpha = 0.16852166786182776\n",
      "Classifier 19/50: error = 0.4238255277962526, alpha = 0.15354431919970357\n",
      "Classifier 20/50: error = 0.40789943119619454, alpha = 0.18632792413109103\n",
      "Classifier 21/50: error = 0.41846680117954516, alpha = 0.16453525164958577\n",
      "Classifier 22/50: error = 0.4058485237335553, alpha = 0.19057715079601634\n",
      "Classifier 23/50: error = 0.4430899058534534, alpha = 0.11431555939028844\n",
      "Classifier 24/50: error = 0.43488559758898804, alpha = 0.1309725951443554\n",
      "Classifier 25/50: error = 0.4329738424847665, alpha = 0.13486405979052182\n",
      "Classifier 26/50: error = 0.36483937712486, alpha = 0.27721036107225944\n",
      "Classifier 27/50: error = 0.4502858751648141, alpha = 0.09975785541296495\n",
      "Classifier 28/50: error = 0.4391900878005495, alpha = 0.12222484472014995\n",
      "Classifier 29/50: error = 0.4478585342477256, alpha = 0.10466344057890259\n",
      "Classifier 30/50: error = 0.45427349311093823, alpha = 0.09170926134027738\n",
      "Classifier 31/50: error = 0.4680928889257874, alpha = 0.06390105699674953\n",
      "Classifier 32/50: error = 0.4443304135909476, alpha = 0.11180269404165318\n",
      "Classifier 33/50: error = 0.4454916485545204, alpha = 0.1094516836729655\n",
      "Classifier 34/50: error = 0.4596613761513316, alpha = 0.08085297229767043\n",
      "Classifier 35/50: error = 0.45649341270703125, alpha = 0.08723377832582142\n",
      "Classifier 36/50: error = 0.43750767039854754, alpha = 0.12564162984360602\n",
      "Classifier 37/50: error = 0.4601262910185234, alpha = 0.07991712121125018\n",
      "Classifier 38/50: error = 0.46166105673615154, alpha = 0.07682869471079765\n",
      "Classifier 39/50: error = 0.4452161351058457, alpha = 0.11000937205479445\n",
      "Classifier 40/50: error = 0.45391985900894327, alpha = 0.09242254142798037\n",
      "Classifier 41/50: error = 0.470407184274346, alpha = 0.05925488493723427\n",
      "Classifier 42/50: error = 0.42746704555455395, alpha = 0.14609654853959428\n",
      "Classifier 43/50: error = 0.45608217511425264, alpha = 0.08806258817613674\n",
      "Classifier 44/50: error = 0.46040672750619965, alpha = 0.07935268379792723\n",
      "Classifier 45/50: error = 0.46815668980101477, alpha = 0.06377293454159659\n",
      "Classifier 46/50: error = 0.4407650143878478, alpha = 0.11902893317918836\n",
      "Classifier 47/50: error = 0.46416200562168264, alpha = 0.07179911236349194\n",
      "Classifier 48/50: error = 0.46083608208406934, alpha = 0.07848861503289634\n",
      "Classifier 49/50: error = 0.45966646821837065, alpha = 0.0808427214511189\n",
      "Classifier 50/50: error = 0.4547308471066195, alpha = 0.09078691607002144\n",
      "Accuracy for digit 3: 0.8829\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_on_mnist(digit=3, T=50, A=20, verboseParam=True)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Classifier 1/50: error = 0.24052342760658513, alpha = 0.5749059891486037\n",
      "Classifier 2/50: error = 0.25252229805391857, alpha = 0.542602460222201\n",
      "Classifier 3/50: error = 0.2738234236395714, alpha = 0.4876548718878465\n",
      "Classifier 4/50: error = 0.2829808030110401, alpha = 0.46486177630565095\n",
      "Classifier 5/50: error = 0.2611382918594022, alpha = 0.5200303242735971\n",
      "Classifier 6/50: error = 0.29958325374514294, alpha = 0.4246415773946476\n",
      "Classifier 7/50: error = 0.3240640077562412, alpha = 0.3675786671426079\n",
      "Classifier 8/50: error = 0.29023366169318043, alpha = 0.4471247430794601\n",
      "Classifier 9/50: error = 0.3557339195461215, alpha = 0.29696438733156594\n",
      "Classifier 10/50: error = 0.3811802478103294, alpha = 0.242270841810073\n",
      "Classifier 11/50: error = 0.4040401035043397, alpha = 0.19432961891415823\n",
      "Classifier 12/50: error = 0.31559058803262474, alpha = 0.38705526391328177\n",
      "Classifier 13/50: error = 0.38848440973445697, alpha = 0.2268437051044694\n",
      "Classifier 14/50: error = 0.3827078110074197, alpha = 0.23903533661584958\n",
      "Classifier 15/50: error = 0.38754861176891064, alpha = 0.2288141411848405\n",
      "Classifier 16/50: error = 0.3876215458531959, alpha = 0.22866050704721502\n",
      "Classifier 17/50: error = 0.3893751331176789, alpha = 0.22496978664235515\n",
      "Classifier 18/50: error = 0.4427945206769201, alpha = 0.11491412449428805\n",
      "Classifier 19/50: error = 0.4237066283390126, alpha = 0.1537877776586801\n",
      "Classifier 20/50: error = 0.4160215301001945, alpha = 0.1695635507495102\n",
      "Classifier 21/50: error = 0.411716824653185, alpha = 0.17843631419464323\n",
      "Classifier 22/50: error = 0.40367593526295914, alpha = 0.19508591818016965\n",
      "Classifier 23/50: error = 0.36941323610272825, alpha = 0.267367429301572\n",
      "Classifier 24/50: error = 0.42297401302004345, alpha = 0.15528828065301473\n",
      "Classifier 25/50: error = 0.4325801901862012, alpha = 0.1356658575013743\n",
      "Classifier 26/50: error = 0.433251554815006, alpha = 0.13429851431385767\n",
      "Classifier 27/50: error = 0.4230617892846258, alpha = 0.1551084656124888\n",
      "Classifier 28/50: error = 0.41402261322394235, alpha = 0.17368030299735246\n",
      "Classifier 29/50: error = 0.43220770380288853, alpha = 0.13642470377104035\n",
      "Classifier 30/50: error = 0.4245856648148375, alpha = 0.15198828854748503\n",
      "Classifier 31/50: error = 0.4535612853309653, alpha = 0.09314588040849259\n",
      "Classifier 32/50: error = 0.4401687617232224, alpha = 0.12023858764773447\n",
      "Classifier 33/50: error = 0.43856766630565713, alpha = 0.12348857196970313\n",
      "Classifier 34/50: error = 0.4219885790023083, alpha = 0.15730768911528445\n",
      "Classifier 35/50: error = 0.40303413547727596, alpha = 0.19641933577312407\n",
      "Classifier 36/50: error = 0.42665454777974965, alpha = 0.147756877124268\n",
      "Classifier 37/50: error = 0.4313205700601537, alpha = 0.13823264380348388\n",
      "Classifier 38/50: error = 0.4125257240816861, alpha = 0.17676694703802887\n",
      "Classifier 39/50: error = 0.41761424230410205, alpha = 0.16628745044441812\n",
      "Classifier 40/50: error = 0.4120874822657225, alpha = 0.17767124749395205\n",
      "Classifier 41/50: error = 0.4307882917469707, alpha = 0.13931783431555123\n",
      "Classifier 42/50: error = 0.44581558230075236, alpha = 0.1087960706671505\n",
      "Classifier 43/50: error = 0.4148063676803156, alpha = 0.17206548018466214\n",
      "Classifier 44/50: error = 0.43388361860152513, alpha = 0.1330116698114266\n",
      "Classifier 45/50: error = 0.43957249793726116, alpha = 0.12144861498579677\n",
      "Classifier 46/50: error = 0.4378085573827568, alpha = 0.12503035291830036\n",
      "Classifier 47/50: error = 0.45596906790354197, alpha = 0.08829056600332726\n",
      "Classifier 48/50: error = 0.40833541121589, alpha = 0.18542548912771573\n",
      "Classifier 49/50: error = 0.4281211921210908, alpha = 0.14476038993686852\n",
      "Classifier 50/50: error = 0.4423224637183333, alpha = 0.11587086565865701\n",
      "Accuracy for digit 0: 0.9609\n",
      "Running AdaBoost for digit: 1\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Classifier 1/50: error = 0.17881777052584724, alpha = 0.7621888996194138\n",
      "Classifier 2/50: error = 0.2912034579655779, alpha = 0.44477316466161376\n",
      "Classifier 3/50: error = 0.26280916172562824, alpha = 0.5157093248834823\n",
      "Classifier 4/50: error = 0.21628798249833614, alpha = 0.6437154279603065\n",
      "Classifier 5/50: error = 0.3122226510030195, alpha = 0.394874303214081\n",
      "Classifier 6/50: error = 0.35011662385100606, alpha = 0.309263307683446\n",
      "Classifier 7/50: error = 0.3879866959390478, alpha = 0.2278914853124372\n",
      "Classifier 8/50: error = 0.31711317197962896, alpha = 0.3835352138743555\n",
      "Classifier 9/50: error = 0.39593754942744086, alpha = 0.21121054606933007\n",
      "Classifier 10/50: error = 0.34174424437427686, alpha = 0.32776545409539803\n",
      "Classifier 11/50: error = 0.3658094363013358, alpha = 0.2751184754255174\n",
      "Classifier 12/50: error = 0.3552976013318036, alpha = 0.29791653044085364\n",
      "Classifier 13/50: error = 0.40574884844229364, alpha = 0.19078383784997563\n",
      "Classifier 14/50: error = 0.4161318323680422, alpha = 0.16933655106566414\n",
      "Classifier 15/50: error = 0.35076262728091545, alpha = 0.3078443410299957\n",
      "Classifier 16/50: error = 0.3985125267840106, alpha = 0.20583338831386427\n",
      "Classifier 17/50: error = 0.3929832982823019, alpha = 0.2173945964100589\n",
      "Classifier 18/50: error = 0.4014251312238911, alpha = 0.1997652838950504\n",
      "Classifier 19/50: error = 0.4245807900090095, alpha = 0.1519982651340492\n",
      "Classifier 20/50: error = 0.4130784615763121, alpha = 0.1756267954622514\n",
      "Classifier 21/50: error = 0.40961287827679804, alpha = 0.18278297291882603\n",
      "Classifier 22/50: error = 0.43515062121624226, alpha = 0.1304334412521329\n",
      "Classifier 23/50: error = 0.39398861693108733, alpha = 0.21528837595173358\n",
      "Classifier 24/50: error = 0.4164578929192922, alpha = 0.168665626469822\n",
      "Classifier 25/50: error = 0.33011542210175726, alpha = 0.35383153417255697\n",
      "Classifier 26/50: error = 0.3741193186608178, alpha = 0.2572924837745826\n",
      "Classifier 27/50: error = 0.4386447804996584, alpha = 0.12333198271921897\n",
      "Classifier 28/50: error = 0.4240582752652218, alpha = 0.1530677978645031\n",
      "Classifier 29/50: error = 0.4442466543126631, alpha = 0.11197231849807021\n",
      "Classifier 30/50: error = 0.4215027406234637, alpha = 0.15830376480007274\n",
      "Classifier 31/50: error = 0.38506899802650907, alpha = 0.23404376780929498\n",
      "Classifier 32/50: error = 0.43469552095250613, alpha = 0.13135932636630793\n",
      "Classifier 33/50: error = 0.43741767912518015, alpha = 0.12582447272418365\n",
      "Classifier 34/50: error = 0.44526833976334085, alpha = 0.10990369528956366\n",
      "Classifier 35/50: error = 0.3858105597699437, alpha = 0.2324784719222411\n",
      "Classifier 36/50: error = 0.4295727706362322, alpha = 0.14179722354694174\n",
      "Classifier 37/50: error = 0.4303527024782503, alpha = 0.14020614108779383\n",
      "Classifier 38/50: error = 0.3896981033826955, alpha = 0.2242907008327045\n",
      "Classifier 39/50: error = 0.45877078396371873, alpha = 0.08264608731386625\n",
      "Classifier 40/50: error = 0.42895997476247694, alpha = 0.1430478441130641\n",
      "Classifier 41/50: error = 0.44074131282005424, alpha = 0.11907701136863746\n",
      "Classifier 42/50: error = 0.37929992409608515, alpha = 0.2462603735128061\n",
      "Classifier 43/50: error = 0.4171309363852471, alpha = 0.16728120085288464\n",
      "Classifier 44/50: error = 0.4460227791110587, alpha = 0.10837677168669796\n",
      "Classifier 45/50: error = 0.4467031470337907, alpha = 0.1070001943430582\n",
      "Classifier 46/50: error = 0.4496046361707683, alpha = 0.10113412648675552\n",
      "Classifier 47/50: error = 0.4492750813799593, alpha = 0.10180004532087035\n",
      "Classifier 48/50: error = 0.4496782446346582, alpha = 0.10098540089553501\n",
      "Classifier 49/50: error = 0.4328539618213315, alpha = 0.13510821647063648\n",
      "Classifier 50/50: error = 0.42508505697525956, alpha = 0.15096641082998408\n",
      "Accuracy for digit 1: 0.9639\n",
      "Running AdaBoost for digit: 2\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Classifier 1/50: error = 0.31201745552198723, alpha = 0.39535216630387565\n",
      "Classifier 2/50: error = 0.28395713357094543, alpha = 0.4624583728159681\n",
      "Classifier 3/50: error = 0.33185275313550666, alpha = 0.3499086113245768\n",
      "Classifier 4/50: error = 0.3924580018266993, alpha = 0.21849588787426824\n",
      "Classifier 5/50: error = 0.3111657117197483, alpha = 0.39733756302342155\n",
      "Classifier 6/50: error = 0.36709537024852024, alpha = 0.27234903402303356\n",
      "Classifier 7/50: error = 0.3490754851240133, alpha = 0.31155274710623365\n",
      "Classifier 8/50: error = 0.33917148191087276, alpha = 0.3334942761092445\n",
      "Classifier 9/50: error = 0.33900660164213015, alpha = 0.33386213562048705\n",
      "Classifier 10/50: error = 0.37060347584843734, alpha = 0.26481438462088547\n",
      "Classifier 11/50: error = 0.417047472106609, alpha = 0.16745284919061848\n",
      "Classifier 12/50: error = 0.39019493835568936, alpha = 0.22324643937222818\n",
      "Classifier 13/50: error = 0.4267008563320044, alpha = 0.1476622245504149\n",
      "Classifier 14/50: error = 0.4454926113864768, alpha = 0.10944973484838065\n",
      "Classifier 15/50: error = 0.4083563408475741, alpha = 0.18538217440683366\n",
      "Classifier 16/50: error = 0.43836385305982745, alpha = 0.12390246726378502\n",
      "Classifier 17/50: error = 0.38842208035273074, alpha = 0.22697489319295358\n",
      "Classifier 18/50: error = 0.39045323294458567, alpha = 0.22270373798060805\n",
      "Classifier 19/50: error = 0.4368243123015437, alpha = 0.12703027639945652\n",
      "Classifier 20/50: error = 0.43521485328268394, alpha = 0.1303027813652868\n",
      "Classifier 21/50: error = 0.41361785245859095, alpha = 0.17451461001253832\n",
      "Classifier 22/50: error = 0.4277227681997884, alpha = 0.1455741485135254\n",
      "Classifier 23/50: error = 0.4368263883711882, alpha = 0.1270260568994567\n",
      "Classifier 24/50: error = 0.4234075598899101, alpha = 0.15440023008349948\n",
      "Classifier 25/50: error = 0.4192760421824959, alpha = 0.1628730066788177\n",
      "Classifier 26/50: error = 0.445667826526081, alpha = 0.10909510358567366\n",
      "Classifier 27/50: error = 0.45206668259521465, alpha = 0.09616194956038611\n",
      "Classifier 28/50: error = 0.44003854174532697, alpha = 0.1205028194074693\n",
      "Classifier 29/50: error = 0.45401570868762625, alpha = 0.09222920336373479\n",
      "Classifier 30/50: error = 0.452939943917911, alpha = 0.09439952276811478\n",
      "Classifier 31/50: error = 0.45007469093830976, alpha = 0.1001844592020636\n",
      "Classifier 32/50: error = 0.44564177841712815, alpha = 0.10914782260509316\n",
      "Classifier 33/50: error = 0.45512526996658287, alpha = 0.08999160769573183\n",
      "Classifier 34/50: error = 0.4616469107120118, alpha = 0.07685715414803057\n",
      "Classifier 35/50: error = 0.4455203452440153, alpha = 0.1093936003579643\n",
      "Classifier 36/50: error = 0.4687843794773966, alpha = 0.06251254316441303\n",
      "Classifier 37/50: error = 0.4613323781031228, alpha = 0.07748997339100204\n",
      "Classifier 38/50: error = 0.44285158607577535, alpha = 0.11479848145406865\n",
      "Classifier 39/50: error = 0.44642345584302234, alpha = 0.10756603978296904\n",
      "Classifier 40/50: error = 0.4495571847771253, alpha = 0.1012300041910347\n",
      "Classifier 41/50: error = 0.45678916792242075, alpha = 0.08663778606863369\n",
      "Classifier 42/50: error = 0.46465087411311046, alpha = 0.070816395277862\n",
      "Classifier 43/50: error = 0.46141007386340727, alpha = 0.07733364881113163\n",
      "Classifier 44/50: error = 0.46380969232967995, alpha = 0.07250741369863951\n",
      "Classifier 45/50: error = 0.47489796268336815, alpha = 0.05024631746258448\n",
      "Classifier 46/50: error = 0.45955128981212656, alpha = 0.0810745913946774\n",
      "Classifier 47/50: error = 0.44158308899565746, alpha = 0.1173698181546384\n",
      "Classifier 48/50: error = 0.4587458191028546, alpha = 0.0826963590599611\n",
      "Classifier 49/50: error = 0.47080635763414946, alpha = 0.05845376964223461\n",
      "Classifier 50/50: error = 0.4692515488557666, alpha = 0.06157460307428731\n",
      "Accuracy for digit 2: 0.91\n",
      "Running AdaBoost for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2986133768352368, alpha = 0.42695479154917626\n",
      "Classifier 2/50: error = 0.34046952984031564, alpha = 0.3306012688957759\n",
      "Classifier 3/50: error = 0.28439939148346816, alpha = 0.46137132175213397\n",
      "Classifier 4/50: error = 0.3523314101254853, alpha = 0.3044034456593691\n",
      "Classifier 5/50: error = 0.39384739557063586, alpha = 0.2155841316930041\n",
      "Classifier 6/50: error = 0.3636456573188424, alpha = 0.27978781302626154\n",
      "Classifier 7/50: error = 0.40384853155513356, alpha = 0.1947274453079166\n",
      "Classifier 8/50: error = 0.4098899140514052, alpha = 0.18221024222111565\n",
      "Classifier 9/50: error = 0.37497205019365587, alpha = 0.25547243897208904\n",
      "Classifier 10/50: error = 0.36972074477787487, alpha = 0.26670750324362485\n",
      "Classifier 11/50: error = 0.4234111711320121, alpha = 0.15439283405518178\n",
      "Classifier 12/50: error = 0.4164614834876318, alpha = 0.16865823910803437\n",
      "Classifier 13/50: error = 0.4318564124338172, alpha = 0.13714051368027305\n",
      "Classifier 14/50: error = 0.3989747882663106, alpha = 0.20486932781009304\n",
      "Classifier 15/50: error = 0.40838788928753833, alpha = 0.18531688493152074\n",
      "Classifier 16/50: error = 0.4159761370650049, alpha = 0.16965697366143637\n",
      "Classifier 17/50: error = 0.41297370502646236, alpha = 0.1758428457806505\n",
      "Classifier 18/50: error = 0.4190418766246301, alpha = 0.16335390912078776\n",
      "Classifier 19/50: error = 0.44241545740848753, alpha = 0.11568237410211162\n",
      "Classifier 20/50: error = 0.41143522488829604, alpha = 0.17901769659096883\n",
      "Classifier 21/50: error = 0.41054227796434084, alpha = 0.18086204200524633\n",
      "Classifier 22/50: error = 0.44720118443621665, alpha = 0.10599277969905313\n",
      "Classifier 23/50: error = 0.4233340940896012, alpha = 0.15455069584227518\n",
      "Classifier 24/50: error = 0.44647419784512327, alpha = 0.10746337815614863\n",
      "Classifier 25/50: error = 0.42539548899315793, alpha = 0.1503313492937123\n",
      "Classifier 26/50: error = 0.41499578940071913, alpha = 0.1716753352923357\n",
      "Classifier 27/50: error = 0.4428645835670185, alpha = 0.11477214246345865\n",
      "Classifier 28/50: error = 0.4305536037833795, alpha = 0.1397964114087752\n",
      "Classifier 29/50: error = 0.4411438187317267, alpha = 0.11826060978059723\n",
      "Classifier 30/50: error = 0.43716190400627, alpha = 0.12634419840494085\n",
      "Classifier 31/50: error = 0.43634211880832596, alpha = 0.12801043097231538\n",
      "Classifier 32/50: error = 0.43897223142981523, alpha = 0.12266712283118594\n",
      "Classifier 33/50: error = 0.46010087027131963, alpha = 0.07996828831807301\n",
      "Classifier 34/50: error = 0.4442833217649924, alpha = 0.11189806090069711\n",
      "Classifier 35/50: error = 0.4577461578738249, alpha = 0.08470972257863846\n",
      "Classifier 36/50: error = 0.4579517351780671, alpha = 0.08429562503709662\n",
      "Classifier 37/50: error = 0.4580785586675884, alpha = 0.08404017691457906\n",
      "Classifier 38/50: error = 0.446350093049267, alpha = 0.10771447197157086\n",
      "Classifier 39/50: error = 0.45254779365076386, alpha = 0.0951908923062929\n",
      "Classifier 40/50: error = 0.45258973711881956, alpha = 0.09510624362614932\n",
      "Classifier 41/50: error = 0.46012721371668097, alpha = 0.07991526400401955\n",
      "Classifier 42/50: error = 0.4473923151445206, alpha = 0.10560622343248051\n",
      "Classifier 43/50: error = 0.42120964091842017, alpha = 0.15890483432535568\n",
      "Classifier 44/50: error = 0.44562691959004386, alpha = 0.10917789579947935\n",
      "Classifier 45/50: error = 0.45304047585421514, alpha = 0.0941966657030008\n",
      "Classifier 46/50: error = 0.45101194533278544, alpha = 0.09829142870417061\n",
      "Classifier 47/50: error = 0.45017728989413835, alpha = 0.09997719912083325\n",
      "Classifier 48/50: error = 0.4700257673573578, alpha = 0.06002043515946362\n",
      "Classifier 49/50: error = 0.4645948719062132, alpha = 0.07092896322541202\n",
      "Classifier 50/50: error = 0.45842132543195324, alpha = 0.08334983007407239\n",
      "Accuracy for digit 3: 0.8995\n",
      "Running AdaBoost for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.30916716596764515, alpha = 0.4020078773044001\n",
      "Classifier 2/50: error = 0.31807377644750484, alpha = 0.3813190589678485\n",
      "Classifier 3/50: error = 0.31102351138573936, alpha = 0.39766931884759293\n",
      "Classifier 4/50: error = 0.33652990609116307, alpha = 0.33939838013445234\n",
      "Classifier 5/50: error = 0.32852015514058386, alpha = 0.3574429045715893\n",
      "Classifier 6/50: error = 0.38241274614577936, alpha = 0.2396599238078403\n",
      "Classifier 7/50: error = 0.3283269921383627, alpha = 0.35788079373209125\n",
      "Classifier 8/50: error = 0.3311033859635888, alpha = 0.35159941953134816\n",
      "Classifier 9/50: error = 0.3780083095505917, alpha = 0.24900527741201767\n",
      "Classifier 10/50: error = 0.369022742656943, alpha = 0.2682057720878482\n",
      "Classifier 11/50: error = 0.3698118356978878, alpha = 0.2665120620306665\n",
      "Classifier 12/50: error = 0.3836664234257966, alpha = 0.23700742560752963\n",
      "Classifier 13/50: error = 0.4170309589161505, alpha = 0.1674868105259753\n",
      "Classifier 14/50: error = 0.39054408757123765, alpha = 0.22251287449928386\n",
      "Classifier 15/50: error = 0.3806115848486924, alpha = 0.24347658557047075\n",
      "Classifier 16/50: error = 0.39924183778369193, alpha = 0.2043125590688046\n",
      "Classifier 17/50: error = 0.4341835073183352, alpha = 0.13240126752320233\n",
      "Classifier 18/50: error = 0.40099101483411115, alpha = 0.20066878901969853\n",
      "Classifier 19/50: error = 0.43186502991663656, alpha = 0.13712295257246035\n",
      "Classifier 20/50: error = 0.3922268381986871, alpha = 0.21898069090885325\n",
      "Classifier 21/50: error = 0.4389980069980145, alpha = 0.12261479242901942\n",
      "Classifier 22/50: error = 0.42686137844055827, alpha = 0.1473341449858656\n",
      "Classifier 23/50: error = 0.4103741511430474, alpha = 0.1812094369281114\n",
      "Classifier 24/50: error = 0.4197057085125473, alpha = 0.16199080112427028\n",
      "Classifier 25/50: error = 0.4468638000553792, alpha = 0.1066752068402973\n",
      "Classifier 26/50: error = 0.43054942595511014, alpha = 0.13980493143683173\n",
      "Classifier 27/50: error = 0.43751258193151904, alpha = 0.1256316509073053\n",
      "Classifier 28/50: error = 0.4239416982683043, alpha = 0.15330646605117795\n",
      "Classifier 29/50: error = 0.42378573324250424, alpha = 0.15362580049251895\n",
      "Classifier 30/50: error = 0.45207495406364395, alpha = 0.0961452532036163\n",
      "Classifier 31/50: error = 0.44063604826586156, alpha = 0.1192905451826756\n",
      "Classifier 32/50: error = 0.43054952260181334, alpha = 0.13980473434075177\n",
      "Classifier 33/50: error = 0.44812343199685784, alpha = 0.10412785011199524\n",
      "Classifier 34/50: error = 0.44341107964902354, alpha = 0.11366482905038959\n",
      "Classifier 35/50: error = 0.4486872696515922, alpha = 0.10298803792088942\n",
      "Classifier 36/50: error = 0.4450696875785902, alpha = 0.11030583570391392\n",
      "Classifier 37/50: error = 0.4486562920631636, alpha = 0.10305065295656048\n",
      "Classifier 38/50: error = 0.4388098250440367, alpha = 0.12299686097889166\n",
      "Classifier 39/50: error = 0.45980987575300536, alpha = 0.0805540345167096\n",
      "Classifier 40/50: error = 0.46233521697922053, alpha = 0.07547254009751912\n",
      "Classifier 41/50: error = 0.45527827937997056, alpha = 0.08968311241325867\n",
      "Classifier 42/50: error = 0.4628428199725202, alpha = 0.07445161856977632\n",
      "Classifier 43/50: error = 0.474671079713429, alpha = 0.05070124040735945\n",
      "Classifier 44/50: error = 0.46561161086415004, alpha = 0.06888553075650738\n",
      "Classifier 45/50: error = 0.441323896777182, alpha = 0.11789540885926462\n",
      "Classifier 46/50: error = 0.4287136467434693, alpha = 0.1435506861311828\n",
      "Classifier 47/50: error = 0.434336819422074, alpha = 0.13208924948718678\n",
      "Classifier 48/50: error = 0.45758856575001383, alpha = 0.08502718244759803\n",
      "Classifier 49/50: error = 0.4559937648282273, alpha = 0.08824078633450134\n",
      "Classifier 50/50: error = 0.4479413299689752, alpha = 0.10449603146339179\n",
      "Accuracy for digit 4: 0.9025\n",
      "Running AdaBoost for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3888735123166343, alpha = 0.22602491276780973\n",
      "Classifier 2/50: error = 0.3796810799083881, alpha = 0.24545104799348968\n",
      "Classifier 3/50: error = 0.4024320998985895, alpha = 0.19767076544064904\n",
      "Classifier 4/50: error = 0.3710994706404753, alpha = 0.26375148077829247\n",
      "Classifier 5/50: error = 0.38994219146709885, alpha = 0.22377760977089733\n",
      "Classifier 6/50: error = 0.36953817768854114, alpha = 0.26709927219640517\n",
      "Classifier 7/50: error = 0.3977091357251852, alpha = 0.20750978421826297\n",
      "Classifier 8/50: error = 0.34124694550213264, alpha = 0.32887117048143977\n",
      "Classifier 9/50: error = 0.3835160624084615, alpha = 0.23732538216045204\n",
      "Classifier 10/50: error = 0.41899921902891957, alpha = 0.16344152247057855\n",
      "Classifier 11/50: error = 0.3459223744227967, alpha = 0.318505819656309\n",
      "Classifier 12/50: error = 0.38102307370295785, alpha = 0.2426040309618411\n",
      "Classifier 13/50: error = 0.3852297543879297, alpha = 0.23370434630020231\n",
      "Classifier 14/50: error = 0.43284960354019986, alpha = 0.13511709312814174\n",
      "Classifier 15/50: error = 0.42415112461818505, alpha = 0.15287771968329866\n",
      "Classifier 16/50: error = 0.40577468833660324, alpha = 0.19073025460347753\n",
      "Classifier 17/50: error = 0.40636931073092364, alpha = 0.1894975061055732\n",
      "Classifier 18/50: error = 0.4194222542465482, alpha = 0.1625727709431059\n",
      "Classifier 19/50: error = 0.42378412338056104, alpha = 0.15362909680608092\n",
      "Classifier 20/50: error = 0.45570280111428685, alpha = 0.08882728701632941\n",
      "Classifier 21/50: error = 0.42956538338151207, alpha = 0.14181229714766402\n",
      "Classifier 22/50: error = 0.4281130959620679, alpha = 0.1447769239903164\n",
      "Classifier 23/50: error = 0.436549954820471, alpha = 0.12758793288295753\n",
      "Classifier 24/50: error = 0.45285544759162055, alpha = 0.09457002857628467\n",
      "Classifier 25/50: error = 0.43784947619839587, alpha = 0.12494723013185496\n",
      "Classifier 26/50: error = 0.4324286837847934, alpha = 0.13597449447606638\n",
      "Classifier 27/50: error = 0.4462898320759414, alpha = 0.10783639927509124\n",
      "Classifier 28/50: error = 0.4361542184702918, alpha = 0.12839244207793607\n",
      "Classifier 29/50: error = 0.4275500942824373, alpha = 0.14592688474543963\n",
      "Classifier 30/50: error = 0.41228329214833803, alpha = 0.17726716349967503\n",
      "Classifier 31/50: error = 0.4320562825657335, alpha = 0.13673323062852694\n",
      "Classifier 32/50: error = 0.4136745161776347, alpha = 0.17439779832393906\n",
      "Classifier 33/50: error = 0.4603624277360787, alpha = 0.07944184303772478\n",
      "Classifier 34/50: error = 0.4403369705182724, alpha = 0.11989729680327589\n",
      "Classifier 35/50: error = 0.4545215066984136, alpha = 0.09120907341557398\n",
      "Classifier 36/50: error = 0.453763457615434, alpha = 0.09273803295311442\n",
      "Classifier 37/50: error = 0.44851682977707086, alpha = 0.10333255821835084\n",
      "Classifier 38/50: error = 0.446792088951256, alpha = 0.10682026957336879\n",
      "Classifier 39/50: error = 0.46309724344654146, alpha = 0.07393996525649255\n",
      "Classifier 40/50: error = 0.4596096717625787, alpha = 0.08095705942811912\n",
      "Classifier 41/50: error = 0.4475956702176819, alpha = 0.10519497826468327\n",
      "Classifier 42/50: error = 0.43730615342747414, alpha = 0.12605108053022632\n",
      "Classifier 43/50: error = 0.46048600493176756, alpha = 0.07919313046816011\n",
      "Classifier 44/50: error = 0.44777905851328814, alpha = 0.10482414233319066\n",
      "Classifier 45/50: error = 0.4514751455096472, alpha = 0.09735613478883628\n",
      "Classifier 46/50: error = 0.458194820844269, alpha = 0.08380601102286195\n",
      "Classifier 47/50: error = 0.4651719354743684, alpha = 0.06976911477201099\n",
      "Classifier 48/50: error = 0.46543151097035024, alpha = 0.0692474514996305\n",
      "Classifier 49/50: error = 0.462374802639688, alpha = 0.07539291742900003\n",
      "Classifier 50/50: error = 0.4716176413537183, alpha = 0.056825805145887906\n",
      "Accuracy for digit 5: 0.8737\n",
      "Running AdaBoost for digit: 6\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2622770687177751, alpha = 0.5170834314094018\n",
      "Classifier 2/50: error = 0.27973856205056324, alpha = 0.4728793970578081\n",
      "Classifier 3/50: error = 0.30444137009918687, alpha = 0.4131183913840453\n",
      "Classifier 4/50: error = 0.3407574344797131, alpha = 0.3299603297611685\n",
      "Classifier 5/50: error = 0.2640595321750077, alpha = 0.512487325359739\n",
      "Classifier 6/50: error = 0.331043752535589, alpha = 0.3517340542023011\n",
      "Classifier 7/50: error = 0.320356859316718, alpha = 0.3760661536694937\n",
      "Classifier 8/50: error = 0.35561212715365853, alpha = 0.2972301126448939\n",
      "Classifier 9/50: error = 0.3894607764121752, alpha = 0.22478969093142315\n",
      "Classifier 10/50: error = 0.2969842069840738, alpha = 0.4308501971424071\n",
      "Classifier 11/50: error = 0.3738896006336109, alpha = 0.2577830719457714\n",
      "Classifier 12/50: error = 0.3894495402085535, alpha = 0.2248133182576831\n",
      "Classifier 13/50: error = 0.3844076318724711, alpha = 0.2354407367254079\n",
      "Classifier 14/50: error = 0.39193500593208397, alpha = 0.21959287472501895\n",
      "Classifier 15/50: error = 0.42339959303339386, alpha = 0.15441654671605132\n",
      "Classifier 16/50: error = 0.3651691592083759, alpha = 0.2764989373623683\n",
      "Classifier 17/50: error = 0.40419610310904064, alpha = 0.19400570842729786\n",
      "Classifier 18/50: error = 0.39532681053145735, alpha = 0.21248766902040295\n",
      "Classifier 19/50: error = 0.4264809743202368, alpha = 0.1481116767829807\n",
      "Classifier 20/50: error = 0.37296920056105, alpha = 0.2597499086089437\n",
      "Classifier 21/50: error = 0.4026521586167423, alpha = 0.1972132666343145\n",
      "Classifier 22/50: error = 0.3808230128047031, alpha = 0.24302821111241385\n",
      "Classifier 23/50: error = 0.4241408476174929, alpha = 0.15289875788576113\n",
      "Classifier 24/50: error = 0.37668871250832925, alpha = 0.251813451340452\n",
      "Classifier 25/50: error = 0.4273615008689009, alpha = 0.14631218234037022\n",
      "Classifier 26/50: error = 0.4305745939458789, alpha = 0.13975360555676447\n",
      "Classifier 27/50: error = 0.412951598127024, alpha = 0.17588844121229982\n",
      "Classifier 28/50: error = 0.3988275622397742, alpha = 0.20517633136510546\n",
      "Classifier 29/50: error = 0.41970208923484087, alpha = 0.16199823130291463\n",
      "Classifier 30/50: error = 0.3992265260283676, alpha = 0.20434447900778338\n",
      "Classifier 31/50: error = 0.4216236324015483, alpha = 0.15805588098686413\n",
      "Classifier 32/50: error = 0.45597222567533446, alpha = 0.0882842011041783\n",
      "Classifier 33/50: error = 0.449456419325208, alpha = 0.10143361153457608\n",
      "Classifier 34/50: error = 0.41873942762911764, alpha = 0.1639751551634245\n",
      "Classifier 35/50: error = 0.4321529665313139, alpha = 0.13653623018025843\n",
      "Classifier 36/50: error = 0.4318740483058521, alpha = 0.13710457456892786\n",
      "Classifier 37/50: error = 0.4295320367913722, alpha = 0.14188034124394025\n",
      "Classifier 38/50: error = 0.4394606232454844, alpha = 0.12167568711352178\n",
      "Classifier 39/50: error = 0.4143918849791056, alpha = 0.17291935596201244\n",
      "Classifier 40/50: error = 0.4245719747816705, alpha = 0.15201630610909725\n",
      "Classifier 41/50: error = 0.44874943310082194, alpha = 0.10286238929550431\n",
      "Classifier 42/50: error = 0.4178481105428159, alpha = 0.16580669874083145\n",
      "Classifier 43/50: error = 0.42285618729139895, alpha = 0.15552966952106295\n",
      "Classifier 44/50: error = 0.46039091766672, alpha = 0.07938450307965103\n",
      "Classifier 45/50: error = 0.4270436150880408, alpha = 0.14696172280012632\n",
      "Classifier 46/50: error = 0.4367818510068691, alpha = 0.12711657768659462\n",
      "Classifier 47/50: error = 0.44835300223551333, alpha = 0.10366373565188518\n",
      "Classifier 48/50: error = 0.4346140565113008, alpha = 0.13152508642871213\n",
      "Classifier 49/50: error = 0.4412888395716036, alpha = 0.11796650293036215\n",
      "Classifier 50/50: error = 0.466362248130896, alpha = 0.06737727640350247\n",
      "Accuracy for digit 6: 0.9506\n",
      "Running AdaBoost for digit: 7\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Classifier 1/50: error = 0.34240561896400346, alpha = 0.3262961221267729\n",
      "Classifier 2/50: error = 0.30196299028705165, alpha = 0.4189838312667094\n",
      "Classifier 3/50: error = 0.35317228241290577, alpha = 0.30256199501638437\n",
      "Classifier 4/50: error = 0.2960536820646279, alpha = 0.4330806519575683\n",
      "Classifier 5/50: error = 0.3603167893410771, alpha = 0.28699472772365325\n",
      "Classifier 6/50: error = 0.28551678162077787, alpha = 0.45862935126737336\n",
      "Classifier 7/50: error = 0.3279815949146988, alpha = 0.35866411738349524\n",
      "Classifier 8/50: error = 0.34587784078618844, alpha = 0.31860423513084013\n",
      "Classifier 9/50: error = 0.37028428095908805, alpha = 0.26549872013739206\n",
      "Classifier 10/50: error = 0.34524069607242047, alpha = 0.32001292474753845\n",
      "Classifier 11/50: error = 0.36485965065614534, alpha = 0.27716661802849957\n",
      "Classifier 12/50: error = 0.34664775371689927, alpha = 0.31690363300068036\n",
      "Classifier 13/50: error = 0.3361844130656228, alpha = 0.34017226121212346\n",
      "Classifier 14/50: error = 0.306925056979231, alpha = 0.40726726616806347\n",
      "Classifier 15/50: error = 0.3679725956434654, alpha = 0.2704621436904991\n",
      "Classifier 16/50: error = 0.41511460978325987, alpha = 0.17143063177655066\n",
      "Classifier 17/50: error = 0.4085726206828833, alpha = 0.1849346147646595\n",
      "Classifier 18/50: error = 0.39547232189147685, alpha = 0.21218332675785426\n",
      "Classifier 19/50: error = 0.41265354454488334, alpha = 0.17650324682828453\n",
      "Classifier 20/50: error = 0.416251588568217, alpha = 0.16909011496349804\n",
      "Classifier 21/50: error = 0.4099239787342975, alpha = 0.1821398266713194\n",
      "Classifier 22/50: error = 0.428802406216799, alpha = 0.14336948857001788\n",
      "Classifier 23/50: error = 0.40006778223751704, alpha = 0.20259134500478973\n",
      "Classifier 24/50: error = 0.4451765665198195, alpha = 0.11008947152264585\n",
      "Classifier 25/50: error = 0.43243046965338183, alpha = 0.13597085629460612\n",
      "Classifier 26/50: error = 0.4248916886625411, alpha = 0.15136205215077309\n",
      "Classifier 27/50: error = 0.41743635493106357, alpha = 0.16665317596643114\n",
      "Classifier 28/50: error = 0.4089519280547378, alpha = 0.1841498701076255\n",
      "Classifier 29/50: error = 0.4398577563067758, alpha = 0.12086968224823412\n",
      "Classifier 30/50: error = 0.4405549287105478, alpha = 0.11945510718237336\n",
      "Classifier 31/50: error = 0.4305767928529561, alpha = 0.13974912129072692\n",
      "Classifier 32/50: error = 0.4054529526556349, alpha = 0.19139750340510017\n",
      "Classifier 33/50: error = 0.44361600980314386, alpha = 0.11324967011303792\n",
      "Classifier 34/50: error = 0.4253002739871705, alpha = 0.15052612111198074\n",
      "Classifier 35/50: error = 0.4288033815996144, alpha = 0.14336749743184757\n",
      "Classifier 36/50: error = 0.44098798344782963, alpha = 0.11857667136685254\n",
      "Classifier 37/50: error = 0.422284098857455, alpha = 0.15670195984590723\n",
      "Classifier 38/50: error = 0.43648651654098847, alpha = 0.12771688816742907\n",
      "Classifier 39/50: error = 0.4624563620746507, alpha = 0.07522887164200001\n",
      "Classifier 40/50: error = 0.4596810297108054, alpha = 0.08081340778595927\n",
      "Classifier 41/50: error = 0.43730807828973073, alpha = 0.12604716931519125\n",
      "Classifier 42/50: error = 0.4412385744442142, alpha = 0.11806843989580885\n",
      "Classifier 43/50: error = 0.44991001403990216, alpha = 0.1005171408360325\n",
      "Classifier 44/50: error = 0.45639944054758996, alpha = 0.0874231596050533\n",
      "Classifier 45/50: error = 0.4551527849506053, alpha = 0.08993613113988748\n",
      "Classifier 46/50: error = 0.46667256685359093, alpha = 0.06675384325414772\n",
      "Classifier 47/50: error = 0.4609501527052161, alpha = 0.078259069569804\n",
      "Classifier 48/50: error = 0.4637717620798659, alpha = 0.07258367414204756\n",
      "Classifier 49/50: error = 0.44156976480054677, alpha = 0.11739683541846396\n",
      "Classifier 50/50: error = 0.46023066675885616, alpha = 0.07970703716375352\n",
      "Accuracy for digit 7: 0.9388\n",
      "Running AdaBoost for digit: 8\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Classifier 1/50: error = 0.32236560977694206, alpha = 0.37146077967820823\n",
      "Classifier 2/50: error = 0.36427857147463616, alpha = 0.278420790309496\n",
      "Classifier 3/50: error = 0.33714133506071653, alpha = 0.3380297789787379\n",
      "Classifier 4/50: error = 0.29333878081866566, alpha = 0.4396115902293786\n",
      "Classifier 5/50: error = 0.3491476575772167, alpha = 0.3113939397271359\n",
      "Classifier 6/50: error = 0.40789617638166953, alpha = 0.18633466239801447\n",
      "Classifier 7/50: error = 0.3874941012123257, alpha = 0.22892897347589522\n",
      "Classifier 8/50: error = 0.3644153890223161, alpha = 0.2781254134143783\n",
      "Classifier 9/50: error = 0.41172401957005866, alpha = 0.17842146135119757\n",
      "Classifier 10/50: error = 0.4041965410665269, alpha = 0.19400479912890936\n",
      "Classifier 11/50: error = 0.39759360596253224, alpha = 0.20775094877296246\n",
      "Classifier 12/50: error = 0.42892760652580475, alpha = 0.14311391494902923\n",
      "Classifier 13/50: error = 0.4331772100738511, alpha = 0.1344499047956306\n",
      "Classifier 14/50: error = 0.43432919269828746, alpha = 0.13210477065339865\n",
      "Classifier 15/50: error = 0.4211823176914187, alpha = 0.15896087279137358\n",
      "Classifier 16/50: error = 0.4344143387093056, alpha = 0.1319314933646724\n",
      "Classifier 17/50: error = 0.4481043032990294, alpha = 0.10416652397420878\n",
      "Classifier 18/50: error = 0.44441195950399204, alpha = 0.11163755811991391\n",
      "Classifier 19/50: error = 0.43595246614745314, alpha = 0.12880265648348213\n",
      "Classifier 20/50: error = 0.46210187780900913, alpha = 0.075941898366177\n",
      "Classifier 21/50: error = 0.4449547703396388, alpha = 0.11053848397524588\n",
      "Classifier 22/50: error = 0.44838496756860496, alpha = 0.10359911594270373\n",
      "Classifier 23/50: error = 0.4442889102872532, alpha = 0.11188674333562079\n",
      "Classifier 24/50: error = 0.436495801068292, alpha = 0.12769801461654992\n",
      "Classifier 25/50: error = 0.42851150840340624, alpha = 0.1439633753451074\n",
      "Classifier 26/50: error = 0.45358702965022957, alpha = 0.09309394400360241\n",
      "Classifier 27/50: error = 0.4496956825328635, alpha = 0.10095016834821649\n",
      "Classifier 28/50: error = 0.4347092541633941, alpha = 0.13133138337364486\n",
      "Classifier 29/50: error = 0.4360778990686929, alpha = 0.1285476140060134\n",
      "Classifier 30/50: error = 0.4573304813711318, alpha = 0.08554711488772972\n",
      "Classifier 31/50: error = 0.4646944892789666, alpha = 0.0707287273007594\n",
      "Classifier 32/50: error = 0.43968688943918166, alpha = 0.1212164473728548\n",
      "Classifier 33/50: error = 0.43318391653003896, alpha = 0.13443624798145393\n",
      "Classifier 34/50: error = 0.4623315453781091, alpha = 0.07547992521097341\n",
      "Classifier 35/50: error = 0.4499656553633117, alpha = 0.10040473129679645\n",
      "Classifier 36/50: error = 0.4558448282209613, alpha = 0.08854099288677868\n",
      "Classifier 37/50: error = 0.4756312780709438, alpha = 0.04877608824728113\n",
      "Classifier 38/50: error = 0.4584748170354466, alpha = 0.083242102875917\n",
      "Classifier 39/50: error = 0.45075146048313197, alpha = 0.09881747498774701\n",
      "Classifier 40/50: error = 0.4632156311615792, alpha = 0.07370189716500297\n",
      "Classifier 41/50: error = 0.44651921076650614, alpha = 0.10737230954029249\n",
      "Classifier 42/50: error = 0.4606939884741146, alpha = 0.07877456298778152\n",
      "Classifier 43/50: error = 0.4406916661657274, alpha = 0.11917772045970579\n",
      "Classifier 44/50: error = 0.4661339034641504, alpha = 0.06783605629928027\n",
      "Classifier 45/50: error = 0.461281505218693, alpha = 0.07759233214670752\n",
      "Classifier 46/50: error = 0.4566067160808742, alpha = 0.08700544731554496\n",
      "Classifier 47/50: error = 0.4634922858396948, alpha = 0.07314559951392008\n",
      "Classifier 48/50: error = 0.4643017761567374, alpha = 0.07151813340125546\n",
      "Classifier 49/50: error = 0.4702956840812311, alpha = 0.05947867219388207\n",
      "Classifier 50/50: error = 0.4506476503189435, alpha = 0.09902713364672433\n",
      "Accuracy for digit 8: 0.8799\n",
      "Running AdaBoost for digit: 9\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Classifier 1/50: error = 0.32820642124726856, alpha = 0.35815418759820056\n",
      "Classifier 2/50: error = 0.3654313721792137, alpha = 0.27593347215957115\n",
      "Classifier 3/50: error = 0.33643415891556316, alpha = 0.3396128080934544\n",
      "Classifier 4/50: error = 0.3865243907709722, alpha = 0.2309727668447036\n",
      "Classifier 5/50: error = 0.39229132281898, alpha = 0.21884544172055984\n",
      "Classifier 6/50: error = 0.3842474284093127, alpha = 0.23577926167329094\n",
      "Classifier 7/50: error = 0.3828131944600608, alpha = 0.2388123074786735\n",
      "Classifier 8/50: error = 0.37070786866658145, alpha = 0.2645906250320867\n",
      "Classifier 9/50: error = 0.3357135873474161, alpha = 0.3412275114220886\n",
      "Classifier 10/50: error = 0.41466907544422726, alpha = 0.17234828833065247\n",
      "Classifier 11/50: error = 0.38753639870621054, alpha = 0.22883986878603102\n",
      "Classifier 12/50: error = 0.429630147452877, alpha = 0.141680149049985\n",
      "Classifier 13/50: error = 0.41897214866616617, alpha = 0.1634971228893217\n",
      "Classifier 14/50: error = 0.38476522965402243, alpha = 0.23468529004143937\n",
      "Classifier 15/50: error = 0.4308718047807053, alpha = 0.13914754934605217\n",
      "Classifier 16/50: error = 0.4276647575517102, alpha = 0.14569264796122522\n",
      "Classifier 17/50: error = 0.4371160506458436, alpha = 0.1264373779243741\n",
      "Classifier 18/50: error = 0.4554463242471612, alpha = 0.08934432248728566\n",
      "Classifier 19/50: error = 0.44491124051984154, alpha = 0.11062661257028356\n",
      "Classifier 20/50: error = 0.42345488854304225, alpha = 0.1543032996509691\n",
      "Classifier 21/50: error = 0.44253504962567647, alpha = 0.1154399812614028\n",
      "Classifier 22/50: error = 0.4303604034081636, alpha = 0.1401904345071294\n",
      "Classifier 23/50: error = 0.41714621200277113, alpha = 0.16724978686199846\n",
      "Classifier 24/50: error = 0.4200954300469775, alpha = 0.16119082775405888\n",
      "Classifier 25/50: error = 0.4212528079045704, alpha = 0.15881630317996112\n",
      "Classifier 26/50: error = 0.4528617793113917, alpha = 0.0945572515587527\n",
      "Classifier 27/50: error = 0.45241008130905513, alpha = 0.09546882758236155\n",
      "Classifier 28/50: error = 0.4334124535860615, alpha = 0.13397089214237765\n",
      "Classifier 29/50: error = 0.4624433914010365, alpha = 0.07525496012952108\n",
      "Classifier 30/50: error = 0.4497415070780342, alpha = 0.10085758295294228\n",
      "Classifier 31/50: error = 0.44497631803893445, alpha = 0.1104948600657819\n",
      "Classifier 32/50: error = 0.45298155564707043, alpha = 0.09431555614094109\n",
      "Classifier 33/50: error = 0.4654469785017112, alpha = 0.06921636792633742\n",
      "Classifier 34/50: error = 0.4304900867403048, alpha = 0.13992594667283947\n",
      "Classifier 35/50: error = 0.46382174250450925, alpha = 0.07248318646589774\n",
      "Classifier 36/50: error = 0.4350417502893933, alpha = 0.13065491494293233\n",
      "Classifier 37/50: error = 0.4313340229391822, alpha = 0.1382052207433838\n",
      "Classifier 38/50: error = 0.47012277825841947, alpha = 0.059825715833855236\n",
      "Classifier 39/50: error = 0.44296984502467285, alpha = 0.11455883940268807\n",
      "Classifier 40/50: error = 0.45036310626929854, alpha = 0.0996018533660176\n",
      "Classifier 41/50: error = 0.44519214287857145, alpha = 0.11005793982504539\n",
      "Classifier 42/50: error = 0.4471558991843653, alpha = 0.1060843724165281\n",
      "Classifier 43/50: error = 0.4543938701927501, alpha = 0.09146648199503751\n",
      "Classifier 44/50: error = 0.4441362266130048, alpha = 0.1121959601107754\n",
      "Classifier 45/50: error = 0.43652240074670845, alpha = 0.12764394339494872\n",
      "Classifier 46/50: error = 0.45529103942907234, alpha = 0.08965738656365652\n",
      "Classifier 47/50: error = 0.4678285503824532, alpha = 0.06443191382690575\n",
      "Classifier 48/50: error = 0.46268669743132773, alpha = 0.07476560497709536\n",
      "Classifier 49/50: error = 0.4563503068138476, alpha = 0.08752218088263004\n",
      "Classifier 50/50: error = 0.454391258059264, alpha = 0.09147175009339216\n",
      "Accuracy for digit 9: 0.8661\n",
      "Accuracies for all digits: {0: 0.9609, 1: 0.9639, 2: 0.91, 3: 0.8995, 4: 0.9025, 5: 0.8737, 6: 0.9506, 7: 0.9388, 8: 0.8799, 9: 0.8661}\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = run_adaboost_for_all_digits(T=50, A=50, verboseParam=True) # Ejecutamos AdaBoost para todos los dgitos\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Classifier 1/50: error = 0.22608695652173919, alpha = 0.6152699156987816\n",
      "Classifier 2/50: error = 0.30183308020289334, alpha = 0.4192920320417054\n",
      "Classifier 3/50: error = 0.19549038530040463, alpha = 0.7073608594780536\n",
      "Classifier 4/50: error = 0.3261160058515066, alpha = 0.36290240809753027\n",
      "Classifier 5/50: error = 0.2700381241115829, alpha = 0.49721457914557854\n",
      "Classifier 6/50: error = 0.2547486560044247, alpha = 0.5367220696840952\n",
      "Classifier 7/50: error = 0.2868659165721218, alpha = 0.4553272704379755\n",
      "Classifier 8/50: error = 0.4242603001388516, alpha = 0.15265423312185747\n",
      "Classifier 9/50: error = 0.373951667640087, alpha = 0.2576505090500228\n",
      "Classifier 10/50: error = 0.35361074931667325, alpha = 0.3016025737378443\n",
      "Classifier 11/50: error = 0.42265260336412724, alpha = 0.15594679309277928\n",
      "Classifier 12/50: error = 0.36754733682857565, alpha = 0.27137662939830576\n",
      "Classifier 13/50: error = 0.36137649351483647, alpha = 0.28469737784585025\n",
      "Classifier 14/50: error = 0.42860835895581856, alpha = 0.1437656374739474\n",
      "Classifier 15/50: error = 0.3925388709276737, alpha = 0.2183263107408885\n",
      "Classifier 16/50: error = 0.4567766397203925, alpha = 0.08666303107483597\n",
      "Classifier 17/50: error = 0.4313101050037607, alpha = 0.1382539764707683\n",
      "Classifier 18/50: error = 0.32153813232957584, alpha = 0.37335606620136547\n",
      "Classifier 19/50: error = 0.42787271337223265, alpha = 0.14526787147371775\n",
      "Classifier 20/50: error = 0.4055675568204541, alpha = 0.1911598061327171\n",
      "Classifier 21/50: error = 0.41609141563848073, alpha = 0.16941972581401477\n",
      "Classifier 22/50: error = 0.37685115854756446, alpha = 0.25146754820404627\n",
      "Classifier 23/50: error = 0.41287705613763614, alpha = 0.17604218923886636\n",
      "Classifier 24/50: error = 0.4223458514397019, alpha = 0.15657539953402105\n",
      "Classifier 25/50: error = 0.43537387377158443, alpha = 0.12997932334336545\n",
      "Classifier 26/50: error = 0.4603280529747346, alpha = 0.0795110277321444\n",
      "Classifier 27/50: error = 0.3959051472470714, alpha = 0.2112782855451909\n",
      "Classifier 28/50: error = 0.3967905694874496, alpha = 0.2094279209542605\n",
      "Classifier 29/50: error = 0.44684095571443655, alpha = 0.10672141764320749\n",
      "Classifier 30/50: error = 0.40891583642146173, alpha = 0.18422453000355665\n",
      "Classifier 31/50: error = 0.4481016375620396, alpha = 0.1041719135107789\n",
      "Classifier 32/50: error = 0.43199638834108367, alpha = 0.13685527465617034\n",
      "Classifier 33/50: error = 0.4382305349306086, alpha = 0.12417322690761576\n",
      "Classifier 34/50: error = 0.44242438002192574, alpha = 0.11566428903353579\n",
      "Classifier 35/50: error = 0.43323941704619795, alpha = 0.13432323040744948\n",
      "Classifier 36/50: error = 0.4313427655757741, alpha = 0.138187399401315\n",
      "Classifier 37/50: error = 0.4482700549599805, alpha = 0.103831422235004\n",
      "Classifier 38/50: error = 0.4387185101714399, alpha = 0.12318227175810337\n",
      "Classifier 39/50: error = 0.44671137510779724, alpha = 0.10698354909733183\n",
      "Classifier 40/50: error = 0.4593675807267351, alpha = 0.0814444410163825\n",
      "Classifier 41/50: error = 0.4747147628778111, alpha = 0.05061364968927417\n",
      "Classifier 42/50: error = 0.45967030187356417, alpha = 0.08083500392622027\n",
      "Classifier 43/50: error = 0.4526926741176749, alpha = 0.09489850592521863\n",
      "Classifier 44/50: error = 0.4284748319788251, alpha = 0.14403825979905088\n",
      "Classifier 45/50: error = 0.443928693637038, alpha = 0.11261629260906238\n",
      "Classifier 46/50: error = 0.4363188665831295, alpha = 0.12805770193193713\n",
      "Classifier 47/50: error = 0.42586377036624434, alpha = 0.14937359735137887\n",
      "Classifier 48/50: error = 0.4420562022549184, alpha = 0.11641060397876665\n",
      "Classifier 49/50: error = 0.4605757807361207, alpha = 0.07901245301411003\n",
      "Classifier 50/50: error = 0.4514954881314496, alpha = 0.09731506286548193\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2192390417562855, alpha = 0.6350531909275953\n",
      "Classifier 2/50: error = 0.3470614676054282, alpha = 0.31599054464127524\n",
      "Classifier 3/50: error = 0.27938422499433296, alpha = 0.4737590522028901\n",
      "Classifier 4/50: error = 0.33566929574793947, alpha = 0.3413268187398625\n",
      "Classifier 5/50: error = 0.3509463836795672, alpha = 0.3074409340787567\n",
      "Classifier 6/50: error = 0.30166043507729223, alpha = 0.4197017346804545\n",
      "Classifier 7/50: error = 0.34396383792653684, alpha = 0.32283969142868113\n",
      "Classifier 8/50: error = 0.3846999282910506, alpha = 0.23482322341805634\n",
      "Classifier 9/50: error = 0.3341650803083045, alpha = 0.344703324020913\n",
      "Classifier 10/50: error = 0.33023731169969284, alpha = 0.3535559652733073\n",
      "Classifier 11/50: error = 0.4278613032431674, alpha = 0.14529117677753453\n",
      "Classifier 12/50: error = 0.3632078403891845, alpha = 0.2807340443491876\n",
      "Classifier 13/50: error = 0.2805554729068531, alpha = 0.4708539770544076\n",
      "Classifier 14/50: error = 0.299932460801525, alpha = 0.4238097480594233\n",
      "Classifier 15/50: error = 0.4149924636058233, alpha = 0.17168218486204856\n",
      "Classifier 16/50: error = 0.3389015949718862, alpha = 0.334096458333853\n",
      "Classifier 17/50: error = 0.3620374530225493, alpha = 0.28326595492141066\n",
      "Classifier 18/50: error = 0.42105340614181785, alpha = 0.1592252767932102\n",
      "Classifier 19/50: error = 0.416042728430412, alpha = 0.16951992370102603\n",
      "Classifier 20/50: error = 0.37031049853730347, alpha = 0.26544250200260183\n",
      "Classifier 21/50: error = 0.37679492699949124, alpha = 0.2515872777143803\n",
      "Classifier 22/50: error = 0.4095691370879062, alpha = 0.1828734122226802\n",
      "Classifier 23/50: error = 0.4329831050330879, alpha = 0.13484519575354484\n",
      "Classifier 24/50: error = 0.414153182276614, alpha = 0.17341122062141803\n",
      "Classifier 25/50: error = 0.4147835888670979, alpha = 0.172112400353222\n",
      "Classifier 26/50: error = 0.3894449893238079, alpha = 0.22482288786246118\n",
      "Classifier 27/50: error = 0.4383723346706224, alpha = 0.12388524232707104\n",
      "Classifier 28/50: error = 0.4225543407743445, alpha = 0.156148142791015\n",
      "Classifier 29/50: error = 0.44318712614345157, alpha = 0.11411857117818067\n",
      "Classifier 30/50: error = 0.40465344371223466, alpha = 0.1930563385994554\n",
      "Classifier 31/50: error = 0.4284272563473611, alpha = 0.144135400207377\n",
      "Classifier 32/50: error = 0.446881073325756, alpha = 0.10664026581000642\n",
      "Classifier 33/50: error = 0.45270200143826567, alpha = 0.09487968281404403\n",
      "Classifier 34/50: error = 0.4481891514146594, alpha = 0.1039949828091696\n",
      "Classifier 35/50: error = 0.43426043735220166, alpha = 0.13224469770194844\n",
      "Classifier 36/50: error = 0.447790120444432, alpha = 0.10480177453222365\n",
      "Classifier 37/50: error = 0.42121134781935443, alpha = 0.15890133359637987\n",
      "Classifier 38/50: error = 0.43278051357534775, alpha = 0.13525781380727034\n",
      "Classifier 39/50: error = 0.40039838432244723, alpha = 0.20190272422997677\n",
      "Classifier 40/50: error = 0.4676409908806777, alpha = 0.06480860142989425\n",
      "Classifier 41/50: error = 0.45082742590255565, alpha = 0.09866405804230445\n",
      "Classifier 42/50: error = 0.44248020472492766, alpha = 0.11555114075735191\n",
      "Classifier 43/50: error = 0.45327126817210006, alpha = 0.09373099362709704\n",
      "Classifier 44/50: error = 0.44579760564829246, alpha = 0.10883245136158852\n",
      "Classifier 45/50: error = 0.43153164483355444, alpha = 0.13780240160278023\n",
      "Classifier 46/50: error = 0.4419744981985883, alpha = 0.11657623970654976\n",
      "Classifier 47/50: error = 0.43864371721389717, alpha = 0.12333414180245998\n",
      "Classifier 48/50: error = 0.4482070417752742, alpha = 0.10395881385952407\n",
      "Classifier 49/50: error = 0.44679977655812725, alpha = 0.10680471827710553\n",
      "Classifier 50/50: error = 0.41699933236254433, alpha = 0.167551855354414\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Classifier 1/50: error = 0.33383685800604235, alpha = 0.3454410868898294\n",
      "Classifier 2/50: error = 0.32019531459383876, alpha = 0.37643718084831046\n",
      "Classifier 3/50: error = 0.34566321670493594, alpha = 0.3190786195163977\n",
      "Classifier 4/50: error = 0.3618903165737645, alpha = 0.2835845065105109\n",
      "Classifier 5/50: error = 0.28806905745944644, alpha = 0.4523903407248115\n",
      "Classifier 6/50: error = 0.3432307857527038, alpha = 0.3244648094467225\n",
      "Classifier 7/50: error = 0.41157330953297044, alpha = 0.17873259625244697\n",
      "Classifier 8/50: error = 0.3661172467159805, alpha = 0.27445518858559637\n",
      "Classifier 9/50: error = 0.3667703910594987, alpha = 0.2730485363900999\n",
      "Classifier 10/50: error = 0.3822265547989103, alpha = 0.2400541442118353\n",
      "Classifier 11/50: error = 0.39707726245206065, alpha = 0.20882909041432768\n",
      "Classifier 12/50: error = 0.368678852014735, alpha = 0.2689443692279753\n",
      "Classifier 13/50: error = 0.41835339793527215, alpha = 0.16476826267461073\n",
      "Classifier 14/50: error = 0.4079740654603008, alpha = 0.1861734174283983\n",
      "Classifier 15/50: error = 0.43929091327083863, alpha = 0.1220201713950878\n",
      "Classifier 16/50: error = 0.41501513233931075, alpha = 0.17163549827322858\n",
      "Classifier 17/50: error = 0.4343377910224782, alpha = 0.1320872721851196\n",
      "Classifier 18/50: error = 0.4048958882520204, alpha = 0.19255319993628223\n",
      "Classifier 19/50: error = 0.44071432974830316, alpha = 0.1191317466948008\n",
      "Classifier 20/50: error = 0.4126615625607466, alpha = 0.17648670605807082\n",
      "Classifier 21/50: error = 0.42117233916843344, alpha = 0.15898133845102375\n",
      "Classifier 22/50: error = 0.4080435940565479, alpha = 0.18602948830663046\n",
      "Classifier 23/50: error = 0.4248208418197198, alpha = 0.15150702013033368\n",
      "Classifier 24/50: error = 0.40256702969593217, alpha = 0.19739023872028116\n",
      "Classifier 25/50: error = 0.45552832843571817, alpha = 0.0891790038751011\n",
      "Classifier 26/50: error = 0.43772053045503756, alpha = 0.12520917730179298\n",
      "Classifier 27/50: error = 0.43814168108677953, alpha = 0.1243536928056627\n",
      "Classifier 28/50: error = 0.4161390427380349, alpha = 0.16932171288218512\n",
      "Classifier 29/50: error = 0.4465654661087973, alpha = 0.10727872914884294\n",
      "Classifier 30/50: error = 0.4642061093568144, alpha = 0.07171044995511439\n",
      "Classifier 31/50: error = 0.46133556947557597, alpha = 0.07748355224606854\n",
      "Classifier 32/50: error = 0.4636288482451163, alpha = 0.07287101629957299\n",
      "Classifier 33/50: error = 0.43956281049419266, alpha = 0.12146827710149749\n",
      "Classifier 34/50: error = 0.4645969689944297, alpha = 0.07092474791427222\n",
      "Classifier 35/50: error = 0.4549754216630706, alpha = 0.09029374615349542\n",
      "Classifier 36/50: error = 0.4499063110462197, alpha = 0.10052462190919709\n",
      "Classifier 37/50: error = 0.43835247680352274, alpha = 0.12392557092579201\n",
      "Classifier 38/50: error = 0.4548301509920443, alpha = 0.09058667044691557\n",
      "Classifier 39/50: error = 0.4706525492497009, alpha = 0.0587624442598437\n",
      "Classifier 40/50: error = 0.4751215566315732, alpha = 0.049798009664117696\n",
      "Classifier 41/50: error = 0.45168960049908846, alpha = 0.09692316481495124\n",
      "Classifier 42/50: error = 0.4467993089773761, alpha = 0.10680566414694638\n",
      "Classifier 43/50: error = 0.4650264683112241, alpha = 0.0700614735491476\n",
      "Classifier 44/50: error = 0.4567350974417159, alpha = 0.08674674180688124\n",
      "Classifier 45/50: error = 0.46297442416914625, alpha = 0.07418695370274397\n",
      "Classifier 46/50: error = 0.4553334315106643, alpha = 0.08957191969233425\n",
      "Classifier 47/50: error = 0.4421576959874609, alpha = 0.11620485819835306\n",
      "Classifier 48/50: error = 0.4691598553984575, alpha = 0.06175868825303161\n",
      "Classifier 49/50: error = 0.43974830296899126, alpha = 0.12109180857944425\n",
      "Classifier 50/50: error = 0.46505761329212636, alpha = 0.06999887760360265\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.28597063621533436, alpha = 0.4575174760300126\n",
      "Classifier 2/50: error = 0.3783112562343167, alpha = 0.2483611347282499\n",
      "Classifier 3/50: error = 0.4271793936100291, alpha = 0.14668426961582437\n",
      "Classifier 4/50: error = 0.31955731426496126, alpha = 0.3779034747618132\n",
      "Classifier 5/50: error = 0.395310279207019, alpha = 0.21252224733458072\n",
      "Classifier 6/50: error = 0.365023116135648, alpha = 0.2768139556473892\n",
      "Classifier 7/50: error = 0.35954430778468804, alpha = 0.28867126201410576\n",
      "Classifier 8/50: error = 0.3314736059568836, alpha = 0.3507638458409054\n",
      "Classifier 9/50: error = 0.4117406020698674, alpha = 0.17838722952564703\n",
      "Classifier 10/50: error = 0.46077470474309296, alpha = 0.07861212869019503\n",
      "Classifier 11/50: error = 0.4331424367777794, alpha = 0.1345207168297723\n",
      "Classifier 12/50: error = 0.4292016196292041, alpha = 0.14255463185945602\n",
      "Classifier 13/50: error = 0.4536762755491671, alpha = 0.09291390384286163\n",
      "Classifier 14/50: error = 0.4112223803638806, alpha = 0.17945720843761553\n",
      "Classifier 15/50: error = 0.39351722946552736, alpha = 0.21627573389862956\n",
      "Classifier 16/50: error = 0.4092298447622072, alpha = 0.18357503381381118\n",
      "Classifier 17/50: error = 0.41691344713541234, alpha = 0.16772849850419658\n",
      "Classifier 18/50: error = 0.38572902952936794, alpha = 0.23265051188503855\n",
      "Classifier 19/50: error = 0.40884364299173526, alpha = 0.18437387691422918\n",
      "Classifier 20/50: error = 0.4191724503973613, alpha = 0.1630857424164044\n",
      "Classifier 21/50: error = 0.4413067688783312, alpha = 0.11793014314116958\n",
      "Classifier 22/50: error = 0.42109792851404965, alpha = 0.15913395669885882\n",
      "Classifier 23/50: error = 0.3531343065594271, alpha = 0.3026451164289528\n",
      "Classifier 24/50: error = 0.44707369808105907, alpha = 0.10625063466210267\n",
      "Classifier 25/50: error = 0.40831607765996636, alpha = 0.18546550131636352\n",
      "Classifier 26/50: error = 0.4364944187046872, alpha = 0.12770082467415914\n",
      "Classifier 27/50: error = 0.44107625884219803, alpha = 0.11839763032391351\n",
      "Classifier 28/50: error = 0.43367152412769194, alpha = 0.1334434325933209\n",
      "Classifier 29/50: error = 0.44574985391079447, alpha = 0.10892909151361893\n",
      "Classifier 30/50: error = 0.44694178234360726, alpha = 0.10651746335008064\n",
      "Classifier 31/50: error = 0.45184393377994936, alpha = 0.09661159888705398\n",
      "Classifier 32/50: error = 0.45147903527387545, alpha = 0.09734828129705149\n",
      "Classifier 33/50: error = 0.46136095242793396, alpha = 0.07743248114927542\n",
      "Classifier 34/50: error = 0.449537962645139, alpha = 0.10126884391286767\n",
      "Classifier 35/50: error = 0.4470870217152776, alpha = 0.10622368551053374\n",
      "Classifier 36/50: error = 0.42098750783065375, alpha = 0.15936044603328378\n",
      "Classifier 37/50: error = 0.4583121844050676, alpha = 0.08356963611174038\n",
      "Classifier 38/50: error = 0.4157983454242118, alpha = 0.17002291296542127\n",
      "Classifier 39/50: error = 0.45919146966452834, alpha = 0.0817990149012621\n",
      "Classifier 40/50: error = 0.4566909748261434, alpha = 0.0868356534347161\n",
      "Classifier 41/50: error = 0.4654528892544876, alpha = 0.0692044897043165\n",
      "Classifier 42/50: error = 0.46949638863691034, alpha = 0.06108307939614091\n",
      "Classifier 43/50: error = 0.44705779168373183, alpha = 0.10628280806075678\n",
      "Classifier 44/50: error = 0.46708105437177305, alpha = 0.06593326700476987\n",
      "Classifier 45/50: error = 0.45750551350553736, alpha = 0.08519449308184818\n",
      "Classifier 46/50: error = 0.4588895891901709, alpha = 0.08240685490860755\n",
      "Classifier 47/50: error = 0.4550177419135548, alpha = 0.09020841435995428\n",
      "Classifier 48/50: error = 0.45334923036925506, alpha = 0.09357369765386897\n",
      "Classifier 49/50: error = 0.4705257140069392, alpha = 0.05901699549313057\n",
      "Classifier 50/50: error = 0.47103488027115087, alpha = 0.05799517318449233\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.33184969613968995, alpha = 0.3499155049589789\n",
      "Classifier 2/50: error = 0.3841036216920736, alpha = 0.2360831839555879\n",
      "Classifier 3/50: error = 0.3235685381479054, alpha = 0.36871008675711153\n",
      "Classifier 4/50: error = 0.37676339490007404, alpha = 0.25165441967983476\n",
      "Classifier 5/50: error = 0.3147749184126907, alpha = 0.3889447658407086\n",
      "Classifier 6/50: error = 0.36361141555458276, alpha = 0.2798618003780361\n",
      "Classifier 7/50: error = 0.3412132592896631, alpha = 0.3289460979578556\n",
      "Classifier 8/50: error = 0.3673345247182993, alpha = 0.27183443144759617\n",
      "Classifier 9/50: error = 0.3698834132654164, alpha = 0.266358501880104\n",
      "Classifier 10/50: error = 0.45308627027977266, alpha = 0.09410426257814877\n",
      "Classifier 11/50: error = 0.37531540477905434, alpha = 0.25474006136696664\n",
      "Classifier 12/50: error = 0.3865042108872416, alpha = 0.23101531871497857\n",
      "Classifier 13/50: error = 0.36825723455301285, alpha = 0.2698502967835561\n",
      "Classifier 14/50: error = 0.40697482508820276, alpha = 0.1882427613935199\n",
      "Classifier 15/50: error = 0.4250352954348872, alpha = 0.15106822096436953\n",
      "Classifier 16/50: error = 0.447887045886335, alpha = 0.10460579070613084\n",
      "Classifier 17/50: error = 0.44163501258286186, alpha = 0.11726453512900525\n",
      "Classifier 18/50: error = 0.4424390066622446, alpha = 0.115634642748714\n",
      "Classifier 19/50: error = 0.4209149200941604, alpha = 0.1595093431669013\n",
      "Classifier 20/50: error = 0.4043418650307729, alpha = 0.19370309133180685\n",
      "Classifier 21/50: error = 0.43985101446724617, alpha = 0.12088336390052347\n",
      "Classifier 22/50: error = 0.3886582849043734, alpha = 0.2264777810011415\n",
      "Classifier 23/50: error = 0.44231613689115007, alpha = 0.11588368998235854\n",
      "Classifier 24/50: error = 0.3676986317333117, alpha = 0.2710512308747027\n",
      "Classifier 25/50: error = 0.417066970206851, alpha = 0.16741274952685783\n",
      "Classifier 26/50: error = 0.44017897109427595, alpha = 0.12021787233138538\n",
      "Classifier 27/50: error = 0.3764403010975901, alpha = 0.25234251831234206\n",
      "Classifier 28/50: error = 0.42878595312178513, alpha = 0.1434030759481911\n",
      "Classifier 29/50: error = 0.4499551832274592, alpha = 0.1004258874652656\n",
      "Classifier 30/50: error = 0.4193657964701928, alpha = 0.1626886993943689\n",
      "Classifier 31/50: error = 0.3982906421117631, alpha = 0.2062962695483179\n",
      "Classifier 32/50: error = 0.4123194262007848, alpha = 0.17719260155572625\n",
      "Classifier 33/50: error = 0.46376530015742334, alpha = 0.07259666620666809\n",
      "Classifier 34/50: error = 0.45875831246384713, alpha = 0.08267120112392758\n",
      "Classifier 35/50: error = 0.4307015754670831, alpha = 0.1394946592726284\n",
      "Classifier 36/50: error = 0.44426593208826304, alpha = 0.11193327769137634\n",
      "Classifier 37/50: error = 0.44304317225910705, alpha = 0.1144102543633648\n",
      "Classifier 38/50: error = 0.4542448596158003, alpha = 0.09176701163653803\n",
      "Classifier 39/50: error = 0.43797045304060866, alpha = 0.12470148691626448\n",
      "Classifier 40/50: error = 0.46381526858520383, alpha = 0.07249620246149363\n",
      "Classifier 41/50: error = 0.4545352641335366, alpha = 0.09118132908107085\n",
      "Classifier 42/50: error = 0.4488740649937437, alpha = 0.10261048531580397\n",
      "Classifier 43/50: error = 0.46539437375836523, alpha = 0.06932208303988581\n",
      "Classifier 44/50: error = 0.4553807315102975, alpha = 0.08947655948519131\n",
      "Classifier 45/50: error = 0.42128014208942766, alpha = 0.15876024479368112\n",
      "Classifier 46/50: error = 0.44812742172925046, alpha = 0.10411978382259732\n",
      "Classifier 47/50: error = 0.44817293549217685, alpha = 0.10402776678077158\n",
      "Classifier 48/50: error = 0.44651249757062494, alpha = 0.10738589133790649\n",
      "Classifier 49/50: error = 0.4588982122472486, alpha = 0.08238949143743478\n",
      "Classifier 50/50: error = 0.4299846410194341, alpha = 0.14095690824907406\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3719900359811792, alpha = 0.26184448179357755\n",
      "Classifier 2/50: error = 0.3581220771562308, alpha = 0.29176210411722475\n",
      "Classifier 3/50: error = 0.3746619315677808, alpha = 0.25613415467038664\n",
      "Classifier 4/50: error = 0.3847080042939344, alpha = 0.23480616433474616\n",
      "Classifier 5/50: error = 0.4105388069954934, alpha = 0.18086921351722454\n",
      "Classifier 6/50: error = 0.4012672845058399, alpha = 0.20009376520453073\n",
      "Classifier 7/50: error = 0.36034251477516976, alpha = 0.2869389222890765\n",
      "Classifier 8/50: error = 0.40545677153930715, alpha = 0.19138958242195625\n",
      "Classifier 9/50: error = 0.3669905508589788, alpha = 0.27257462436317736\n",
      "Classifier 10/50: error = 0.4389778047129131, alpha = 0.12265580771279733\n",
      "Classifier 11/50: error = 0.4120361012716667, alpha = 0.17777728963205452\n",
      "Classifier 12/50: error = 0.3878033149542593, alpha = 0.22827766035247934\n",
      "Classifier 13/50: error = 0.4014249876633952, alpha = 0.1997655826271854\n",
      "Classifier 14/50: error = 0.45794247093537754, alpha = 0.08431428552272772\n",
      "Classifier 15/50: error = 0.44761950606053214, alpha = 0.10514677733960827\n",
      "Classifier 16/50: error = 0.40451816560331166, alpha = 0.19333711959235558\n",
      "Classifier 17/50: error = 0.42250038337988827, alpha = 0.15625871213304376\n",
      "Classifier 18/50: error = 0.41717275823926736, alpha = 0.16719519585473772\n",
      "Classifier 19/50: error = 0.4340780720016848, alpha = 0.13261586245481316\n",
      "Classifier 20/50: error = 0.43674824347361296, alpha = 0.12718488530874114\n",
      "Classifier 21/50: error = 0.4052910034333057, alpha = 0.19173343417089467\n",
      "Classifier 22/50: error = 0.44535930553082265, alpha = 0.1097195610832842\n",
      "Classifier 23/50: error = 0.44195988326174573, alpha = 0.116605868719413\n",
      "Classifier 24/50: error = 0.3990596315445448, alpha = 0.20469242538639357\n",
      "Classifier 25/50: error = 0.44585283043653534, alpha = 0.10872068974520518\n",
      "Classifier 26/50: error = 0.4448435434933409, alpha = 0.11076367245030687\n",
      "Classifier 27/50: error = 0.4283024209114631, alpha = 0.14439030332008165\n",
      "Classifier 28/50: error = 0.4564694442050514, alpha = 0.08728208124683348\n",
      "Classifier 29/50: error = 0.4628564513669835, alpha = 0.0744242044384472\n",
      "Classifier 30/50: error = 0.45976775408418696, alpha = 0.08063882626686922\n",
      "Classifier 31/50: error = 0.4559061889652064, alpha = 0.08841730815594465\n",
      "Classifier 32/50: error = 0.4429950361586056, alpha = 0.11450779333128419\n",
      "Classifier 33/50: error = 0.4396531969109979, alpha = 0.12128482796967831\n",
      "Classifier 34/50: error = 0.4371234222509536, alpha = 0.12642239779273645\n",
      "Classifier 35/50: error = 0.44918978478151506, alpha = 0.10197241554892796\n",
      "Classifier 36/50: error = 0.46517664560495153, alpha = 0.06975964858735413\n",
      "Classifier 37/50: error = 0.450359994120482, alpha = 0.09960813962036122\n",
      "Classifier 38/50: error = 0.4588317219914312, alpha = 0.08252337814316703\n",
      "Classifier 39/50: error = 0.43455521196522917, alpha = 0.13164482504865732\n",
      "Classifier 40/50: error = 0.4423662187918782, alpha = 0.11578217623486947\n",
      "Classifier 41/50: error = 0.452206195571107, alpha = 0.09588034305433404\n",
      "Classifier 42/50: error = 0.4486898724770082, alpha = 0.10298277686349049\n",
      "Classifier 43/50: error = 0.46201092298533364, alpha = 0.07612486167537157\n",
      "Classifier 44/50: error = 0.45438788836854943, alpha = 0.09147854602542944\n",
      "Classifier 45/50: error = 0.45746693071538946, alpha = 0.08527222060771474\n",
      "Classifier 46/50: error = 0.4428022246233616, alpha = 0.11489851226694207\n",
      "Classifier 47/50: error = 0.46349469410577315, alpha = 0.07314075716769554\n",
      "Classifier 48/50: error = 0.46800679981001, alpha = 0.06407394115791679\n",
      "Classifier 49/50: error = 0.46480435259359454, alpha = 0.07050790308301354\n",
      "Classifier 50/50: error = 0.4454082178668277, alpha = 0.10962055509813771\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3741019355929336, alpha = 0.25732960299168434\n",
      "Classifier 2/50: error = 0.2862893838533235, alpha = 0.4567372247708348\n",
      "Classifier 3/50: error = 0.2606145146362491, alpha = 0.5213885278196972\n",
      "Classifier 4/50: error = 0.3549236482566915, alpha = 0.298732996724495\n",
      "Classifier 5/50: error = 0.33466976917751434, alpha = 0.3435696114800678\n",
      "Classifier 6/50: error = 0.31376856986738977, alpha = 0.3912796284228622\n",
      "Classifier 7/50: error = 0.30772015846548617, alpha = 0.4053997377077101\n",
      "Classifier 8/50: error = 0.3096108312364458, alpha = 0.4009696627005589\n",
      "Classifier 9/50: error = 0.39775514005259704, alpha = 0.20741375833370432\n",
      "Classifier 10/50: error = 0.39323700458284505, alpha = 0.21686288358411085\n",
      "Classifier 11/50: error = 0.329809581213789, alpha = 0.3545232088518526\n",
      "Classifier 12/50: error = 0.3625031462414618, alpha = 0.2822580940384131\n",
      "Classifier 13/50: error = 0.3965070987476029, alpha = 0.21002016665588003\n",
      "Classifier 14/50: error = 0.39615086990707676, alpha = 0.21076462936007556\n",
      "Classifier 15/50: error = 0.3149130397326253, alpha = 0.38862462147835775\n",
      "Classifier 16/50: error = 0.3762804578726193, alpha = 0.25268302578408836\n",
      "Classifier 17/50: error = 0.3881603262935815, alpha = 0.2275259053291295\n",
      "Classifier 18/50: error = 0.36052138476537143, alpha = 0.2865509529074287\n",
      "Classifier 19/50: error = 0.4269804466021342, alpha = 0.14709081049858294\n",
      "Classifier 20/50: error = 0.3956112522068711, alpha = 0.21189278512353135\n",
      "Classifier 21/50: error = 0.4438994942378205, alpha = 0.11267543557478221\n",
      "Classifier 22/50: error = 0.42634970727604493, alpha = 0.14838002293075458\n",
      "Classifier 23/50: error = 0.43853991977230566, alpha = 0.12354491597429736\n",
      "Classifier 24/50: error = 0.47140274601225496, alpha = 0.05725699577181903\n",
      "Classifier 25/50: error = 0.4464028369836037, alpha = 0.10760775667046349\n",
      "Classifier 26/50: error = 0.4132382809488057, alpha = 0.175297214620042\n",
      "Classifier 27/50: error = 0.4313719219815896, alpha = 0.13812796644140768\n",
      "Classifier 28/50: error = 0.4432120735042171, alpha = 0.11406802413995092\n",
      "Classifier 29/50: error = 0.44356499106957764, alpha = 0.11335302306975763\n",
      "Classifier 30/50: error = 0.4208407333103452, alpha = 0.15966152762746666\n",
      "Classifier 31/50: error = 0.4592204123148038, alpha = 0.08174074169807793\n",
      "Classifier 32/50: error = 0.4506882602965957, alpha = 0.09894511527514181\n",
      "Classifier 33/50: error = 0.4550357871132857, alpha = 0.09017202959436563\n",
      "Classifier 34/50: error = 0.43839599161626286, alpha = 0.12383719884529466\n",
      "Classifier 35/50: error = 0.4363705392716388, alpha = 0.12795265393828453\n",
      "Classifier 36/50: error = 0.4262829149965294, alpha = 0.14851657296677667\n",
      "Classifier 37/50: error = 0.4463374175829023, alpha = 0.10774011824603347\n",
      "Classifier 38/50: error = 0.42260844050836144, alpha = 0.15603728556929475\n",
      "Classifier 39/50: error = 0.45444548215343683, alpha = 0.0913623930671526\n",
      "Classifier 40/50: error = 0.411649760725016, alpha = 0.17857476151955556\n",
      "Classifier 41/50: error = 0.4175350450971965, alpha = 0.1664502695922427\n",
      "Classifier 42/50: error = 0.42837928624589794, alpha = 0.1442333487838499\n",
      "Classifier 43/50: error = 0.4661661743591723, alpha = 0.06777121733412918\n",
      "Classifier 44/50: error = 0.456101278267253, alpha = 0.08802408494299012\n",
      "Classifier 45/50: error = 0.4529615580019986, alpha = 0.09435590841546333\n",
      "Classifier 46/50: error = 0.44308503010475886, alpha = 0.11432543888788096\n",
      "Classifier 47/50: error = 0.446045076069235, alpha = 0.10833165215725175\n",
      "Classifier 48/50: error = 0.40287736140912805, alpha = 0.19674515773896636\n",
      "Classifier 49/50: error = 0.47543030112863194, alpha = 0.04917900711551212\n",
      "Classifier 50/50: error = 0.4445477771110493, alpha = 0.11136253184660572\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3693032165376327, alpha = 0.26760359097605557\n",
      "Classifier 2/50: error = 0.3141102369354646, alpha = 0.3904864610299214\n",
      "Classifier 3/50: error = 0.3493528863785719, alpha = 0.31094243991494086\n",
      "Classifier 4/50: error = 0.2861963603551331, alpha = 0.45696487995013524\n",
      "Classifier 5/50: error = 0.3490308904306242, alpha = 0.3116508803317504\n",
      "Classifier 6/50: error = 0.3154949212107937, alpha = 0.387276739986836\n",
      "Classifier 7/50: error = 0.3573952489324439, alpha = 0.29334376540905094\n",
      "Classifier 8/50: error = 0.3231792764719501, alpha = 0.3695996113836597\n",
      "Classifier 9/50: error = 0.3810544029454064, alpha = 0.24253761273173666\n",
      "Classifier 10/50: error = 0.3663375675337184, alpha = 0.27398057381231905\n",
      "Classifier 11/50: error = 0.3220183487460543, alpha = 0.37225584837978204\n",
      "Classifier 12/50: error = 0.3553737129612754, alpha = 0.2977504002417276\n",
      "Classifier 13/50: error = 0.36100035718158346, alpha = 0.2855124737660954\n",
      "Classifier 14/50: error = 0.3604109331108676, alpha = 0.2867905128517847\n",
      "Classifier 15/50: error = 0.42058343684456445, alpha = 0.16018939446639524\n",
      "Classifier 16/50: error = 0.3961623676410681, alpha = 0.21074059729815328\n",
      "Classifier 17/50: error = 0.45082701965417704, alpha = 0.09866487847415374\n",
      "Classifier 18/50: error = 0.4498147450601435, alpha = 0.10070961413903325\n",
      "Classifier 19/50: error = 0.35844646522107504, alpha = 0.2910566569946513\n",
      "Classifier 20/50: error = 0.3972170760191974, alpha = 0.20853710809899784\n",
      "Classifier 21/50: error = 0.3917367522146533, alpha = 0.22000884888696748\n",
      "Classifier 22/50: error = 0.4102034054486443, alpha = 0.18156228742988031\n",
      "Classifier 23/50: error = 0.3849559684599049, alpha = 0.23428245051796226\n",
      "Classifier 24/50: error = 0.4154952670182751, alpha = 0.17064682755909322\n",
      "Classifier 25/50: error = 0.4284220613745691, alpha = 0.14414600751924372\n",
      "Classifier 26/50: error = 0.414937379136265, alpha = 0.171795635223458\n",
      "Classifier 27/50: error = 0.4781538986858843, alpha = 0.04372003743834402\n",
      "Classifier 28/50: error = 0.4262228592039349, alpha = 0.14863935563334857\n",
      "Classifier 29/50: error = 0.4091478587418771, alpha = 0.1837445992520882\n",
      "Classifier 30/50: error = 0.44919598183095943, alpha = 0.10195989214018027\n",
      "Classifier 31/50: error = 0.4388689267998055, alpha = 0.12287686198373511\n",
      "Classifier 32/50: error = 0.46070827460663666, alpha = 0.07874581311741981\n",
      "Classifier 33/50: error = 0.43588689809270353, alpha = 0.12893598249266564\n",
      "Classifier 34/50: error = 0.43291257990463805, alpha = 0.1349888291082273\n",
      "Classifier 35/50: error = 0.4081861386133161, alpha = 0.18573443478767054\n",
      "Classifier 36/50: error = 0.432539309914749, alpha = 0.1357491330555883\n",
      "Classifier 37/50: error = 0.41738103409275423, alpha = 0.16676692121583694\n",
      "Classifier 38/50: error = 0.4159108952336267, alpha = 0.16979125230331413\n",
      "Classifier 39/50: error = 0.4621160397196107, alpha = 0.07591341094387583\n",
      "Classifier 40/50: error = 0.4238293621588074, alpha = 0.15353646826192505\n",
      "Classifier 41/50: error = 0.4417962263648867, alpha = 0.11693766597371871\n",
      "Classifier 42/50: error = 0.4348885149601265, alpha = 0.13096665974493632\n",
      "Classifier 43/50: error = 0.44308758457031766, alpha = 0.11432026289308898\n",
      "Classifier 44/50: error = 0.4506214931469915, alpha = 0.09907996295925359\n",
      "Classifier 45/50: error = 0.46072823170955157, alpha = 0.07870565102220327\n",
      "Classifier 46/50: error = 0.4746642230815837, alpha = 0.050714988962372184\n",
      "Classifier 47/50: error = 0.42875611158508586, alpha = 0.14346399533568846\n",
      "Classifier 48/50: error = 0.4362440318610712, alpha = 0.12820984216642137\n",
      "Classifier 49/50: error = 0.4493955193604088, alpha = 0.10155667047171771\n",
      "Classifier 50/50: error = 0.4629499533613245, alpha = 0.07423616535244572\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2932228014699598, alpha = 0.4398913724798685\n",
      "Classifier 2/50: error = 0.3921341689713867, alpha = 0.21917506792960367\n",
      "Classifier 3/50: error = 0.38685118224230763, alpha = 0.23028379945022065\n",
      "Classifier 4/50: error = 0.41323856367980893, alpha = 0.1752966316032332\n",
      "Classifier 5/50: error = 0.40223972978039796, alpha = 0.19807076697900777\n",
      "Classifier 6/50: error = 0.41270172521026643, alpha = 0.17640385393654864\n",
      "Classifier 7/50: error = 0.38958111433269266, alpha = 0.22453666156632238\n",
      "Classifier 8/50: error = 0.45288343190956737, alpha = 0.09451355819205362\n",
      "Classifier 9/50: error = 0.3784893410861241, alpha = 0.2479825747291302\n",
      "Classifier 10/50: error = 0.41041041921610294, alpha = 0.18113449374403556\n",
      "Classifier 11/50: error = 0.4089606149329014, alpha = 0.18413190055567613\n",
      "Classifier 12/50: error = 0.4499808176029173, alpha = 0.10037410017839862\n",
      "Classifier 13/50: error = 0.4486233261962364, alpha = 0.10311728778628808\n",
      "Classifier 14/50: error = 0.3861350444024605, alpha = 0.2317938987961481\n",
      "Classifier 15/50: error = 0.4153947071701965, alpha = 0.17085386824716545\n",
      "Classifier 16/50: error = 0.4187000960365693, alpha = 0.16405595351848584\n",
      "Classifier 17/50: error = 0.41192565254819136, alpha = 0.17800525149600696\n",
      "Classifier 18/50: error = 0.43478318197839916, alpha = 0.131180965797488\n",
      "Classifier 19/50: error = 0.4281615927608987, alpha = 0.1446778845380823\n",
      "Classifier 20/50: error = 0.43468497693304664, alpha = 0.13138078044297258\n",
      "Classifier 21/50: error = 0.44116330446610796, alpha = 0.1182210909117501\n",
      "Classifier 22/50: error = 0.42131254310268496, alpha = 0.15869379637040096\n",
      "Classifier 23/50: error = 0.4635494016216737, alpha = 0.073030756651018\n",
      "Classifier 24/50: error = 0.45582009425158304, alpha = 0.08859084986381113\n",
      "Classifier 25/50: error = 0.4152858514713971, alpha = 0.17107800545163457\n",
      "Classifier 26/50: error = 0.43193280194771366, alpha = 0.1369848465001324\n",
      "Classifier 27/50: error = 0.4687371793116114, alpha = 0.06260731343706591\n",
      "Classifier 28/50: error = 0.4541194589715706, alpha = 0.0920199367634215\n",
      "Classifier 29/50: error = 0.46671394323051785, alpha = 0.06667072166007175\n",
      "Classifier 30/50: error = 0.43772871523277657, alpha = 0.12519254980579497\n",
      "Classifier 31/50: error = 0.4395056068721781, alpha = 0.12158438232033528\n",
      "Classifier 32/50: error = 0.45329922058655514, alpha = 0.09367459650354232\n",
      "Classifier 33/50: error = 0.4203582175937114, alpha = 0.16065152466609553\n",
      "Classifier 34/50: error = 0.4459582118070676, alpha = 0.10850743083973366\n",
      "Classifier 35/50: error = 0.44842028437169673, alpha = 0.10352772205182019\n",
      "Classifier 36/50: error = 0.44898400900816904, alpha = 0.10238827901370459\n",
      "Classifier 37/50: error = 0.4559706007272777, alpha = 0.08828747639712829\n",
      "Classifier 38/50: error = 0.4702048581743106, alpha = 0.059660969374023654\n",
      "Classifier 39/50: error = 0.4451287992712366, alpha = 0.11018616957914852\n",
      "Classifier 40/50: error = 0.4410146641196011, alpha = 0.11852255656258431\n",
      "Classifier 41/50: error = 0.46756531947623836, alpha = 0.06496058228845436\n",
      "Classifier 42/50: error = 0.4361987668618119, alpha = 0.12830186952741754\n",
      "Classifier 43/50: error = 0.444727783346927, alpha = 0.11099805086991492\n",
      "Classifier 44/50: error = 0.4367761765303661, alpha = 0.1271281110297572\n",
      "Classifier 45/50: error = 0.45382418524406676, alpha = 0.09261553152818937\n",
      "Classifier 46/50: error = 0.47404880520893955, alpha = 0.05194907093665471\n",
      "Classifier 47/50: error = 0.44025084899134537, alpha = 0.1200720314457966\n",
      "Classifier 48/50: error = 0.4708267691487163, alpha = 0.05841280706622801\n",
      "Classifier 49/50: error = 0.46925150708645835, alpha = 0.06157468693003557\n",
      "Classifier 50/50: error = 0.466493420141451, alpha = 0.06711374428289715\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Classifier 1/50: error = 0.399394856278366, alpha = 0.2039935887284973\n",
      "Classifier 2/50: error = 0.398159279613181, alpha = 0.20657035044067382\n",
      "Classifier 3/50: error = 0.41782823086296295, alpha = 0.16584756148723268\n",
      "Classifier 4/50: error = 0.35169504715930794, alpha = 0.3057983674745003\n",
      "Classifier 5/50: error = 0.3642180761868512, alpha = 0.2785514093460986\n",
      "Classifier 6/50: error = 0.37777772959329736, alpha = 0.24949568550074944\n",
      "Classifier 7/50: error = 0.3616955310649749, alpha = 0.2840063049539\n",
      "Classifier 8/50: error = 0.3998072232207076, alpha = 0.20313420458616108\n",
      "Classifier 9/50: error = 0.4171799748445292, alpha = 0.16718035543776266\n",
      "Classifier 10/50: error = 0.36138820329247845, alpha = 0.2846720084106652\n",
      "Classifier 11/50: error = 0.4448476760553771, alpha = 0.11075530551716732\n",
      "Classifier 12/50: error = 0.4168722568125468, alpha = 0.16781321976039296\n",
      "Classifier 13/50: error = 0.38757721810883206, alpha = 0.22875388125733084\n",
      "Classifier 14/50: error = 0.42275074745992425, alpha = 0.15574569872008734\n",
      "Classifier 15/50: error = 0.36831633567085, alpha = 0.2697232804412087\n",
      "Classifier 16/50: error = 0.4335698263208949, alpha = 0.133650477342149\n",
      "Classifier 17/50: error = 0.3885361534337709, alpha = 0.2267348031175524\n",
      "Classifier 18/50: error = 0.43971051499768754, alpha = 0.12116849884517676\n",
      "Classifier 19/50: error = 0.41572088026209986, alpha = 0.17018236958922625\n",
      "Classifier 20/50: error = 0.4498096995594604, alpha = 0.10071980784455065\n",
      "Classifier 21/50: error = 0.386258557522009, alpha = 0.23153337627143425\n",
      "Classifier 22/50: error = 0.4624785660473294, alpha = 0.07518421205033936\n",
      "Classifier 23/50: error = 0.4453829839465233, alpha = 0.10967163211189856\n",
      "Classifier 24/50: error = 0.4412871393579036, alpha = 0.11796995089974494\n",
      "Classifier 25/50: error = 0.4482351823312998, alpha = 0.10390192263384967\n",
      "Classifier 26/50: error = 0.4283247952390851, alpha = 0.14434461551755662\n",
      "Classifier 27/50: error = 0.430831041605232, alpha = 0.13923066538288784\n",
      "Classifier 28/50: error = 0.4381560179188932, alpha = 0.12432457355105538\n",
      "Classifier 29/50: error = 0.44089907998022904, alpha = 0.11875699392222276\n",
      "Classifier 30/50: error = 0.44229583073770284, alpha = 0.11592485031429248\n",
      "Classifier 31/50: error = 0.4402181733911328, alpha = 0.12013832989558505\n",
      "Classifier 32/50: error = 0.4482959270689659, alpha = 0.10377911843985414\n",
      "Classifier 33/50: error = 0.44471954316656115, alpha = 0.11101473514406732\n",
      "Classifier 34/50: error = 0.44863559810044534, alpha = 0.10309248213616265\n",
      "Classifier 35/50: error = 0.4509980615732727, alpha = 0.09831946543294826\n",
      "Classifier 36/50: error = 0.45723329423712533, alpha = 0.08574291839435823\n",
      "Classifier 37/50: error = 0.4494975536012228, alpha = 0.1013504943309648\n",
      "Classifier 38/50: error = 0.45112685968677124, alpha = 0.09805937768586404\n",
      "Classifier 39/50: error = 0.4659187761467477, alpha = 0.06826830657041842\n",
      "Classifier 40/50: error = 0.46449778415496457, alpha = 0.07112411994749868\n",
      "Classifier 41/50: error = 0.4408878071480951, alpha = 0.11877985911243037\n",
      "Classifier 42/50: error = 0.44102698839831245, alpha = 0.1184975602015044\n",
      "Classifier 43/50: error = 0.467225906768174, alpha = 0.0656423065481805\n",
      "Classifier 44/50: error = 0.4193383989674652, alpha = 0.1627449580437862\n",
      "Classifier 45/50: error = 0.4786916890815369, alpha = 0.04264244974748578\n",
      "Classifier 46/50: error = 0.4576924981845114, alpha = 0.08481781488445027\n",
      "Classifier 47/50: error = 0.4688456022975689, alpha = 0.06238961934793418\n",
      "Classifier 48/50: error = 0.4643091652164073, alpha = 0.07150327958094284\n",
      "Classifier 49/50: error = 0.46308178744813344, alpha = 0.07397104663236537\n",
      "Classifier 50/50: error = 0.45479140721120803, alpha = 0.09066479615996381\n",
      "Multiclass Accuracy: 0.8361\n"
     ]
    }
   ],
   "source": [
    "class AdaBoostMulticlass: # Creamos la clase AdaBoostMulticlass\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.models = [] # Inicializamos los modelos\n",
    "\n",
    "    def fit(self, X, y, verbose=False): # Creamos la funcin fit\n",
    "        for digit in range(10): # Para cada dgito\n",
    "            X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X, y)\n",
    "            model = AdaBoost(T=self.T, A=self.A) # Creamos el clasificador AdaBoost\n",
    "            model.fit(X_train_balanced, Y_train_binary_balanced, verbose) # Ajustamos el clasificador AdaBoost\n",
    "            self.models.append(model) # Aadimos el clasificador AdaBoost\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        model_preds = np.array([model.predict(X) for model in self.models]) # Realizamos las predicciones\n",
    "        return np.argmax(model_preds, axis=0) # Devolvemos el ndice del valor mximo\n",
    "\n",
    "def run_adaboost_multiclass_on_mnist(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_multiclass_on_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    adaboost_multiclass = AdaBoostMulticlass(T=T, A=A) # Creamos el clasificador AdaBoostMulticlass\n",
    "    adaboost_multiclass.fit(X_train, y_train, verboseParam) # Ajustamos el clasificador AdaBoostMulticlass\n",
    "    y_pred = adaboost_multiclass.predict(X_test) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test == y_pred) / len(y_test) # Calculamos la precisin\n",
    "    print(f\"Multiclass Accuracy: {accuracy}\") # Mostramos la precisin\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "accuracy = run_adaboost_multiclass_on_mnist(T=50, A=20, verboseParam=True) # Ejecutamos AdaBoostMulticlass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclase con ADABoosti Binario con Mejoras (Version 1: Solo aadido el parmetro n_componentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "from sklearn.decomposition import PCA # importamos Principal Component Analysis\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, n_features): # Inicializamos la clase\n",
    "        self.feature_index = np.random.randint(0, n_features) # Elegimos un ndice de caracterstica aleatorio\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.n_features = n_features # Inicializamos el nmero de caractersticas\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "        \n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, verbose=False): # Creamos la funcin fit\n",
    "        n_samples, n_features = X.shape # Obtenemos el nmero de muestras y el nmero de caractersticas\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        for t in range(self.T): # Para cada iteracin\n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): # Para cada clasificador dbil\n",
    "                clf = DecisionStump(n_features) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index]), max(X[:, clf.feature_index])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {t + 1}/{self.T}: error = {min_error}, alpha = {best_clf.alpha}') # Mostramos el error y el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components=50): # Creamos la funcin apply_pca\n",
    "    pca = PCA(n_components=n_components) # Creamos el objeto PCA\n",
    "    X_train_reduced = pca.fit_transform(X_train) # Aplicamos PCA a los datos de entrenamiento\n",
    "    X_test_reduced = pca.transform(X_test) # Aplicamos PCA a los datos de prueba\n",
    "    return X_train_reduced, X_test_reduced # Devolvemos los datos reducidos\n",
    "\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False):\n",
    "    print(f\"Running AdaBoost for digit: {digit}\")\n",
    "\n",
    "    # Load MNIST data\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Balance the training dataset for the specified digit\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train)\n",
    "\n",
    "    # Flatten the images\n",
    "    X_train_balanced = X_train_balanced.reshape(X_train_balanced.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # Create the AdaBoost classifier (assuming AdaBoost class is properly defined and imported)\n",
    "    adaboost = AdaBoost(T=T, A=A)\n",
    "    adaboost.fit(X_train_balanced, Y_train_binary_balanced, verboseParam)  # Train the model\n",
    "    y_pred = adaboost.predict(X_test)  # Predict on the test set\n",
    "\n",
    "    # Convert test labels to binary\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1)\n",
    "\n",
    "    # Calculate accuracy using the correct labels\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary)\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.32654284002396616, alpha = 0.36193161781632127\n",
      "Classifier 2/50: error = 0.3278824223679109, alpha = 0.35888910802399876\n",
      "Classifier 3/50: error = 0.3102920104514464, alpha = 0.39937724049123485\n",
      "Classifier 4/50: error = 0.34543031674796315, alpha = 0.31959355636828796\n",
      "Classifier 5/50: error = 0.3359004284699686, alpha = 0.34080866150254474\n",
      "Classifier 6/50: error = 0.3007772224580255, alpha = 0.42179976710006434\n",
      "Classifier 7/50: error = 0.3291195840877196, alpha = 0.3560848705120504\n",
      "Classifier 8/50: error = 0.37566007272679985, alpha = 0.2540051513004905\n",
      "Classifier 9/50: error = 0.38894746673838576, alpha = 0.22586932348998157\n",
      "Classifier 10/50: error = 0.3522621835287082, alpha = 0.3045551361122384\n",
      "Classifier 11/50: error = 0.42055947686654804, alpha = 0.16023855501713782\n",
      "Classifier 12/50: error = 0.36865403739146096, alpha = 0.26899767634644345\n",
      "Classifier 13/50: error = 0.4004842198509689, alpha = 0.20172396580539753\n",
      "Classifier 14/50: error = 0.4311166730882734, alpha = 0.13864830349454627\n",
      "Classifier 15/50: error = 0.40379841487436446, alpha = 0.1948315297628514\n",
      "Classifier 16/50: error = 0.3921296411159969, alpha = 0.21918456568594108\n",
      "Classifier 17/50: error = 0.4016731671210684, alpha = 0.19924920350731823\n",
      "Classifier 18/50: error = 0.4362299405831749, alpha = 0.12823849062893902\n",
      "Classifier 19/50: error = 0.42362321810608583, alpha = 0.15395857919721745\n",
      "Classifier 20/50: error = 0.40638886996441737, alpha = 0.18945696633453005\n",
      "Classifier 21/50: error = 0.3766718007133424, alpha = 0.25184946572261613\n",
      "Classifier 22/50: error = 0.45826995647845015, alpha = 0.08365468377249302\n",
      "Classifier 23/50: error = 0.438923820996694, alpha = 0.12276540908399329\n",
      "Classifier 24/50: error = 0.43241390248139133, alpha = 0.13600460716725055\n",
      "Classifier 25/50: error = 0.42603542048254195, alpha = 0.14902259835589723\n",
      "Classifier 26/50: error = 0.43674002995048183, alpha = 0.127201579549953\n",
      "Classifier 27/50: error = 0.4246518516612346, alpha = 0.15185283611187658\n",
      "Classifier 28/50: error = 0.43404108237260564, alpha = 0.13269115117640812\n",
      "Classifier 29/50: error = 0.43173168066299916, alpha = 0.13739470731132222\n",
      "Classifier 30/50: error = 0.4282407253732895, alpha = 0.14451628712679943\n",
      "Classifier 31/50: error = 0.43056970729042476, alpha = 0.13976357101064107\n",
      "Classifier 32/50: error = 0.42656344531618773, alpha = 0.1479430940885041\n",
      "Classifier 33/50: error = 0.44181639178417653, alpha = 0.11689678131056827\n",
      "Classifier 34/50: error = 0.4448494309680453, alpha = 0.11075175246278472\n",
      "Classifier 35/50: error = 0.4557560955508455, alpha = 0.08871985593426245\n",
      "Classifier 36/50: error = 0.44149810066691597, alpha = 0.11754215059844611\n",
      "Classifier 37/50: error = 0.45079534323958625, alpha = 0.09872885043417617\n",
      "Classifier 38/50: error = 0.4424368148847175, alpha = 0.11563908518189515\n",
      "Classifier 39/50: error = 0.4486342806446697, alpha = 0.10309514515178973\n",
      "Classifier 40/50: error = 0.44607953109793386, alpha = 0.1082619307447635\n",
      "Classifier 41/50: error = 0.45391575880869967, alpha = 0.09243081208165896\n",
      "Classifier 42/50: error = 0.45218302934077637, alpha = 0.09592710296701012\n",
      "Classifier 43/50: error = 0.45462457184069177, alpha = 0.09100122747952065\n",
      "Classifier 44/50: error = 0.44428922597751264, alpha = 0.11188610401808234\n",
      "Classifier 45/50: error = 0.4575664563963947, alpha = 0.08507172177879398\n",
      "Classifier 46/50: error = 0.4581664124816325, alpha = 0.08386322800630223\n",
      "Classifier 47/50: error = 0.4565819981470669, alpha = 0.08705525857070813\n",
      "Classifier 48/50: error = 0.4546399446314691, alpha = 0.09097022667054237\n",
      "Classifier 49/50: error = 0.46571941594142796, alpha = 0.06866889909014082\n",
      "Classifier 50/50: error = 0.4522682967834311, alpha = 0.09575499682987712\n",
      "Accuracy for digit 4: 0.9146\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_on_mnist(digit=4, T=50, A=50, verboseParam=True)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2584212747994935, alpha = 0.5270951122758907\n",
      "Classifier 2/50: error = 0.2338948291435367, alpha = 0.5932239462830551\n",
      "Classifier 3/50: error = 0.2530358589146863, alpha = 0.5412429831463339\n",
      "Classifier 4/50: error = 0.24243996186387784, alpha = 0.5696743462229993\n",
      "Classifier 5/50: error = 0.3391752783385592, alpha = 0.3334858070368075\n",
      "Classifier 6/50: error = 0.2956139657450003, alpha = 0.4341360582070645\n",
      "Classifier 7/50: error = 0.32158124068765226, alpha = 0.37325726590584635\n",
      "Classifier 8/50: error = 0.438662777700055, alpha = 0.12329543819784176\n",
      "Classifier 9/50: error = 0.39040158401278663, alpha = 0.22281224694513813\n",
      "Classifier 10/50: error = 0.39913737263404836, alpha = 0.20453034246953708\n",
      "Classifier 11/50: error = 0.2856434781013628, alpha = 0.45831885738417766\n",
      "Classifier 12/50: error = 0.3412330561570819, alpha = 0.32890206380384396\n",
      "Classifier 13/50: error = 0.3667542277662121, alpha = 0.2730833339188711\n",
      "Classifier 14/50: error = 0.40703241462323536, alpha = 0.188123455124968\n",
      "Classifier 15/50: error = 0.3925981044094293, alpha = 0.21820210990669286\n",
      "Classifier 16/50: error = 0.42669887380538374, alpha = 0.14766627669079402\n",
      "Classifier 17/50: error = 0.3516017139998009, alpha = 0.30600305282089985\n",
      "Classifier 18/50: error = 0.39084014603868994, alpha = 0.22189103821224182\n",
      "Classifier 19/50: error = 0.4257479516268161, alpha = 0.1496104501114625\n",
      "Classifier 20/50: error = 0.42270400628129, alpha = 0.15584146846431168\n",
      "Classifier 21/50: error = 0.3783940690383565, alpha = 0.24818508854120658\n",
      "Classifier 22/50: error = 0.4420330103147788, alpha = 0.11645761952754806\n",
      "Classifier 23/50: error = 0.44195718840320164, alpha = 0.11661133205631016\n",
      "Classifier 24/50: error = 0.4243168478956997, alpha = 0.15253848360116892\n",
      "Classifier 25/50: error = 0.4380840724233459, alpha = 0.12447070273221819\n",
      "Classifier 26/50: error = 0.44887540616770805, alpha = 0.10260777462716357\n",
      "Classifier 27/50: error = 0.4750762306893849, alpha = 0.049888886947865765\n",
      "Classifier 28/50: error = 0.4351275315325669, alpha = 0.13048041101527427\n",
      "Classifier 29/50: error = 0.4054830684489281, alpha = 0.19133503901720939\n",
      "Classifier 30/50: error = 0.4032105879728012, alpha = 0.19605266557244297\n",
      "Classifier 31/50: error = 0.4473456030537064, alpha = 0.10570069436206257\n",
      "Classifier 32/50: error = 0.44963737391491576, alpha = 0.10106797946244603\n",
      "Classifier 33/50: error = 0.43962645481327206, alpha = 0.12133910313902063\n",
      "Classifier 34/50: error = 0.39546321123055006, alpha = 0.2122023808970947\n",
      "Classifier 35/50: error = 0.4493653589847012, alpha = 0.10161761587449819\n",
      "Classifier 36/50: error = 0.4470838224809188, alpha = 0.10623015645257278\n",
      "Classifier 37/50: error = 0.4359672695546922, alpha = 0.12877255588206327\n",
      "Classifier 38/50: error = 0.44417354346039084, alpha = 0.11212038362138568\n",
      "Classifier 39/50: error = 0.4424539957466016, alpha = 0.11560426204722657\n",
      "Classifier 40/50: error = 0.4553997624573092, alpha = 0.08943819218283026\n",
      "Classifier 41/50: error = 0.4562596240184288, alpha = 0.0877049422267531\n",
      "Classifier 42/50: error = 0.4620270688276893, alpha = 0.07609238257891474\n",
      "Classifier 43/50: error = 0.4499063879123779, alpha = 0.10052446661814753\n",
      "Classifier 44/50: error = 0.46250819129921167, alpha = 0.0751246262581161\n",
      "Classifier 45/50: error = 0.4710386995787079, alpha = 0.057987508851940595\n",
      "Classifier 46/50: error = 0.43415929887084537, alpha = 0.1324505384617445\n",
      "Classifier 47/50: error = 0.44892581054214553, alpha = 0.10250590185878836\n",
      "Classifier 48/50: error = 0.45762430810921306, alpha = 0.08495518011472514\n",
      "Classifier 49/50: error = 0.4535564663808652, alpha = 0.09315560217949861\n",
      "Classifier 50/50: error = 0.45530671522384003, alpha = 0.08962578236933806\n",
      "Accuracy for digit 0: 0.9503\n",
      "Running AdaBoost for digit: 1\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Classifier 1/50: error = 0.23488837795742767, alpha = 0.5904556600837811\n",
      "Classifier 2/50: error = 0.36377228858825605, alpha = 0.2795142224377521\n",
      "Classifier 3/50: error = 0.3641814846786158, alpha = 0.2786304207833748\n",
      "Classifier 4/50: error = 0.21586398725082742, alpha = 0.6449669849619093\n",
      "Classifier 5/50: error = 0.2944099947759673, alpha = 0.4370305017686607\n",
      "Classifier 6/50: error = 0.3223930070616839, alpha = 0.3713980715684888\n",
      "Classifier 7/50: error = 0.32364027825851105, alpha = 0.3685462101929708\n",
      "Classifier 8/50: error = 0.3270507652222623, alpha = 0.3607772456149383\n",
      "Classifier 9/50: error = 0.38095446764947716, alpha = 0.24274948364589907\n",
      "Classifier 10/50: error = 0.4210473230822561, alpha = 0.15923775399619852\n",
      "Classifier 11/50: error = 0.3864643841352977, alpha = 0.23109930093627346\n",
      "Classifier 12/50: error = 0.3958710615488188, alpha = 0.2113495466185633\n",
      "Classifier 13/50: error = 0.40250084484033277, alpha = 0.19752783696312964\n",
      "Classifier 14/50: error = 0.36690909353817003, alpha = 0.27274995399087143\n",
      "Classifier 15/50: error = 0.3605701139765769, alpha = 0.28644527370482276\n",
      "Classifier 16/50: error = 0.4225558662223444, alpha = 0.15614501690229468\n",
      "Classifier 17/50: error = 0.3820231533929357, alpha = 0.24048488693636225\n",
      "Classifier 18/50: error = 0.37239637663472086, alpha = 0.26097498925590396\n",
      "Classifier 19/50: error = 0.3509990958238488, alpha = 0.30732523114688814\n",
      "Classifier 20/50: error = 0.3322000358855465, alpha = 0.3491256842090992\n",
      "Classifier 21/50: error = 0.38671458634635114, alpha = 0.23057175545744601\n",
      "Classifier 22/50: error = 0.35792103061895647, alpha = 0.2921994620315893\n",
      "Classifier 23/50: error = 0.37662824467042033, alpha = 0.2519422231031721\n",
      "Classifier 24/50: error = 0.4153858330942841, alpha = 0.17087213960339367\n",
      "Classifier 25/50: error = 0.4061108247985926, alpha = 0.19003331915281693\n",
      "Classifier 26/50: error = 0.4300471866017348, alpha = 0.140829317441415\n",
      "Classifier 27/50: error = 0.44854564464240093, alpha = 0.10327431129547567\n",
      "Classifier 28/50: error = 0.4195665297693467, alpha = 0.1622765402290686\n",
      "Classifier 29/50: error = 0.4109013850138448, alpha = 0.180120175408312\n",
      "Classifier 30/50: error = 0.4343439346433118, alpha = 0.13207476933824727\n",
      "Classifier 31/50: error = 0.4310263753626099, alpha = 0.13883239756941707\n",
      "Classifier 32/50: error = 0.4054885149076518, alpha = 0.19132374245387423\n",
      "Classifier 33/50: error = 0.39487030788602473, alpha = 0.21344271278911775\n",
      "Classifier 34/50: error = 0.4571856527627508, alpha = 0.08583890435553747\n",
      "Classifier 35/50: error = 0.44369641382860714, alpha = 0.11308679377828879\n",
      "Classifier 36/50: error = 0.4306934952203723, alpha = 0.13951113631182566\n",
      "Classifier 37/50: error = 0.3838801436754883, alpha = 0.23655556922140095\n",
      "Classifier 38/50: error = 0.42101049607632834, alpha = 0.15931329236809416\n",
      "Classifier 39/50: error = 0.41792833539844165, alpha = 0.16564180186337985\n",
      "Classifier 40/50: error = 0.4473553091616874, alpha = 0.10568106449211027\n",
      "Classifier 41/50: error = 0.43468317893324204, alpha = 0.1313844388725056\n",
      "Classifier 42/50: error = 0.4233224106477065, alpha = 0.1545746254113941\n",
      "Classifier 43/50: error = 0.4275446678116523, alpha = 0.1459379704596006\n",
      "Classifier 44/50: error = 0.4645609598652268, alpha = 0.07099712942648337\n",
      "Classifier 45/50: error = 0.40753198811280034, alpha = 0.18708872753141842\n",
      "Classifier 46/50: error = 0.47316053701924277, alpha = 0.053730572573633506\n",
      "Classifier 47/50: error = 0.43141162671028455, alpha = 0.1380470331431574\n",
      "Classifier 48/50: error = 0.43129168150727804, alpha = 0.13829153245571965\n",
      "Classifier 49/50: error = 0.46349604286303014, alpha = 0.07313804519742467\n",
      "Classifier 50/50: error = 0.4467121313983585, alpha = 0.10698201913809265\n",
      "Accuracy for digit 1: 0.9622\n",
      "Running AdaBoost for digit: 2\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3580899630748573, alpha = 0.2918319580051959\n",
      "Classifier 2/50: error = 0.3876752033755485, alpha = 0.22854748536224165\n",
      "Classifier 3/50: error = 0.3124546981653885, alpha = 0.39433411398786167\n",
      "Classifier 4/50: error = 0.31502879980870313, alpha = 0.3883563655400444\n",
      "Classifier 5/50: error = 0.3772927841439736, alpha = 0.25052747395790154\n",
      "Classifier 6/50: error = 0.3476045523265942, alpha = 0.3147927015079227\n",
      "Classifier 7/50: error = 0.4465868646637047, alpha = 0.10723543780669441\n",
      "Classifier 8/50: error = 0.3510113537209585, alpha = 0.3072983262585254\n",
      "Classifier 9/50: error = 0.31174182596306954, alpha = 0.3959943279790693\n",
      "Classifier 10/50: error = 0.3525149410359457, alpha = 0.3040013554737989\n",
      "Classifier 11/50: error = 0.41035218543936836, alpha = 0.1812548271333815\n",
      "Classifier 12/50: error = 0.3938698819540064, alpha = 0.2155370366368049\n",
      "Classifier 13/50: error = 0.3993474343190859, alpha = 0.20409243644064892\n",
      "Classifier 14/50: error = 0.3864998398142857, alpha = 0.23102453579062954\n",
      "Classifier 15/50: error = 0.38542220040954844, alpha = 0.2332980846758525\n",
      "Classifier 16/50: error = 0.440347427749167, alpha = 0.11987608029881756\n",
      "Classifier 17/50: error = 0.40587520132974675, alpha = 0.1905218347633543\n",
      "Classifier 18/50: error = 0.42146093807556295, alpha = 0.15838948376029036\n",
      "Classifier 19/50: error = 0.43069719654733407, alpha = 0.1395035886481101\n",
      "Classifier 20/50: error = 0.40082825918898135, alpha = 0.20100760761712405\n",
      "Classifier 21/50: error = 0.4305221566581778, alpha = 0.13986054340310913\n",
      "Classifier 22/50: error = 0.4242978153688889, alpha = 0.15257744147259208\n",
      "Classifier 23/50: error = 0.41467465887814103, alpha = 0.17233678648821715\n",
      "Classifier 24/50: error = 0.44792348779665503, alpha = 0.10453210701623655\n",
      "Classifier 25/50: error = 0.45880405130340435, alpha = 0.08257909751194653\n",
      "Classifier 26/50: error = 0.43288732877978253, alpha = 0.1350402575672325\n",
      "Classifier 27/50: error = 0.4374014246985375, alpha = 0.12585749910940183\n",
      "Classifier 28/50: error = 0.414229311069518, alpha = 0.1732543425738461\n",
      "Classifier 29/50: error = 0.41802554430196803, alpha = 0.16544200735989545\n",
      "Classifier 30/50: error = 0.4183786702548119, alpha = 0.16471633379770345\n",
      "Classifier 31/50: error = 0.4394386997770525, alpha = 0.12172018665276836\n",
      "Classifier 32/50: error = 0.4451476765872853, alpha = 0.1101479548705568\n",
      "Classifier 33/50: error = 0.47243740532790357, alpha = 0.05518112925603424\n",
      "Classifier 34/50: error = 0.4716371168928135, alpha = 0.05678672823918304\n",
      "Classifier 35/50: error = 0.43970497304996464, alpha = 0.12117974628542588\n",
      "Classifier 36/50: error = 0.4554032077576758, alpha = 0.08943124632004928\n",
      "Classifier 37/50: error = 0.4392099662352257, alpha = 0.12218449116100705\n",
      "Classifier 38/50: error = 0.4701412132471295, alpha = 0.05978871381879154\n",
      "Classifier 39/50: error = 0.44728796215283884, alpha = 0.10581727040107079\n",
      "Classifier 40/50: error = 0.44479025171881675, alpha = 0.11087157027032611\n",
      "Classifier 41/50: error = 0.4523380217554547, alpha = 0.09561426624369615\n",
      "Classifier 42/50: error = 0.46292342817718946, alpha = 0.0742895088300885\n",
      "Classifier 43/50: error = 0.45981673908486975, alpha = 0.08054021860382968\n",
      "Classifier 44/50: error = 0.46230712766738524, alpha = 0.07552903956904886\n",
      "Classifier 45/50: error = 0.4712335195950018, alpha = 0.05759656599865878\n",
      "Classifier 46/50: error = 0.4676945992978094, alpha = 0.06470093438732745\n",
      "Classifier 47/50: error = 0.4743625592525411, alpha = 0.05131988833010247\n",
      "Classifier 48/50: error = 0.4519509833056534, alpha = 0.09639549974696689\n",
      "Classifier 49/50: error = 0.46956951791871204, alpha = 0.06093627575570696\n",
      "Classifier 50/50: error = 0.47721708001269936, alpha = 0.045597414603044374\n",
      "Accuracy for digit 2: 0.9113\n",
      "Running AdaBoost for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.36541598694942906, alpha = 0.27596664582366454\n",
      "Classifier 2/50: error = 0.46309791589731286, alpha = 0.07393861298893968\n",
      "Classifier 3/50: error = 0.4144370029473473, alpha = 0.1728263963507353\n",
      "Classifier 4/50: error = 0.3322561233711972, alpha = 0.34899927710343215\n",
      "Classifier 5/50: error = 0.308680499872223, alpha = 0.4031476646544513\n",
      "Classifier 6/50: error = 0.4070080678859642, alpha = 0.18817389278118274\n",
      "Classifier 7/50: error = 0.3508542213747648, alpha = 0.3076432491255713\n",
      "Classifier 8/50: error = 0.3247466322089466, alpha = 0.36602134744381437\n",
      "Classifier 9/50: error = 0.41135824076411664, alpha = 0.17917665652424267\n",
      "Classifier 10/50: error = 0.3986399824962007, alpha = 0.2055675379136564\n",
      "Classifier 11/50: error = 0.42345913760188125, alpha = 0.1542945975979354\n",
      "Classifier 12/50: error = 0.396679261564567, alpha = 0.20966045549465362\n",
      "Classifier 13/50: error = 0.43403682622619333, alpha = 0.13269981423625776\n",
      "Classifier 14/50: error = 0.3811053040709116, alpha = 0.24242970643680592\n",
      "Classifier 15/50: error = 0.42798079640595854, alpha = 0.14504711855472763\n",
      "Classifier 16/50: error = 0.44198745273157086, alpha = 0.11654997701798221\n",
      "Classifier 17/50: error = 0.4212333907778174, alpha = 0.15885612544772582\n",
      "Classifier 18/50: error = 0.4188950027699283, alpha = 0.1636555800552334\n",
      "Classifier 19/50: error = 0.4019905513464851, alpha = 0.1985889849693149\n",
      "Classifier 20/50: error = 0.41373973445223455, alpha = 0.17426335733669854\n",
      "Classifier 21/50: error = 0.42029186748251446, alpha = 0.16078768225604087\n",
      "Classifier 22/50: error = 0.4609926430906738, alpha = 0.07817356784306277\n",
      "Classifier 23/50: error = 0.4337387023258946, alpha = 0.13330667193782816\n",
      "Classifier 24/50: error = 0.4080291808011227, alpha = 0.1860593241405917\n",
      "Classifier 25/50: error = 0.4276042027074325, alpha = 0.14581634882096556\n",
      "Classifier 26/50: error = 0.43087088384771954, alpha = 0.13914942710555425\n",
      "Classifier 27/50: error = 0.4423645429872035, alpha = 0.11578557297671781\n",
      "Classifier 28/50: error = 0.42591930015574786, alpha = 0.14926004318502348\n",
      "Classifier 29/50: error = 0.4224270827237296, alpha = 0.1564089257051137\n",
      "Classifier 30/50: error = 0.428102591134774, alpha = 0.14479837716633065\n",
      "Classifier 31/50: error = 0.46846036071513475, alpha = 0.06316314291861189\n",
      "Classifier 32/50: error = 0.4420570865501754, alpha = 0.1164088113132392\n",
      "Classifier 33/50: error = 0.45372174847021823, alpha = 0.09282217138331766\n",
      "Classifier 34/50: error = 0.4158748605840501, alpha = 0.16986542026139922\n",
      "Classifier 35/50: error = 0.4165672985981046, alpha = 0.16844053955603466\n",
      "Classifier 36/50: error = 0.4411452707798599, alpha = 0.11825766488020856\n",
      "Classifier 37/50: error = 0.454567210573783, alpha = 0.09111690389649367\n",
      "Classifier 38/50: error = 0.4544122196102658, alpha = 0.09142947540098853\n",
      "Classifier 39/50: error = 0.4489210090463339, alpha = 0.10251560611698621\n",
      "Classifier 40/50: error = 0.4673088116070043, alpha = 0.06547578320053829\n",
      "Classifier 41/50: error = 0.4614647669292731, alpha = 0.07722360812537903\n",
      "Classifier 42/50: error = 0.4617752128861486, alpha = 0.0765990361502422\n",
      "Classifier 43/50: error = 0.4616776090729497, alpha = 0.07679539433220661\n",
      "Classifier 44/50: error = 0.4419455627065324, alpha = 0.11663490112704296\n",
      "Classifier 45/50: error = 0.4554574754898749, alpha = 0.0893218415451554\n",
      "Classifier 46/50: error = 0.4599686803719429, alpha = 0.08023436806909331\n",
      "Classifier 47/50: error = 0.4727601191567211, alpha = 0.054533757316308315\n",
      "Classifier 48/50: error = 0.447934958466132, alpha = 0.10450891413979788\n",
      "Classifier 49/50: error = 0.47063644383661496, alpha = 0.05879476650020346\n",
      "Classifier 50/50: error = 0.46947383707972556, alpha = 0.0611283511311231\n",
      "Accuracy for digit 3: 0.8811\n",
      "Running AdaBoost for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3754172729607122, alpha = 0.25452282734076154\n",
      "Classifier 2/50: error = 0.3254241212835153, alpha = 0.3644774226342497\n",
      "Classifier 3/50: error = 0.2789501393698056, alpha = 0.4748376177933295\n",
      "Classifier 4/50: error = 0.3293821249049772, alpha = 0.3554904691232416\n",
      "Classifier 5/50: error = 0.39413464538270837, alpha = 0.21498259186248136\n",
      "Classifier 6/50: error = 0.37575569405632264, alpha = 0.25380131260786587\n",
      "Classifier 7/50: error = 0.37670128182390233, alpha = 0.25178668486616274\n",
      "Classifier 8/50: error = 0.3896595626414452, alpha = 0.2243717269110106\n",
      "Classifier 9/50: error = 0.3427554577753379, alpha = 0.3255194588381902\n",
      "Classifier 10/50: error = 0.3677225980591171, alpha = 0.2709996902823785\n",
      "Classifier 11/50: error = 0.4286482402684607, alpha = 0.14368421582734156\n",
      "Classifier 12/50: error = 0.39335436151447206, alpha = 0.21661697001775648\n",
      "Classifier 13/50: error = 0.4208566303903159, alpha = 0.15962891623501335\n",
      "Classifier 14/50: error = 0.41312084806688265, alpha = 0.17553938201092018\n",
      "Classifier 15/50: error = 0.4295101144357042, alpha = 0.14192507477087174\n",
      "Classifier 16/50: error = 0.4502024199102346, alpha = 0.09992643529819867\n",
      "Classifier 17/50: error = 0.418458616557287, alpha = 0.16455206809931758\n",
      "Classifier 18/50: error = 0.41348997870733506, alpha = 0.1747782377998796\n",
      "Classifier 19/50: error = 0.41518481626129744, alpha = 0.17128605526467508\n",
      "Classifier 20/50: error = 0.4290152305249637, alpha = 0.14293505756577154\n",
      "Classifier 21/50: error = 0.3850203934020575, alpha = 0.2341464021979219\n",
      "Classifier 22/50: error = 0.41475105788786726, alpha = 0.1721794094925258\n",
      "Classifier 23/50: error = 0.44313767744632715, alpha = 0.11421876325960895\n",
      "Classifier 24/50: error = 0.3270094048627197, alpha = 0.36087121166107483\n",
      "Classifier 25/50: error = 0.44490597985869873, alpha = 0.11063726319374458\n",
      "Classifier 26/50: error = 0.42617427210516595, alpha = 0.1487386940786026\n",
      "Classifier 27/50: error = 0.4510913315138445, alpha = 0.09813111998004985\n",
      "Classifier 28/50: error = 0.4405087989279487, alpha = 0.1195486905628581\n",
      "Classifier 29/50: error = 0.41791685828460645, alpha = 0.16566539176337397\n",
      "Classifier 30/50: error = 0.40532155853768426, alpha = 0.1916700505434247\n",
      "Classifier 31/50: error = 0.42310975667460593, alpha = 0.15501020568890325\n",
      "Classifier 32/50: error = 0.43255773607317016, alpha = 0.13571159763894583\n",
      "Classifier 33/50: error = 0.4398998623998003, alpha = 0.12078423464096813\n",
      "Classifier 34/50: error = 0.4303644805245831, alpha = 0.14018211897324157\n",
      "Classifier 35/50: error = 0.4425201048704815, alpha = 0.11547027096902336\n",
      "Classifier 36/50: error = 0.467366115079761, alpha = 0.06536068508924484\n",
      "Classifier 37/50: error = 0.43483737513725373, alpha = 0.1310707051816252\n",
      "Classifier 38/50: error = 0.45542023555940814, alpha = 0.08939691771982758\n",
      "Classifier 39/50: error = 0.4471386942206227, alpha = 0.10611917117253798\n",
      "Classifier 40/50: error = 0.4515566186133464, alpha = 0.09719164188080036\n",
      "Classifier 41/50: error = 0.4371963243820004, alpha = 0.12627425351356747\n",
      "Classifier 42/50: error = 0.43342118512903394, alpha = 0.1339531137879021\n",
      "Classifier 43/50: error = 0.4385471903710084, alpha = 0.12353015172483701\n",
      "Classifier 44/50: error = 0.4194694743436631, alpha = 0.16247581415041346\n",
      "Classifier 45/50: error = 0.44984973892963986, alpha = 0.10063891465304431\n",
      "Classifier 46/50: error = 0.45501839100896213, alpha = 0.09020710557650455\n",
      "Classifier 47/50: error = 0.45402889299775007, alpha = 0.0922026098743892\n",
      "Classifier 48/50: error = 0.45547865772911245, alpha = 0.08927913832886956\n",
      "Classifier 49/50: error = 0.46073162445024335, alpha = 0.07869882342441416\n",
      "Classifier 50/50: error = 0.43699828213238506, alpha = 0.12667670765887895\n",
      "Accuracy for digit 4: 0.9132\n",
      "Running AdaBoost for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1/50: error = 0.40658732355383354, alpha = 0.18904567296969088\n",
      "Classifier 2/50: error = 0.3535234502220418, alpha = 0.30179355222455206\n",
      "Classifier 3/50: error = 0.3920888553533009, alpha = 0.2192701207992344\n",
      "Classifier 4/50: error = 0.35277143799399835, alpha = 0.30343956675318284\n",
      "Classifier 5/50: error = 0.4002103958797607, alpha = 0.20229426765729375\n",
      "Classifier 6/50: error = 0.4063912695086229, alpha = 0.18945199292165166\n",
      "Classifier 7/50: error = 0.38699706629528197, alpha = 0.22997630463799462\n",
      "Classifier 8/50: error = 0.3969103348972369, alpha = 0.20917774271852513\n",
      "Classifier 9/50: error = 0.3766520908843486, alpha = 0.2518914394438665\n",
      "Classifier 10/50: error = 0.4009629955944085, alpha = 0.20072711518025996\n",
      "Classifier 11/50: error = 0.4219124507168386, alpha = 0.1574637483648609\n",
      "Classifier 12/50: error = 0.4318282411913046, alpha = 0.13719792293685557\n",
      "Classifier 13/50: error = 0.40917243429560046, alpha = 0.18369377041085402\n",
      "Classifier 14/50: error = 0.45070173172954603, alpha = 0.0989179078460086\n",
      "Classifier 15/50: error = 0.40692835203728905, alpha = 0.18833904188399916\n",
      "Classifier 16/50: error = 0.4627803367769654, alpha = 0.07457728010996331\n",
      "Classifier 17/50: error = 0.4400521958570309, alpha = 0.12047511281223283\n",
      "Classifier 18/50: error = 0.42400753400607694, alpha = 0.15317167836005305\n",
      "Classifier 19/50: error = 0.4497401863163545, alpha = 0.1008602514384922\n",
      "Classifier 20/50: error = 0.42717926659737815, alpha = 0.14668452914612728\n",
      "Classifier 21/50: error = 0.41984414987225516, alpha = 0.16170660190781116\n",
      "Classifier 22/50: error = 0.44143736908768527, alpha = 0.11766530142885984\n",
      "Classifier 23/50: error = 0.4192737256815896, alpha = 0.16287776367739853\n",
      "Classifier 24/50: error = 0.4344402612786481, alpha = 0.1318787409307583\n",
      "Classifier 25/50: error = 0.4256169470130622, alpha = 0.14987837852038818\n",
      "Classifier 26/50: error = 0.4589568826794248, alpha = 0.08227135340285849\n",
      "Classifier 27/50: error = 0.4629408849340251, alpha = 0.07425440236779074\n",
      "Classifier 28/50: error = 0.44272670203785314, alpha = 0.11505156295733705\n",
      "Classifier 29/50: error = 0.4484935519554769, alpha = 0.10337961296471433\n",
      "Classifier 30/50: error = 0.4679418342408136, alpha = 0.06420440754493106\n",
      "Classifier 31/50: error = 0.42631739718652195, alpha = 0.14844607694307563\n",
      "Classifier 32/50: error = 0.43462471702787997, alpha = 0.13150339449608317\n",
      "Classifier 33/50: error = 0.46646879037745614, alpha = 0.06716322618578584\n",
      "Classifier 34/50: error = 0.4600978551510272, alpha = 0.07997435720681753\n",
      "Classifier 35/50: error = 0.46207033072179526, alpha = 0.07600535742091061\n",
      "Classifier 36/50: error = 0.43474231153780885, alpha = 0.13126412230150034\n",
      "Classifier 37/50: error = 0.4443974473842158, alpha = 0.11166694568819603\n",
      "Classifier 38/50: error = 0.4454778980571209, alpha = 0.10947951552276507\n",
      "Classifier 39/50: error = 0.4421152029785145, alpha = 0.1162909978643208\n",
      "Classifier 40/50: error = 0.4583720439940544, alpha = 0.0834490800918856\n",
      "Classifier 41/50: error = 0.45858660747898694, alpha = 0.08301697336539669\n",
      "Classifier 42/50: error = 0.44897359098717715, alpha = 0.10240933429701005\n",
      "Classifier 43/50: error = 0.45983769632559635, alpha = 0.0804980317892042\n",
      "Classifier 44/50: error = 0.46022004385899395, alpha = 0.07972841826499542\n",
      "Classifier 45/50: error = 0.46661880827202684, alpha = 0.06686184101176972\n",
      "Classifier 46/50: error = 0.46160382333002387, alpha = 0.0769438395279247\n",
      "Classifier 47/50: error = 0.459900749232125, alpha = 0.08037110834569604\n",
      "Classifier 48/50: error = 0.4726141204050164, alpha = 0.054826628742398784\n",
      "Classifier 49/50: error = 0.4582674989636236, alpha = 0.08365963328039912\n",
      "Classifier 50/50: error = 0.4294416456252089, alpha = 0.14206479201152258\n",
      "Accuracy for digit 5: 0.8584\n",
      "Running AdaBoost for digit: 6\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2731806271659201, alpha = 0.4892723882707189\n",
      "Classifier 2/50: error = 0.2496786301782021, alpha = 0.5501634979720457\n",
      "Classifier 3/50: error = 0.4054183470095548, alpha = 0.1914692822007747\n",
      "Classifier 4/50: error = 0.3655929310221461, alpha = 0.27558515440269116\n",
      "Classifier 5/50: error = 0.28941183789093655, alpha = 0.4491211529651399\n",
      "Classifier 6/50: error = 0.34373244178432527, alpha = 0.3233524997775002\n",
      "Classifier 7/50: error = 0.3842401655298212, alpha = 0.2357946100758624\n",
      "Classifier 8/50: error = 0.309221917439646, alpha = 0.40187970971213954\n",
      "Classifier 9/50: error = 0.35252561316015496, alpha = 0.30397797729905807\n",
      "Classifier 10/50: error = 0.39653589817157164, alpha = 0.20995999038601815\n",
      "Classifier 11/50: error = 0.433925913038818, alpha = 0.1329255765149982\n",
      "Classifier 12/50: error = 0.4052255475626856, alpha = 0.1918692212070118\n",
      "Classifier 13/50: error = 0.35066808381565007, alpha = 0.3080519335062141\n",
      "Classifier 14/50: error = 0.38216611160794467, alpha = 0.2401821354944238\n",
      "Classifier 15/50: error = 0.33729310364989595, alpha = 0.33769025461264784\n",
      "Classifier 16/50: error = 0.4461050024358707, alpha = 0.10821038893791579\n",
      "Classifier 17/50: error = 0.4407945474245185, alpha = 0.11896902672993971\n",
      "Classifier 18/50: error = 0.42060467094986476, alpha = 0.16014582744242614\n",
      "Classifier 19/50: error = 0.4341438173657116, alpha = 0.13248204797518973\n",
      "Classifier 20/50: error = 0.33454831454202405, alpha = 0.3438423644796041\n",
      "Classifier 21/50: error = 0.4346782096006703, alpha = 0.13139455010037976\n",
      "Classifier 22/50: error = 0.4022178806513641, alpha = 0.1981162025490663\n",
      "Classifier 23/50: error = 0.42304159149448967, alpha = 0.15514984113770744\n",
      "Classifier 24/50: error = 0.38384972605731915, alpha = 0.23661987364360804\n",
      "Classifier 25/50: error = 0.43955894447421984, alpha = 0.12147612379377912\n",
      "Classifier 26/50: error = 0.4515207316039884, alpha = 0.09726409653859223\n",
      "Classifier 27/50: error = 0.45183165497218525, alpha = 0.09663638649169619\n",
      "Classifier 28/50: error = 0.44167125801132473, alpha = 0.11719104350527729\n",
      "Classifier 29/50: error = 0.4373856940204668, alpha = 0.12588946158167016\n",
      "Classifier 30/50: error = 0.42088503512367703, alpha = 0.15957064738410115\n",
      "Classifier 31/50: error = 0.4476512157810424, alpha = 0.1050826545860005\n",
      "Classifier 32/50: error = 0.42939962264482107, alpha = 0.14215054670208027\n",
      "Classifier 33/50: error = 0.4379465894332859, alpha = 0.12474996045768519\n",
      "Classifier 34/50: error = 0.43187574907068527, alpha = 0.13710110869843434\n",
      "Classifier 35/50: error = 0.3876196288059488, alpha = 0.22866454513172393\n",
      "Classifier 36/50: error = 0.46647773977757645, alpha = 0.0671452465460709\n",
      "Classifier 37/50: error = 0.44007246639718245, alpha = 0.12043398065891565\n",
      "Classifier 38/50: error = 0.42495605990827556, alpha = 0.15123034011936923\n",
      "Classifier 39/50: error = 0.42856997515943007, alpha = 0.14384400358081137\n",
      "Classifier 40/50: error = 0.43085743331884807, alpha = 0.13917685251122253\n",
      "Classifier 41/50: error = 0.40475319557500633, alpha = 0.19284931455302462\n",
      "Classifier 42/50: error = 0.4235377118835003, alpha = 0.1541336820061456\n",
      "Classifier 43/50: error = 0.4550640408464076, alpha = 0.09011506171135535\n",
      "Classifier 44/50: error = 0.43297383017604685, alpha = 0.13486408485843207\n",
      "Classifier 45/50: error = 0.4197991937029725, alpha = 0.16179888729665642\n",
      "Classifier 46/50: error = 0.4230271346141319, alpha = 0.15517945663274924\n",
      "Classifier 47/50: error = 0.44726486947643546, alpha = 0.10586397506798709\n",
      "Classifier 48/50: error = 0.422511589863875, alpha = 0.1562357475256151\n",
      "Classifier 49/50: error = 0.43968228859261504, alpha = 0.12122578494441529\n",
      "Classifier 50/50: error = 0.4551653866644377, alpha = 0.08991072336177781\n",
      "Accuracy for digit 6: 0.9437\n",
      "Running AdaBoost for digit: 7\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Classifier 1/50: error = 0.30185968552957165, alpha = 0.41922890700670434\n",
      "Classifier 2/50: error = 0.29105128858633955, alpha = 0.44514184165103693\n",
      "Classifier 3/50: error = 0.285635116287186, alpha = 0.45833934705609997\n",
      "Classifier 4/50: error = 0.3847717272891624, alpha = 0.23467156583441448\n",
      "Classifier 5/50: error = 0.3287052586571729, alpha = 0.357023409162681\n",
      "Classifier 6/50: error = 0.3237394094767029, alpha = 0.36831979505116863\n",
      "Classifier 7/50: error = 0.2863601926644609, alpha = 0.45656396499512436\n",
      "Classifier 8/50: error = 0.4025036787916454, alpha = 0.19752194503014853\n",
      "Classifier 9/50: error = 0.35256439241800885, alpha = 0.3038930308268118\n",
      "Classifier 10/50: error = 0.40669800258868505, alpha = 0.18881631907889143\n",
      "Classifier 11/50: error = 0.41612692324841705, alpha = 0.1693466535600607\n",
      "Classifier 12/50: error = 0.3632278455568439, alpha = 0.28069079753313153\n",
      "Classifier 13/50: error = 0.4126829857062956, alpha = 0.17644251163707372\n",
      "Classifier 14/50: error = 0.35432372895495556, alpha = 0.3000436329090136\n",
      "Classifier 15/50: error = 0.4109969365932147, alpha = 0.17992281183537887\n",
      "Classifier 16/50: error = 0.4278810079319946, alpha = 0.1452509298500205\n",
      "Classifier 17/50: error = 0.376029694462356, alpha = 0.25321733247327005\n",
      "Classifier 18/50: error = 0.428834048120708, alpha = 0.14330489563263846\n",
      "Classifier 19/50: error = 0.40522116634066574, alpha = 0.19187831022348598\n",
      "Classifier 20/50: error = 0.34539564843707626, alpha = 0.31967022128047173\n",
      "Classifier 21/50: error = 0.37843781511824637, alpha = 0.2480920977688832\n",
      "Classifier 22/50: error = 0.4389538121847907, alpha = 0.12270451859480205\n",
      "Classifier 23/50: error = 0.42935518872691136, alpha = 0.1422412235596906\n",
      "Classifier 24/50: error = 0.392393623103784, alpha = 0.21863089462386928\n",
      "Classifier 25/50: error = 0.43698664120217556, alpha = 0.1267003651962454\n",
      "Classifier 26/50: error = 0.4099828110766439, alpha = 0.1820182177765786\n",
      "Classifier 27/50: error = 0.4400398915770175, alpha = 0.12050008035325108\n",
      "Classifier 28/50: error = 0.3916114114451241, alpha = 0.22027187641868778\n",
      "Classifier 29/50: error = 0.43806313426791876, alpha = 0.12451323141237253\n",
      "Classifier 30/50: error = 0.4269477404450366, alpha = 0.14715764894297664\n",
      "Classifier 31/50: error = 0.3992417124134857, alpha = 0.2043128204224976\n",
      "Classifier 32/50: error = 0.39825453156258267, alpha = 0.20637160924816833\n",
      "Classifier 33/50: error = 0.44239842492225645, alpha = 0.11571689712051358\n",
      "Classifier 34/50: error = 0.4577028437986226, alpha = 0.08479697448170895\n",
      "Classifier 35/50: error = 0.4500858242187976, alpha = 0.10016196845506319\n",
      "Classifier 36/50: error = 0.45790058154264845, alpha = 0.08439866189474642\n",
      "Classifier 37/50: error = 0.4378337422899616, alpha = 0.12497919190715934\n",
      "Classifier 38/50: error = 0.4431495828685622, alpha = 0.11419464049361414\n",
      "Classifier 39/50: error = 0.4530915140981676, alpha = 0.09409368180294295\n",
      "Classifier 40/50: error = 0.4202968747596485, alpha = 0.1607774065767353\n",
      "Classifier 41/50: error = 0.44049976669711755, alpha = 0.11956701447204104\n",
      "Classifier 42/50: error = 0.45508169524787334, alpha = 0.09007946551223552\n",
      "Classifier 43/50: error = 0.42283597598968226, alpha = 0.15557107810038628\n",
      "Classifier 44/50: error = 0.4378613989460741, alpha = 0.1249230104967486\n",
      "Classifier 45/50: error = 0.4424666235110071, alpha = 0.11557866756392329\n",
      "Classifier 46/50: error = 0.44586319989136913, alpha = 0.10869970477802736\n",
      "Classifier 47/50: error = 0.4573082467829286, alpha = 0.08559191046923283\n",
      "Classifier 48/50: error = 0.4417803066067181, alpha = 0.11696994298635655\n",
      "Classifier 49/50: error = 0.4513429396072599, alpha = 0.09762306759523624\n",
      "Classifier 50/50: error = 0.456309064549009, alpha = 0.08760529947298099\n",
      "Accuracy for digit 7: 0.9304\n",
      "Running AdaBoost for digit: 8\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3569780360652935, alpha = 0.29425231289956627\n",
      "Classifier 2/50: error = 0.41275291184806007, alpha = 0.17629826374114577\n",
      "Classifier 3/50: error = 0.40409672093857185, alpha = 0.194212056395488\n",
      "Classifier 4/50: error = 0.4283539979035462, alpha = 0.1442849853267675\n",
      "Classifier 5/50: error = 0.4419221627952371, alpha = 0.11668234075389425\n",
      "Classifier 6/50: error = 0.31244709277690697, alpha = 0.3943518153184258\n",
      "Classifier 7/50: error = 0.38504025075640763, alpha = 0.23410447047042557\n",
      "Classifier 8/50: error = 0.4228031282767447, alpha = 0.15563837707827674\n",
      "Classifier 9/50: error = 0.44461644563175595, alpha = 0.11122348669516187\n",
      "Classifier 10/50: error = 0.3451919769415412, alpha = 0.3201206903998353\n",
      "Classifier 11/50: error = 0.3953473764600115, alpha = 0.21244465228632686\n",
      "Classifier 12/50: error = 0.4415693635663094, alpha = 0.11739764899755148\n",
      "Classifier 13/50: error = 0.4037064052838723, alpha = 0.1950226300497944\n",
      "Classifier 14/50: error = 0.41474473186621674, alpha = 0.1721924403652611\n",
      "Classifier 15/50: error = 0.4056645040265277, alpha = 0.1909587473240338\n",
      "Classifier 16/50: error = 0.4017423340903225, alpha = 0.19910530868627965\n",
      "Classifier 17/50: error = 0.38603124731413907, alpha = 0.2320128587926963\n",
      "Classifier 18/50: error = 0.4450108680723028, alpha = 0.11042491344775716\n",
      "Classifier 19/50: error = 0.4142311643645159, alpha = 0.17325052360768414\n",
      "Classifier 20/50: error = 0.4370571319457093, alpha = 0.12655711098503616\n",
      "Classifier 21/50: error = 0.4383696608156929, alpha = 0.12389067253556536\n",
      "Classifier 22/50: error = 0.43544525580254195, alpha = 0.12983413644622763\n",
      "Classifier 23/50: error = 0.4361385601215376, alpha = 0.12842427799163597\n",
      "Classifier 24/50: error = 0.464279125412039, alpha = 0.07156366714404933\n",
      "Classifier 25/50: error = 0.4255812863966082, alpha = 0.14995131470378908\n",
      "Classifier 26/50: error = 0.4650656271118704, alpha = 0.06998277132098031\n",
      "Classifier 27/50: error = 0.42719310774846403, alpha = 0.1466562470541709\n",
      "Classifier 28/50: error = 0.44292627831809384, alpha = 0.11464712223136075\n",
      "Classifier 29/50: error = 0.44699700924652885, alpha = 0.1064057529157072\n",
      "Classifier 30/50: error = 0.43721536562231267, alpha = 0.12623556075435696\n",
      "Classifier 31/50: error = 0.42842140709270693, alpha = 0.144147343461491\n",
      "Classifier 32/50: error = 0.45694802755945607, alpha = 0.08631768483166034\n",
      "Classifier 33/50: error = 0.447334928290803, alpha = 0.10572228335711117\n",
      "Classifier 34/50: error = 0.4677853969985085, alpha = 0.06451857987445941\n",
      "Classifier 35/50: error = 0.4669898292347595, alpha = 0.06611651378861501\n",
      "Classifier 36/50: error = 0.45869541195784735, alpha = 0.0827978652109265\n",
      "Classifier 37/50: error = 0.4500551613562528, alpha = 0.10022391186890461\n",
      "Classifier 38/50: error = 0.45988991136251733, alpha = 0.0803929244395797\n",
      "Classifier 39/50: error = 0.4651168879705515, alpha = 0.06987974741545608\n",
      "Classifier 40/50: error = 0.4369439944100778, alpha = 0.12678703628611454\n",
      "Classifier 41/50: error = 0.46937616114370095, alpha = 0.06132443622922769\n",
      "Classifier 42/50: error = 0.44793570446314823, alpha = 0.10450740579086068\n",
      "Classifier 43/50: error = 0.45152380168096096, alpha = 0.09725789811724067\n",
      "Classifier 44/50: error = 0.46160372022971935, alpha = 0.07694404695172867\n",
      "Classifier 45/50: error = 0.45679221268391573, alpha = 0.08663165072581407\n",
      "Classifier 46/50: error = 0.4477213422930734, alpha = 0.10494084923247236\n",
      "Classifier 47/50: error = 0.4638753237325166, alpha = 0.0723754608510698\n",
      "Classifier 48/50: error = 0.46377419757877536, alpha = 0.07257877743855394\n",
      "Classifier 49/50: error = 0.4712242015742615, alpha = 0.057615263951185824\n",
      "Classifier 50/50: error = 0.4503279804024225, alpha = 0.09967280484170524\n",
      "Accuracy for digit 8: 0.8628\n",
      "Running AdaBoost for digit: 9\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Classifier 1/50: error = 0.3640107581106067, alpha = 0.27899911268120686\n",
      "Classifier 2/50: error = 0.3390135477928, alpha = 0.3338466365105494\n",
      "Classifier 3/50: error = 0.35373239227389625, alpha = 0.3013364990467222\n",
      "Classifier 4/50: error = 0.41824563604992465, alpha = 0.164989698762225\n",
      "Classifier 5/50: error = 0.3131658478536973, alpha = 0.3926799692673436\n",
      "Classifier 6/50: error = 0.41150534679968304, alpha = 0.17887291382219733\n",
      "Classifier 7/50: error = 0.4152475504828177, alpha = 0.1711568724031097\n",
      "Classifier 8/50: error = 0.45965279824515054, alpha = 0.0808702405297161\n",
      "Classifier 9/50: error = 0.31415740511673296, alpha = 0.39037699860848746\n",
      "Classifier 10/50: error = 0.3939951372297498, alpha = 0.2152747215781884\n",
      "Classifier 11/50: error = 0.40302554567693855, alpha = 0.1964371868018115\n",
      "Classifier 12/50: error = 0.45163650964902047, alpha = 0.09703034823436349\n",
      "Classifier 13/50: error = 0.41342521874453253, alpha = 0.17491175776331291\n",
      "Classifier 14/50: error = 0.43357620272280006, alpha = 0.13363749540484207\n",
      "Classifier 15/50: error = 0.42029064637261937, alpha = 0.1607901881607291\n",
      "Classifier 16/50: error = 0.4215316280537964, alpha = 0.15824453051262252\n",
      "Classifier 17/50: error = 0.39258337260447673, alpha = 0.21823299895336357\n",
      "Classifier 18/50: error = 0.41830934679826226, alpha = 0.16485877986205752\n",
      "Classifier 19/50: error = 0.4095661963495886, alpha = 0.18287949260081152\n",
      "Classifier 20/50: error = 0.4501618374790013, alpha = 0.10000841398618404\n",
      "Classifier 21/50: error = 0.4450856605501743, alpha = 0.11027349959822803\n",
      "Classifier 22/50: error = 0.42777409882033, alpha = 0.14546929786977328\n",
      "Classifier 23/50: error = 0.4251716926053427, alpha = 0.1507891651829512\n",
      "Classifier 24/50: error = 0.4610485276397476, alpha = 0.07806111530563102\n",
      "Classifier 25/50: error = 0.43460875291463175, alpha = 0.1315358781900191\n",
      "Classifier 26/50: error = 0.4565957387650669, alpha = 0.08702756860483143\n",
      "Classifier 27/50: error = 0.4474616529353965, alpha = 0.10546599755698931\n",
      "Classifier 28/50: error = 0.4578967556118556, alpha = 0.08440636839610668\n",
      "Classifier 29/50: error = 0.44848062055908966, alpha = 0.10340575321853354\n",
      "Classifier 30/50: error = 0.4644543132840697, alpha = 0.07121150278078243\n",
      "Classifier 31/50: error = 0.4475920479176126, alpha = 0.105202303335221\n",
      "Classifier 32/50: error = 0.44566925869391305, alpha = 0.10909220502487946\n",
      "Classifier 33/50: error = 0.4294207601378852, alpha = 0.1421074119680521\n",
      "Classifier 34/50: error = 0.43516875195671667, alpha = 0.1303965595288505\n",
      "Classifier 35/50: error = 0.46037046592289443, alpha = 0.0794256650131325\n",
      "Classifier 36/50: error = 0.44099503518942185, alpha = 0.11856236867567521\n",
      "Classifier 37/50: error = 0.4387573321742759, alpha = 0.12310344438250459\n",
      "Classifier 38/50: error = 0.45225174855873124, alpha = 0.09578839777638821\n",
      "Classifier 39/50: error = 0.45677993317136134, alpha = 0.08665639458193143\n",
      "Classifier 40/50: error = 0.4549927293189021, alpha = 0.09025884796641997\n",
      "Classifier 41/50: error = 0.4808082608212687, alpha = 0.0384023450465974\n",
      "Classifier 42/50: error = 0.4705387571884141, alpha = 0.058990818206085927\n",
      "Classifier 43/50: error = 0.46064954831503513, alpha = 0.07886399661746915\n",
      "Classifier 44/50: error = 0.4517588719107326, alpha = 0.09678331831476744\n",
      "Classifier 45/50: error = 0.4454636562418317, alpha = 0.10950834200819451\n",
      "Classifier 46/50: error = 0.4581916114173874, alpha = 0.08381247506824353\n",
      "Classifier 47/50: error = 0.453125402125682, alpha = 0.09402530434995861\n",
      "Classifier 48/50: error = 0.46376006372413825, alpha = 0.07260719437319828\n",
      "Classifier 49/50: error = 0.43001173358717315, alpha = 0.1409016397958043\n",
      "Classifier 50/50: error = 0.4576211768847316, alpha = 0.08496148787439232\n",
      "Accuracy for digit 9: 0.869\n",
      "Accuracies for all digits: {0: 0.9503, 1: 0.9622, 2: 0.9113, 3: 0.8811, 4: 0.9132, 5: 0.8584, 6: 0.9437, 7: 0.9304, 8: 0.8628, 9: 0.869}\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = run_adaboost_for_all_digits(T=50, A=20, verboseParam=True) # Ejecutamos AdaBoost para todos los dgitos\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Classifier 1/50: error = 0.4041367665681721, alpha = 0.19412890738154484\n",
      "Classifier 2/50: error = 0.3923853820853689, alpha = 0.21864817719050703\n",
      "Classifier 3/50: error = 0.3316592696588827, alpha = 0.3503449864978734\n",
      "Classifier 4/50: error = 0.42129669262611685, alpha = 0.15872630256212605\n",
      "Classifier 5/50: error = 0.4676664848826072, alpha = 0.06475739913816118\n",
      "Classifier 6/50: error = 0.3009617329307832, alpha = 0.4213611812245938\n",
      "Classifier 7/50: error = 0.339161624307877, alpha = 0.33351626666949763\n",
      "Classifier 8/50: error = 0.1565972245519484, alpha = 0.8418837856699998\n",
      "Classifier 9/50: error = 0.3723021759921057, alpha = 0.26117652650366924\n",
      "Classifier 10/50: error = 0.4351921779980539, alpha = 0.13034890657691928\n",
      "Classifier 11/50: error = 0.23390254936659405, alpha = 0.5932024042911099\n",
      "Classifier 12/50: error = 0.40274457439436284, alpha = 0.1970211599140868\n",
      "Classifier 13/50: error = 0.4157525331767733, alpha = 0.17011721324070667\n",
      "Classifier 14/50: error = 0.41140497729783276, alpha = 0.1790801519711057\n",
      "Classifier 15/50: error = 0.43465444539698844, alpha = 0.13144290410178983\n",
      "Classifier 16/50: error = 0.47544510424373604, alpha = 0.049149329265955576\n",
      "Classifier 17/50: error = 0.3972957574032425, alpha = 0.20837280775241274\n",
      "Classifier 18/50: error = 0.4335572020268328, alpha = 0.133676179711423\n",
      "Classifier 19/50: error = 0.3958145078870593, alpha = 0.2114677848799708\n",
      "Classifier 20/50: error = 0.4265121162209985, alpha = 0.1480480172329107\n",
      "Classifier 21/50: error = 0.42032413107916844, alpha = 0.1607214731352161\n",
      "Classifier 22/50: error = 0.37928259201738834, alpha = 0.24629718301646902\n",
      "Classifier 23/50: error = 0.43367729350876677, alpha = 0.1334316871544832\n",
      "Classifier 24/50: error = 0.3885571887892276, alpha = 0.22669053272700754\n",
      "Classifier 25/50: error = 0.371131385978153, alpha = 0.26368310701277053\n",
      "Classifier 26/50: error = 0.4253586690338243, alpha = 0.15040666686007761\n",
      "Classifier 27/50: error = 0.41967586174089916, alpha = 0.162052075439514\n",
      "Classifier 28/50: error = 0.36440866315733667, alpha = 0.27813993285138455\n",
      "Classifier 29/50: error = 0.4091552115901531, alpha = 0.1837293914899117\n",
      "Classifier 30/50: error = 0.4431797345671973, alpha = 0.11413354771507461\n",
      "Classifier 31/50: error = 0.3290509469320504, alpha = 0.356240307193638\n",
      "Classifier 32/50: error = 0.38695521486855977, alpha = 0.23006451481740528\n",
      "Classifier 33/50: error = 0.392892205322275, alpha = 0.21758553681458323\n",
      "Classifier 34/50: error = 0.39455001072023654, alpha = 0.21411303163401094\n",
      "Classifier 35/50: error = 0.4033624668633975, alpha = 0.19573710127106875\n",
      "Classifier 36/50: error = 0.4175409139907226, alpha = 0.16643820361124245\n",
      "Classifier 37/50: error = 0.4519126459181818, alpha = 0.09647288977620018\n",
      "Classifier 38/50: error = 0.3710334160013009, alpha = 0.26389300047235453\n",
      "Classifier 39/50: error = 0.3563822738615645, alpha = 0.29555049953021284\n",
      "Classifier 40/50: error = 0.4231176187519391, alpha = 0.15499410071572078\n",
      "Classifier 41/50: error = 0.39975798873118484, alpha = 0.20323679504507447\n",
      "Classifier 42/50: error = 0.40969426936447395, alpha = 0.18261469653481696\n",
      "Classifier 43/50: error = 0.43211072022132435, alpha = 0.13662230874153444\n",
      "Classifier 44/50: error = 0.41590301164636423, alpha = 0.1698074784600225\n",
      "Classifier 45/50: error = 0.4280824727817085, alpha = 0.14483946365341827\n",
      "Classifier 46/50: error = 0.4475713668322061, alpha = 0.10524412515753596\n",
      "Classifier 47/50: error = 0.4568975989178443, alpha = 0.08641929633405898\n",
      "Classifier 48/50: error = 0.4219179218426877, alpha = 0.15745253257171818\n",
      "Classifier 49/50: error = 0.4011532310985546, alpha = 0.20033113851717696\n",
      "Classifier 50/50: error = 0.4348275906438404, alpha = 0.13109061233567676\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Classifier 1/50: error = 0.2630720166135132, alpha = 0.5150311745776066\n",
      "Classifier 2/50: error = 0.35400568434507584, alpha = 0.30073886692180163\n",
      "Classifier 3/50: error = 0.3943801376831134, alpha = 0.21446861931490846\n",
      "Classifier 4/50: error = 0.30015781653420115, alpha = 0.4232732328957671\n",
      "Classifier 5/50: error = 0.39302320184470707, alpha = 0.2173109592714949\n",
      "Classifier 6/50: error = 0.41258153142757675, alpha = 0.1766518106139813\n",
      "Classifier 7/50: error = 0.3161351311446017, alpha = 0.3857952926991718\n",
      "Classifier 8/50: error = 0.2818884888738997, alpha = 0.46755665076934955\n",
      "Classifier 9/50: error = 0.40782568135250086, alpha = 0.18648060855965362\n",
      "Classifier 10/50: error = 0.10084484033627916, alpha = 1.0939362543822106\n",
      "Classifier 11/50: error = 0.3858740190110238, alpha = 0.23234457359716335\n",
      "Classifier 12/50: error = 0.38319335314491054, alpha = 0.23800794907754907\n",
      "Classifier 13/50: error = 0.42057880047154905, alpha = 0.16019890721366162\n",
      "Classifier 14/50: error = 0.417260515766785, alpha = 0.16701473391503946\n",
      "Classifier 15/50: error = 0.4178245431403095, alpha = 0.16585514167344886\n",
      "Classifier 16/50: error = 0.43506095085821517, alpha = 0.1306158547302831\n",
      "Classifier 17/50: error = 0.405489387113686, alpha = 0.19132193340568396\n",
      "Classifier 18/50: error = 0.4259526461256239, alpha = 0.14919185506700705\n",
      "Classifier 19/50: error = 0.4252491237687487, alpha = 0.1506307586794611\n",
      "Classifier 20/50: error = 0.43399684747020434, alpha = 0.13278118889703833\n",
      "Classifier 21/50: error = 0.42575132896628964, alpha = 0.14960354311625604\n",
      "Classifier 22/50: error = 0.3923818997322003, alpha = 0.2186554802101246\n",
      "Classifier 23/50: error = 0.40224920881547716, alpha = 0.198051055443794\n",
      "Classifier 24/50: error = 0.4137967763750069, alpha = 0.17414577619820562\n",
      "Classifier 25/50: error = 0.42069258530692033, alpha = 0.1599654557861387\n",
      "Classifier 26/50: error = 0.39982114283403425, alpha = 0.2031052008964138\n",
      "Classifier 27/50: error = 0.4355949425571934, alpha = 0.1295296999639297\n",
      "Classifier 28/50: error = 0.4224282844609276, alpha = 0.15640646295261748\n",
      "Classifier 29/50: error = 0.43904835697047057, alpha = 0.12251257219424004\n",
      "Classifier 30/50: error = 0.41718892143113545, alpha = 0.1671619575429149\n",
      "Classifier 31/50: error = 0.4601547944086092, alpha = 0.07985974982990224\n",
      "Classifier 32/50: error = 0.44386606388292116, alpha = 0.11274314924457134\n",
      "Classifier 33/50: error = 0.4000895692922958, alpha = 0.20254595828186048\n",
      "Classifier 34/50: error = 0.3821683542863622, alpha = 0.24017738638012093\n",
      "Classifier 35/50: error = 0.4517901388724437, alpha = 0.0967201971885453\n",
      "Classifier 36/50: error = 0.467541033886412, alpha = 0.06500935887535646\n",
      "Classifier 37/50: error = 0.4374611149916048, alpha = 0.1257362193569265\n",
      "Classifier 38/50: error = 0.3843691449781595, alpha = 0.2355220583055758\n",
      "Classifier 39/50: error = 0.4314183509611037, alpha = 0.1380333267472529\n",
      "Classifier 40/50: error = 0.45451962178992567, alpha = 0.09121287468239209\n",
      "Classifier 41/50: error = 0.4347343435403948, alpha = 0.13128033449278628\n",
      "Classifier 42/50: error = 0.44522753979254187, alpha = 0.1099862855839999\n",
      "Classifier 43/50: error = 0.45551909442819527, alpha = 0.08919761918491775\n",
      "Classifier 44/50: error = 0.39145920019269864, alpha = 0.22059133198113962\n",
      "Classifier 45/50: error = 0.45870415596030334, alpha = 0.08278025706863187\n",
      "Classifier 46/50: error = 0.41587677798013456, alpha = 0.16986147375341237\n",
      "Classifier 47/50: error = 0.31586741742082824, alpha = 0.3864145862139568\n",
      "Classifier 48/50: error = 0.3983796124230876, alpha = 0.20611065506840184\n",
      "Classifier 49/50: error = 0.431839528198227, alpha = 0.13717492140558\n",
      "Classifier 50/50: error = 0.41494487806347546, alpha = 0.17178019039498704\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Classifier 1/50: error = 0.27139979859013086, alpha = 0.4937660777456382\n",
      "Classifier 2/50: error = 0.39243221320282196, alpha = 0.21854996750665093\n",
      "Classifier 3/50: error = 0.39908231297938046, alpha = 0.2046451356158315\n",
      "Classifier 4/50: error = 0.39744990409006853, alpha = 0.20805095492762604\n",
      "Classifier 5/50: error = 0.4046327245535491, alpha = 0.19309934098968295\n",
      "Classifier 6/50: error = 0.3791929344994467, alpha = 0.24648760621328744\n",
      "Classifier 7/50: error = 0.45307864113648666, alpha = 0.09411965640775483\n",
      "Classifier 8/50: error = 0.4120672442817721, alpha = 0.17771301497761088\n",
      "Classifier 9/50: error = 0.31321592734459003, alpha = 0.3925635607537369\n",
      "Classifier 10/50: error = 0.39017853327002167, alpha = 0.22328091237693287\n",
      "Classifier 11/50: error = 0.4252385062805878, alpha = 0.1506524791950725\n",
      "Classifier 12/50: error = 0.39304348622348473, alpha = 0.2172684447313426\n",
      "Classifier 13/50: error = 0.43439302706059235, alpha = 0.1319748631209733\n",
      "Classifier 14/50: error = 0.4504982771708588, alpha = 0.09932882814228781\n",
      "Classifier 15/50: error = 0.4207605315287845, alpha = 0.15982605931725008\n",
      "Classifier 16/50: error = 0.4110810512059221, alpha = 0.1797490830076497\n",
      "Classifier 17/50: error = 0.397782205161398, alpha = 0.207357266475243\n",
      "Classifier 18/50: error = 0.3718728268951871, alpha = 0.2620953590807392\n",
      "Classifier 19/50: error = 0.35406984820290077, alpha = 0.30059858433898223\n",
      "Classifier 20/50: error = 0.39017126757243964, alpha = 0.22329618039615562\n",
      "Classifier 21/50: error = 0.42104542516373844, alpha = 0.15924164690166356\n",
      "Classifier 22/50: error = 0.43647735702067925, alpha = 0.1277355076932556\n",
      "Classifier 23/50: error = 0.4311768740779142, alpha = 0.1385255741911072\n",
      "Classifier 24/50: error = 0.4366410688541018, alpha = 0.1274027266025437\n",
      "Classifier 25/50: error = 0.45986853556394647, alpha = 0.0804359530855566\n",
      "Classifier 26/50: error = 0.42970572946097274, alpha = 0.14152593366694285\n",
      "Classifier 27/50: error = 0.43312179621706587, alpha = 0.1345627497201763\n",
      "Classifier 28/50: error = 0.40830007814311253, alpha = 0.18549861391463868\n",
      "Classifier 29/50: error = 0.41472861449803, alpha = 0.17222564054081052\n",
      "Classifier 30/50: error = 0.44356875419284275, alpha = 0.11334539971084946\n",
      "Classifier 31/50: error = 0.44563806067771694, alpha = 0.10915534702308698\n",
      "Classifier 32/50: error = 0.4596108633192844, alpha = 0.08095466066198703\n",
      "Classifier 33/50: error = 0.46384539538281144, alpha = 0.07243563190177228\n",
      "Classifier 34/50: error = 0.40964946107436206, alpha = 0.18270733657929508\n",
      "Classifier 35/50: error = 0.41961107063549025, alpha = 0.16218509332833925\n",
      "Classifier 36/50: error = 0.4447958104433827, alpha = 0.11086031561299393\n",
      "Classifier 37/50: error = 0.38704541326082986, alpha = 0.22987440820069752\n",
      "Classifier 38/50: error = 0.4058274134153472, alpha = 0.19062092388679572\n",
      "Classifier 39/50: error = 0.4343648059808742, alpha = 0.13203229450770182\n",
      "Classifier 40/50: error = 0.4349504191141693, alpha = 0.13084071773945338\n",
      "Classifier 41/50: error = 0.4482876472970935, alpha = 0.10379585700179786\n",
      "Classifier 42/50: error = 0.44101625993242055, alpha = 0.11851931989317968\n",
      "Classifier 43/50: error = 0.43683399325141103, alpha = 0.12701060042745763\n",
      "Classifier 44/50: error = 0.42308764672701793, alpha = 0.15505549695990556\n",
      "Classifier 45/50: error = 0.4545645467110983, alpha = 0.09112227597935174\n",
      "Classifier 46/50: error = 0.42732433214329096, alpha = 0.146388123378299\n",
      "Classifier 47/50: error = 0.45021465608786626, alpha = 0.09990171782572758\n",
      "Classifier 48/50: error = 0.436379107738566, alpha = 0.12793523494472664\n",
      "Classifier 49/50: error = 0.4305503118849271, alpha = 0.13980312471969347\n",
      "Classifier 50/50: error = 0.4586607514115102, alpha = 0.08286766302293204\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Classifier 1/50: error = 0.4338499184339315, alpha = 0.13308027027170158\n",
      "Classifier 2/50: error = 0.4303924391190719, alpha = 0.14012509619031027\n",
      "Classifier 3/50: error = 0.4090499541747997, alpha = 0.18394710149831264\n",
      "Classifier 4/50: error = 0.4496870015628588, alpha = 0.10096770785546262\n",
      "Classifier 5/50: error = 0.3978253705315264, alpha = 0.20726717192114186\n",
      "Classifier 6/50: error = 0.4028161760064852, alpha = 0.19687232993068593\n",
      "Classifier 7/50: error = 0.33463946100036757, alpha = 0.3436376705255776\n",
      "Classifier 8/50: error = 0.3949816726498959, alpha = 0.2132096925773992\n",
      "Classifier 9/50: error = 0.4619756274535767, alpha = 0.07619586298764429\n",
      "Classifier 10/50: error = 0.45981905046719584, alpha = 0.0805355657894124\n",
      "Classifier 11/50: error = 0.4611342493698831, alpha = 0.07788862734060648\n",
      "Classifier 12/50: error = 0.4542304685598505, alpha = 0.09179603688614486\n",
      "Classifier 13/50: error = 0.30214396402888544, alpha = 0.4185546116202407\n",
      "Classifier 14/50: error = 0.41569748545365615, alpha = 0.17023052785276255\n",
      "Classifier 15/50: error = 0.4547189461284793, alpha = 0.09081091480004388\n",
      "Classifier 16/50: error = 0.41325414693358514, alpha = 0.1752644977119747\n",
      "Classifier 17/50: error = 0.3722972822015629, alpha = 0.2611869970741689\n",
      "Classifier 18/50: error = 0.41778174246811206, alpha = 0.16594312067624284\n",
      "Classifier 19/50: error = 0.4414239386718046, alpha = 0.11769253595848628\n",
      "Classifier 20/50: error = 0.36210294791554787, alpha = 0.28312417596678824\n",
      "Classifier 21/50: error = 0.3094042979297853, alpha = 0.401452866033917\n",
      "Classifier 22/50: error = 0.4643729356330364, alpha = 0.07137508672756332\n",
      "Classifier 23/50: error = 0.45158922282324876, alpha = 0.09712581596598038\n",
      "Classifier 24/50: error = 0.4578267845159698, alpha = 0.08454731164053696\n",
      "Classifier 25/50: error = 0.4543683508145937, alpha = 0.09151794918131344\n",
      "Classifier 26/50: error = 0.4410916993352272, alpha = 0.11836631453726139\n",
      "Classifier 27/50: error = 0.4513012918609065, alpha = 0.09770716012926353\n",
      "Classifier 28/50: error = 0.45757927431624734, alpha = 0.08504590001602208\n",
      "Classifier 29/50: error = 0.4262388044076877, alpha = 0.14860675560270045\n",
      "Classifier 30/50: error = 0.47717591413206095, alpha = 0.04567991797127373\n",
      "Classifier 31/50: error = 0.4495664119933328, alpha = 0.10121136003478044\n",
      "Classifier 32/50: error = 0.4478836372565542, alpha = 0.10461268284011493\n",
      "Classifier 33/50: error = 0.4587574735587472, alpha = 0.08267289042755016\n",
      "Classifier 34/50: error = 0.4752263492307841, alpha = 0.04958790649121094\n",
      "Classifier 35/50: error = 0.45832282855810824, alpha = 0.08354819882248186\n",
      "Classifier 36/50: error = 0.4427111524612562, alpha = 0.11508307569903878\n",
      "Classifier 37/50: error = 0.41341647814213645, alpha = 0.17492977932290313\n",
      "Classifier 38/50: error = 0.45768052546334537, alpha = 0.08484193305448307\n",
      "Classifier 39/50: error = 0.39020828795123685, alpha = 0.22321838744001896\n",
      "Classifier 40/50: error = 0.34601708958222455, alpha = 0.3182965272129452\n",
      "Classifier 41/50: error = 0.450743044043151, alpha = 0.098834472803163\n",
      "Classifier 42/50: error = 0.44772455848107373, alpha = 0.10493434576341303\n",
      "Classifier 43/50: error = 0.4533230249269318, alpha = 0.09362656905198653\n",
      "Classifier 44/50: error = 0.3984657938269234, alpha = 0.20593087230393187\n",
      "Classifier 45/50: error = 0.45808810715834136, alpha = 0.08402094476902053\n",
      "Classifier 46/50: error = 0.44136827618076235, alpha = 0.11780541158824791\n",
      "Classifier 47/50: error = 0.4504424140514023, alpha = 0.09944166158731026\n",
      "Classifier 48/50: error = 0.46383095654713546, alpha = 0.07246466141810391\n",
      "Classifier 49/50: error = 0.47394367186686426, alpha = 0.0521599078896365\n",
      "Classifier 50/50: error = 0.48106354631835435, alpha = 0.03789103071349621\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Classifier 1/50: error = 0.45502011469656756, alpha = 0.09020363007380615\n",
      "Classifier 2/50: error = 0.40753087159059953, alpha = 0.18709103965446439\n",
      "Classifier 3/50: error = 0.41047614528951937, alpha = 0.18099868461991997\n",
      "Classifier 4/50: error = 0.396930935241417, alpha = 0.20913471321508714\n",
      "Classifier 5/50: error = 0.4392247104476271, alpha = 0.12215456041582953\n",
      "Classifier 6/50: error = 0.1828569062403213, alpha = 0.7485551553003805\n",
      "Classifier 7/50: error = 0.36602223947267937, alpha = 0.2746598902659985\n",
      "Classifier 8/50: error = 0.27252967457696053, alpha = 0.49091285124160916\n",
      "Classifier 9/50: error = 0.3742729937551956, alpha = 0.25696436132205097\n",
      "Classifier 10/50: error = 0.3743363177654132, alpha = 0.25682916954933727\n",
      "Classifier 11/50: error = 0.38915887921816217, alpha = 0.2254246018551329\n",
      "Classifier 12/50: error = 0.39641482967295016, alpha = 0.2102129725798024\n",
      "Classifier 13/50: error = 0.439574841893156, alpha = 0.12144385759051127\n",
      "Classifier 14/50: error = 0.4160255391182802, alpha = 0.16955529997392\n",
      "Classifier 15/50: error = 0.39721513763519967, alpha = 0.20854115592028927\n",
      "Classifier 16/50: error = 0.41789900155788196, alpha = 0.16570209459417817\n",
      "Classifier 17/50: error = 0.44709096106893254, alpha = 0.10621571757590852\n",
      "Classifier 18/50: error = 0.44233738324970695, alpha = 0.11584062428429863\n",
      "Classifier 19/50: error = 0.42910876185550934, alpha = 0.14274415220805875\n",
      "Classifier 20/50: error = 0.46009938347001267, alpha = 0.07997128097794284\n",
      "Classifier 21/50: error = 0.43852528718131445, alpha = 0.12357463022668301\n",
      "Classifier 22/50: error = 0.42025661952160726, alpha = 0.16086001728031327\n",
      "Classifier 23/50: error = 0.42105906388037406, alpha = 0.15921367202700937\n",
      "Classifier 24/50: error = 0.44053182094983945, alpha = 0.119501985581278\n",
      "Classifier 25/50: error = 0.4266366824273925, alpha = 0.14779339379417766\n",
      "Classifier 26/50: error = 0.42919776668500775, alpha = 0.14256249541796556\n",
      "Classifier 27/50: error = 0.4391818335081281, alpha = 0.12224160118997494\n",
      "Classifier 28/50: error = 0.431632261657964, alpha = 0.13759732813373537\n",
      "Classifier 29/50: error = 0.4408593948065975, alpha = 0.11883748968547174\n",
      "Classifier 30/50: error = 0.47531155080894516, alpha = 0.049417085420871115\n",
      "Classifier 31/50: error = 0.4501599505321876, alpha = 0.1000122257525529\n",
      "Classifier 32/50: error = 0.4492450940246878, alpha = 0.10186064408689323\n",
      "Classifier 33/50: error = 0.3755636675883371, alpha = 0.2542106817831657\n",
      "Classifier 34/50: error = 0.4488666067942082, alpha = 0.1026255593435311\n",
      "Classifier 35/50: error = 0.4526854959655445, alpha = 0.09491299192686041\n",
      "Classifier 36/50: error = 0.4201797062481687, alpha = 0.16101786266023632\n",
      "Classifier 37/50: error = 0.4391214581803736, alpha = 0.12236416705699299\n",
      "Classifier 38/50: error = 0.4438827889178809, alpha = 0.11270927231449412\n",
      "Classifier 39/50: error = 0.4564245334184167, alpha = 0.0873725895481852\n",
      "Classifier 40/50: error = 0.46732355915284907, alpha = 0.0654461615376508\n",
      "Classifier 41/50: error = 0.4631318744822832, alpha = 0.07387032418834008\n",
      "Classifier 42/50: error = 0.4421796582389135, alpha = 0.1161603381125249\n",
      "Classifier 43/50: error = 0.430597686921411, alpha = 0.13970651196451153\n",
      "Classifier 44/50: error = 0.44877535076980846, alpha = 0.10281000384905502\n",
      "Classifier 45/50: error = 0.43895926038123145, alpha = 0.12269345733138168\n",
      "Classifier 46/50: error = 0.46976555508140483, alpha = 0.060542753170335126\n",
      "Classifier 47/50: error = 0.4656898645701518, alpha = 0.06872828120695994\n",
      "Classifier 48/50: error = 0.405838121005927, alpha = 0.19059872117844034\n",
      "Classifier 49/50: error = 0.46077901635319957, alpha = 0.07860345207567114\n",
      "Classifier 50/50: error = 0.45474838057505884, alpha = 0.0907515594203978\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1/50: error = 0.35409170587692607, alpha = 0.3005507991409799\n",
      "Classifier 2/50: error = 0.3765814107277552, alpha = 0.25204196586902416\n",
      "Classifier 3/50: error = 0.43547187518267394, alpha = 0.12977999556972003\n",
      "Classifier 4/50: error = 0.4276082938992428, alpha = 0.14580799123372548\n",
      "Classifier 5/50: error = 0.44790947115060487, alpha = 0.10456044782803275\n",
      "Classifier 6/50: error = 0.3697410287897369, alpha = 0.2666639809170901\n",
      "Classifier 7/50: error = 0.45256757025634853, alpha = 0.09515097975870183\n",
      "Classifier 8/50: error = 0.38913713549591966, alpha = 0.2254703373191992\n",
      "Classifier 9/50: error = 0.3815163038534156, alpha = 0.2415586225393292\n",
      "Classifier 10/50: error = 0.37615010564556817, alpha = 0.2529607522702776\n",
      "Classifier 11/50: error = 0.39040428683048645, alpha = 0.2228065684819196\n",
      "Classifier 12/50: error = 0.43707193808838796, alpha = 0.12652702198487906\n",
      "Classifier 13/50: error = 0.4016325743048621, alpha = 0.19933365651088913\n",
      "Classifier 14/50: error = 0.41583884961764994, alpha = 0.16993954132309538\n",
      "Classifier 15/50: error = 0.4457491124301305, alpha = 0.10893059214104443\n",
      "Classifier 16/50: error = 0.44114838553807545, alpha = 0.11825134784259116\n",
      "Classifier 17/50: error = 0.463660622826058, alpha = 0.07280712937896582\n",
      "Classifier 18/50: error = 0.47513692479928205, alpha = 0.04976719709166161\n",
      "Classifier 19/50: error = 0.33780501964008636, alpha = 0.3365455903146815\n",
      "Classifier 20/50: error = 0.38778812667798457, alpha = 0.22830964776559368\n",
      "Classifier 21/50: error = 0.42307460206485814, alpha = 0.15508221868192967\n",
      "Classifier 22/50: error = 0.4605519922321273, alpha = 0.07906032784318312\n",
      "Classifier 23/50: error = 0.4315387716278005, alpha = 0.1377878756570077\n",
      "Classifier 24/50: error = 0.4328207755690773, alpha = 0.1351758085578548\n",
      "Classifier 25/50: error = 0.4580614420615082, alpha = 0.08407465257681278\n",
      "Classifier 26/50: error = 0.46799270816463434, alpha = 0.06410224036399455\n",
      "Classifier 27/50: error = 0.43759518301404954, alpha = 0.12546383107633854\n",
      "Classifier 28/50: error = 0.43457382410368217, alpha = 0.13160695211408083\n",
      "Classifier 29/50: error = 0.4121556723730276, alpha = 0.17753052014536969\n",
      "Classifier 30/50: error = 0.44825805166002686, alpha = 0.10385568864155675\n",
      "Classifier 31/50: error = 0.43440781499131365, alpha = 0.1319447692470914\n",
      "Classifier 32/50: error = 0.4618555903810506, alpha = 0.07643733809595646\n",
      "Classifier 33/50: error = 0.4587220171605262, alpha = 0.082744289425082\n",
      "Classifier 34/50: error = 0.45251012103652366, alpha = 0.09526692287430207\n",
      "Classifier 35/50: error = 0.45145830204431137, alpha = 0.09739014213383894\n",
      "Classifier 36/50: error = 0.4202579950323064, alpha = 0.16085719445878988\n",
      "Classifier 37/50: error = 0.3994494932282237, alpha = 0.20387970675451758\n",
      "Classifier 38/50: error = 0.46161074787060663, alpha = 0.07692990830826167\n",
      "Classifier 39/50: error = 0.45310616226457245, alpha = 0.0940641254070772\n",
      "Classifier 40/50: error = 0.46979627738675855, alpha = 0.060481083293615595\n",
      "Classifier 41/50: error = 0.41160975556528223, alpha = 0.17865735172572692\n",
      "Classifier 42/50: error = 0.4328025897823409, alpha = 0.13521284897306285\n",
      "Classifier 43/50: error = 0.4546578550093887, alpha = 0.09093410877679826\n",
      "Classifier 44/50: error = 0.4547225112411459, alpha = 0.09080372561730539\n",
      "Classifier 45/50: error = 0.4374692600052583, alpha = 0.12571967046505247\n",
      "Classifier 46/50: error = 0.4366891846488201, alpha = 0.1273049257768243\n",
      "Classifier 47/50: error = 0.38792309063967245, alpha = 0.22802542171871176\n",
      "Classifier 48/50: error = 0.45041856959748683, alpha = 0.09948982386018618\n",
      "Classifier 49/50: error = 0.44744741277035627, alpha = 0.1054947959394101\n",
      "Classifier 50/50: error = 0.47472807614557466, alpha = 0.0505869549212156\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Classifier 1/50: error = 0.40765784802637145, alpha = 0.18682810623538637\n",
      "Classifier 2/50: error = 0.24166096245332713, alpha = 0.5717974010898469\n",
      "Classifier 3/50: error = 0.4071773448314012, alpha = 0.1878232315861347\n",
      "Classifier 4/50: error = 0.3762167367552326, alpha = 0.25281878426290616\n",
      "Classifier 5/50: error = 0.3924604985862046, alpha = 0.21849065215040342\n",
      "Classifier 6/50: error = 0.40929814182933555, alpha = 0.18343378816467135\n",
      "Classifier 7/50: error = 0.36584680873307224, alpha = 0.2750379306650312\n",
      "Classifier 8/50: error = 0.373731300390004, alpha = 0.25812121022508067\n",
      "Classifier 9/50: error = 0.19672578520206452, alpha = 0.7034426687024292\n",
      "Classifier 10/50: error = 0.2655155515204152, alpha = 0.5087477043916775\n",
      "Classifier 11/50: error = 0.2400097918543621, alpha = 0.5763129134952582\n",
      "Classifier 12/50: error = 0.42550716884731377, alpha = 0.15010291140618784\n",
      "Classifier 13/50: error = 0.3683757578105816, alpha = 0.26959558274580875\n",
      "Classifier 14/50: error = 0.4257697299917522, alpha = 0.149565911437497\n",
      "Classifier 15/50: error = 0.4154208195438832, alpha = 0.17080010460222747\n",
      "Classifier 16/50: error = 0.37731454813328913, alpha = 0.25048115687764844\n",
      "Classifier 17/50: error = 0.38519002559218213, alpha = 0.233788224886897\n",
      "Classifier 18/50: error = 0.4321775766809189, alpha = 0.13648608693435982\n",
      "Classifier 19/50: error = 0.40676055848794745, alpha = 0.1886866967191178\n",
      "Classifier 20/50: error = 0.45649928278685004, alpha = 0.0872219486120465\n",
      "Classifier 21/50: error = 0.37616834817815936, alpha = 0.252921882707111\n",
      "Classifier 22/50: error = 0.4181735344235673, alpha = 0.16513786679738746\n",
      "Classifier 23/50: error = 0.44479358874361596, alpha = 0.110864813848267\n",
      "Classifier 24/50: error = 0.41216781127385604, alpha = 0.17750546921596094\n",
      "Classifier 25/50: error = 0.42793014049834976, alpha = 0.14515057836727566\n",
      "Classifier 26/50: error = 0.4306588898041329, alpha = 0.13958170367205727\n",
      "Classifier 27/50: error = 0.42271141635085696, alpha = 0.1558262855072947\n",
      "Classifier 28/50: error = 0.39188061554923526, alpha = 0.21970698868497246\n",
      "Classifier 29/50: error = 0.4413197707537905, alpha = 0.11790377614455608\n",
      "Classifier 30/50: error = 0.46379748948584265, alpha = 0.07253194796352613\n",
      "Classifier 31/50: error = 0.4167561164651863, alpha = 0.16805211290335464\n",
      "Classifier 32/50: error = 0.37928748829866077, alpha = 0.2462867843311322\n",
      "Classifier 33/50: error = 0.39442526159750013, alpha = 0.214374158222939\n",
      "Classifier 34/50: error = 0.4465763573696502, alpha = 0.10725669502677451\n",
      "Classifier 35/50: error = 0.4487697286486305, alpha = 0.10282136737445713\n",
      "Classifier 36/50: error = 0.39690410125590914, alpha = 0.2091907635490638\n",
      "Classifier 37/50: error = 0.4552009350325935, alpha = 0.08983905079397127\n",
      "Classifier 38/50: error = 0.44240853259140334, alpha = 0.11569640992872166\n",
      "Classifier 39/50: error = 0.44845223842387283, alpha = 0.10346312696080107\n",
      "Classifier 40/50: error = 0.4325662467714244, alpha = 0.13569426085972774\n",
      "Classifier 41/50: error = 0.4100855017771905, alpha = 0.18180596459032158\n",
      "Classifier 42/50: error = 0.4574413313246123, alpha = 0.08532379280310777\n",
      "Classifier 43/50: error = 0.45553521930592566, alpha = 0.08916511225625466\n",
      "Classifier 44/50: error = 0.4347488785988536, alpha = 0.13125076059549512\n",
      "Classifier 45/50: error = 0.4517084089279357, alpha = 0.09688519361209903\n",
      "Classifier 46/50: error = 0.41172671712071296, alpha = 0.1784158926762846\n",
      "Classifier 47/50: error = 0.38942499325731417, alpha = 0.22486493609005617\n",
      "Classifier 48/50: error = 0.41800536629938057, alpha = 0.16548347834835234\n",
      "Classifier 49/50: error = 0.4275324424097728, alpha = 0.14596294581178615\n",
      "Classifier 50/50: error = 0.4661608836803023, alpha = 0.06778184737348318\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Classifier 1/50: error = 0.4571793439221008, alpha = 0.08585161525032356\n",
      "Classifier 2/50: error = 0.36777329358824185, alpha = 0.2708906720438777\n",
      "Classifier 3/50: error = 0.4096368027931619, alpha = 0.1827335078280553\n",
      "Classifier 4/50: error = 0.418894465335322, alpha = 0.16365668397095978\n",
      "Classifier 5/50: error = 0.3290121823431176, alpha = 0.3563281013348451\n",
      "Classifier 6/50: error = 0.3354519625696789, alpha = 0.3418142009672755\n",
      "Classifier 7/50: error = 0.4105574118739139, alpha = 0.18083077342516182\n",
      "Classifier 8/50: error = 0.2520103419731524, alpha = 0.5439595126015684\n",
      "Classifier 9/50: error = 0.2915477523690014, alpha = 0.4439394245078011\n",
      "Classifier 10/50: error = 0.29173325718763043, alpha = 0.44349044796704656\n",
      "Classifier 11/50: error = 0.358538103309879, alpha = 0.29085742259206265\n",
      "Classifier 12/50: error = 0.3432255510384384, alpha = 0.3244764203376249\n",
      "Classifier 13/50: error = 0.42498448458143484, alpha = 0.1511721811588674\n",
      "Classifier 14/50: error = 0.4043218494851015, alpha = 0.1937446436352823\n",
      "Classifier 15/50: error = 0.3965417270293903, alpha = 0.2099478111955794\n",
      "Classifier 16/50: error = 0.30538776991536554, alpha = 0.4108857007426402\n",
      "Classifier 17/50: error = 0.38796255523909956, alpha = 0.22794231847283802\n",
      "Classifier 18/50: error = 0.3848302741858266, alpha = 0.23454790787614377\n",
      "Classifier 19/50: error = 0.453631255688939, alpha = 0.09300472387946931\n",
      "Classifier 20/50: error = 0.37673555011099297, alpha = 0.2517137120251513\n",
      "Classifier 21/50: error = 0.4214276567530808, alpha = 0.15845773102019756\n",
      "Classifier 22/50: error = 0.4471427186693431, alpha = 0.10611103130047259\n",
      "Classifier 23/50: error = 0.4560345908616287, alpha = 0.08815849743301993\n",
      "Classifier 24/50: error = 0.4332266406814289, alpha = 0.13434924704786147\n",
      "Classifier 25/50: error = 0.4429881436038098, alpha = 0.11452176000533548\n",
      "Classifier 26/50: error = 0.4124453893034507, alpha = 0.17693269428004907\n",
      "Classifier 27/50: error = 0.4084736096178384, alpha = 0.18513949465182108\n",
      "Classifier 28/50: error = 0.3643170869434592, alpha = 0.27833763405583956\n",
      "Classifier 29/50: error = 0.37691536515844526, alpha = 0.25133084663980954\n",
      "Classifier 30/50: error = 0.4291972209151427, alpha = 0.1425636092930968\n",
      "Classifier 31/50: error = 0.42613735370319594, alpha = 0.14881417731197155\n",
      "Classifier 32/50: error = 0.4265390042022259, alpha = 0.14799305440461086\n",
      "Classifier 33/50: error = 0.43575592115886574, alpha = 0.1292023244971455\n",
      "Classifier 34/50: error = 0.39118856112742495, alpha = 0.22115944911537946\n",
      "Classifier 35/50: error = 0.4572523802549499, alpha = 0.08570446516176308\n",
      "Classifier 36/50: error = 0.4287134431150369, alpha = 0.14355110183813724\n",
      "Classifier 37/50: error = 0.40589859751755863, alpha = 0.19047332368370248\n",
      "Classifier 38/50: error = 0.42458516463682483, alpha = 0.15198931219082146\n",
      "Classifier 39/50: error = 0.45374484232701684, alpha = 0.09277558477506447\n",
      "Classifier 40/50: error = 0.41851170219991374, alpha = 0.16444299787162445\n",
      "Classifier 41/50: error = 0.4514542677957286, alpha = 0.09739828740810637\n",
      "Classifier 42/50: error = 0.46371426676302185, alpha = 0.07269927262457032\n",
      "Classifier 43/50: error = 0.4524295460107002, alpha = 0.0954295424325364\n",
      "Classifier 44/50: error = 0.4433458786046026, alpha = 0.11379692513784438\n",
      "Classifier 45/50: error = 0.4633916315837132, alpha = 0.07334798999828451\n",
      "Classifier 46/50: error = 0.4630026280976258, alpha = 0.07413023506184184\n",
      "Classifier 47/50: error = 0.46390488151291054, alpha = 0.07231603534473684\n",
      "Classifier 48/50: error = 0.472431419935601, alpha = 0.055193136536121686\n",
      "Classifier 49/50: error = 0.44989439218164506, alpha = 0.1005487013939392\n",
      "Classifier 50/50: error = 0.42112158404645395, alpha = 0.15908543777075357\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Classifier 1/50: error = 0.3820186308862491, alpha = 0.24049446523369344\n",
      "Classifier 2/50: error = 0.42101427888439213, alpha = 0.1593055331106058\n",
      "Classifier 3/50: error = 0.2981240071764125, alpha = 0.4281236042090254\n",
      "Classifier 4/50: error = 0.41434392136206255, alpha = 0.1730181819017054\n",
      "Classifier 5/50: error = 0.4552706864074365, alpha = 0.08969842084857818\n",
      "Classifier 6/50: error = 0.35733303058848154, alpha = 0.2934792258627417\n",
      "Classifier 7/50: error = 0.4209238958847489, alpha = 0.15949093100626333\n",
      "Classifier 8/50: error = 0.41160644581572947, alpha = 0.17866418477477478\n",
      "Classifier 9/50: error = 0.41774521090062466, alpha = 0.16601821522257856\n",
      "Classifier 10/50: error = 0.4522322762508466, alpha = 0.09582770096701329\n",
      "Classifier 11/50: error = 0.40513839826252995, alpha = 0.1920500217258855\n",
      "Classifier 12/50: error = 0.38380883623897843, alpha = 0.23670631986738072\n",
      "Classifier 13/50: error = 0.40396305106972674, alpha = 0.19448962194149683\n",
      "Classifier 14/50: error = 0.4097569395392462, alpha = 0.1824851326799311\n",
      "Classifier 15/50: error = 0.3856522595258848, alpha = 0.23281251946390943\n",
      "Classifier 16/50: error = 0.42494150242711304, alpha = 0.1512601261838176\n",
      "Classifier 17/50: error = 0.4343958856236031, alpha = 0.13196904584265673\n",
      "Classifier 18/50: error = 0.44530679284743035, alpha = 0.10982585710234931\n",
      "Classifier 19/50: error = 0.43851290886464156, alpha = 0.12359976691685733\n",
      "Classifier 20/50: error = 0.4500596078921262, alpha = 0.10021492917630259\n",
      "Classifier 21/50: error = 0.41820722424340306, alpha = 0.1650686337007377\n",
      "Classifier 22/50: error = 0.46297369505642755, alpha = 0.07418841996871585\n",
      "Classifier 23/50: error = 0.433631932677086, alpha = 0.13352403476767807\n",
      "Classifier 24/50: error = 0.46653807497963373, alpha = 0.06702403226777996\n",
      "Classifier 25/50: error = 0.43792432159606065, alpha = 0.12479519307773411\n",
      "Classifier 26/50: error = 0.43178057506609935, alpha = 0.1372950622263002\n",
      "Classifier 27/50: error = 0.4596221732048604, alpha = 0.08093189236636131\n",
      "Classifier 28/50: error = 0.4196734751080913, alpha = 0.16205697516023523\n",
      "Classifier 29/50: error = 0.4136830573515626, alpha = 0.17438019118823317\n",
      "Classifier 30/50: error = 0.40602304803175526, alpha = 0.19021529529503708\n",
      "Classifier 31/50: error = 0.4488025875059729, alpha = 0.10275495287667867\n",
      "Classifier 32/50: error = 0.43129731498449775, alpha = 0.13828004866686308\n",
      "Classifier 33/50: error = 0.4837615719864984, alpha = 0.03248828153189788\n",
      "Classifier 34/50: error = 0.3353222708164497, alpha = 0.3421051167197047\n",
      "Classifier 35/50: error = 0.4537189889279756, alpha = 0.09282773815958262\n",
      "Classifier 36/50: error = 0.44683848247832214, alpha = 0.10672642066995923\n",
      "Classifier 37/50: error = 0.4007114455703906, alpha = 0.20125081389695612\n",
      "Classifier 38/50: error = 0.4396689387517545, alpha = 0.12125287901078584\n",
      "Classifier 39/50: error = 0.42702806629728857, alpha = 0.14699349701590897\n",
      "Classifier 40/50: error = 0.45737337405233225, alpha = 0.085460700825635\n",
      "Classifier 41/50: error = 0.46503923918304, alpha = 0.07003580627186444\n",
      "Classifier 42/50: error = 0.4415968101764335, alpha = 0.11734199610739317\n",
      "Classifier 43/50: error = 0.4469799063985127, alpha = 0.10644034748564402\n",
      "Classifier 44/50: error = 0.4493994931609864, alpha = 0.1015486406252674\n",
      "Classifier 45/50: error = 0.4722671861826834, alpha = 0.05552261166026541\n",
      "Classifier 46/50: error = 0.4627962693794029, alpha = 0.07454523742574119\n",
      "Classifier 47/50: error = 0.4572717590059545, alpha = 0.08566542240860894\n",
      "Classifier 48/50: error = 0.4562420651878717, alpha = 0.08774033082132994\n",
      "Classifier 49/50: error = 0.4696091620746311, alpha = 0.060856693048869794\n",
      "Classifier 50/50: error = 0.47664791414836016, alpha = 0.04673817449329871\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Classifier 1/50: error = 0.4037653387123885, alpha = 0.19490022602687201\n",
      "Classifier 2/50: error = 0.4336737640150761, alpha = 0.13343887257466228\n",
      "Classifier 3/50: error = 0.38531072335126804, alpha = 0.23353340819605217\n",
      "Classifier 4/50: error = 0.2054697982977896, alpha = 0.6762259710744792\n",
      "Classifier 5/50: error = 0.3857635016126604, alpha = 0.2325777694225006\n",
      "Classifier 6/50: error = 0.4455033255376081, alpha = 0.10942804887587351\n",
      "Classifier 7/50: error = 0.3994725126594555, alpha = 0.20383172799769977\n",
      "Classifier 8/50: error = 0.4308940558471569, alpha = 0.1391021802701193\n",
      "Classifier 9/50: error = 0.41738678637248666, alpha = 0.16675509374667696\n",
      "Classifier 10/50: error = 0.42580109662966614, alpha = 0.14950176493600414\n",
      "Classifier 11/50: error = 0.4364303653929179, alpha = 0.1278310339313335\n",
      "Classifier 12/50: error = 0.4704459747628702, alpha = 0.05917703160204048\n",
      "Classifier 13/50: error = 0.4608700166609576, alpha = 0.0784203272796195\n",
      "Classifier 14/50: error = 0.4457295011667697, alpha = 0.10897028209200178\n",
      "Classifier 15/50: error = 0.444776589741136, alpha = 0.1108992315685625\n",
      "Classifier 16/50: error = 0.44134829642484097, alpha = 0.11784592842548602\n",
      "Classifier 17/50: error = 0.4714356983491636, alpha = 0.05719087505227922\n",
      "Classifier 18/50: error = 0.4447535697124798, alpha = 0.1109458404209977\n",
      "Classifier 19/50: error = 0.4380202381122945, alpha = 0.12460036163706557\n",
      "Classifier 20/50: error = 0.46734721557503867, alpha = 0.06539864590092148\n",
      "Classifier 21/50: error = 0.4535154836904338, alpha = 0.09323828154820635\n",
      "Classifier 22/50: error = 0.46047107035026813, alpha = 0.07922318742049962\n",
      "Classifier 23/50: error = 0.42219222673662127, alpha = 0.1568902585852097\n",
      "Classifier 24/50: error = 0.41770675057171847, alpha = 0.16609727654940848\n",
      "Classifier 25/50: error = 0.4340011793195184, alpha = 0.13277237156054764\n",
      "Classifier 26/50: error = 0.4404547269184844, alpha = 0.11965838897349168\n",
      "Classifier 27/50: error = 0.45358179262376835, alpha = 0.09310450910261113\n",
      "Classifier 28/50: error = 0.43746376777345025, alpha = 0.1257308294750841\n",
      "Classifier 29/50: error = 0.40642745555568716, alpha = 0.18937699307048955\n",
      "Classifier 30/50: error = 0.4167715382594893, alpha = 0.1680203901816413\n",
      "Classifier 31/50: error = 0.4344070116176413, alpha = 0.13194640413003508\n",
      "Classifier 32/50: error = 0.4682788341784416, alpha = 0.06352765474661709\n",
      "Classifier 33/50: error = 0.43588352576312306, alpha = 0.12894283990708502\n",
      "Classifier 34/50: error = 0.46717923971493003, alpha = 0.06573604397733115\n",
      "Classifier 35/50: error = 0.46268386898146974, alpha = 0.0747712935596687\n",
      "Classifier 36/50: error = 0.4590903819602582, alpha = 0.08200254948506902\n",
      "Classifier 37/50: error = 0.41607700977802853, alpha = 0.16944937260916265\n",
      "Classifier 38/50: error = 0.45308507713855106, alpha = 0.09410667005557995\n",
      "Classifier 39/50: error = 0.4239938982635807, alpha = 0.1531995948146538\n",
      "Classifier 40/50: error = 0.4599335592507772, alpha = 0.08030506387104822\n",
      "Classifier 41/50: error = 0.45933676595197803, alpha = 0.08150648058436992\n",
      "Classifier 42/50: error = 0.42455780770236107, alpha = 0.15204530022667112\n",
      "Classifier 43/50: error = 0.4610273661190146, alpha = 0.07810369690967743\n",
      "Classifier 44/50: error = 0.4471424727819523, alpha = 0.1061115286332566\n",
      "Classifier 45/50: error = 0.44584137079571196, alpha = 0.10874388106440964\n",
      "Classifier 46/50: error = 0.4450304446857425, alpha = 0.11038528102875436\n",
      "Classifier 47/50: error = 0.4676967873188799, alpha = 0.06469654000182279\n",
      "Classifier 48/50: error = 0.4356667458905491, alpha = 0.1293836731132512\n",
      "Classifier 49/50: error = 0.4658172276932523, alpha = 0.06847235433519235\n",
      "Classifier 50/50: error = 0.4350743931844593, alpha = 0.13058850889496573\n",
      "Multiclass Accuracy: 0.8457\n"
     ]
    }
   ],
   "source": [
    "class AdaBoostMulticlass: # Creamos la clase AdaBoostMulticlass\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.models = [] # Inicializamos los modelos\n",
    "\n",
    "    def fit(self, X, y, verbose=False): # Creamos la funcin fit\n",
    "        for digit in range(10): # Para cada dgito\n",
    "            X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X, y)\n",
    "            model = AdaBoost(T=self.T, A=self.A) # Creamos el clasificador AdaBoost\n",
    "            model.fit(X_train_balanced, Y_train_binary_balanced, verbose) # Ajustamos el clasificador AdaBoost\n",
    "            self.models.append(model) # Aadimos el clasificador AdaBoost\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        model_preds = np.array([model.predict(X) for model in self.models]) # Realizamos las predicciones\n",
    "        return np.argmax(model_preds, axis=0) # Devolvemos el ndice del valor mximo\n",
    "\n",
    "def run_adaboost_multiclass_on_mnist(T=5, A=20, verboseParam=False, n_components=50): # Creamos la funcin run_adaboost_multiclass_on_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1) # Redimensionamos los datos\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Redimensionamos los datos\n",
    "\n",
    "    # Apply PCA\n",
    "    X_train_reduced, X_test_reduced = apply_pca(X_train, X_test, n_components=n_components)\n",
    "\n",
    "    adaboost_multiclass = AdaBoostMulticlass(T=T, A=A) # Creamos el clasificador AdaBoostMulticlass\n",
    "    adaboost_multiclass.fit(X_train_reduced, y_train, verboseParam) # Ajustamos el clasificador AdaBoostMulticlass\n",
    "    y_pred = adaboost_multiclass.predict(X_test_reduced) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test == y_pred) / len(y_test) # Calculamos la precisin\n",
    "    print(f\"Multiclass Accuracy: {accuracy}\") # Mostramos la precisin\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "\n",
    "accuracy = run_adaboost_multiclass_on_mnist(T=50, A=20, verboseParam=True) # Ejecutamos AdaBoostMulticlass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclase con ADABoosti Binario con Mejoras (Version 1: Aadidos los parmetros n_componentes y k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, n_features): # Inicializamos la clase\n",
    "        self.feature_index = np.random.randint(0, n_features) # Elegimos un ndice de caracterstica aleatorio\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.n_features = n_features # Inicializamos el nmero de caractersticas\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "        \n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, verbose=False): # Creamos la funcin fit\n",
    "        n_samples, n_features = X.shape # Obtenemos el nmero de muestras y el nmero de caractersticas\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        for t in range(self.T): # Para cada iteracin\n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): # Para cada clasificador dbil\n",
    "                clf = DecisionStump(n_features) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index]), max(X[:, clf.feature_index])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {t + 1}/{self.T}: error = {min_error}, alpha = {best_clf.alpha}') # Mostramos el error y el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components=50): # Creamos la funcin apply_pca\n",
    "    pca = PCA(n_components=n_components) # Creamos el objeto PCA\n",
    "    X_train_reduced = pca.fit_transform(X_train) # Aplicamos PCA a los datos de entrenamiento\n",
    "    X_test_reduced = pca.transform(X_test) # Aplicamos PCA a los datos de prueba\n",
    "    return X_train_reduced, X_test_reduced # Devolvemos los datos reducidos\n",
    "\n",
    "def select_best_features(X_train, y_train, X_test, k=200): # Creamos la funcin select_best_features\n",
    "    selector = SelectKBest(f_classif, k=k) # Creamos el objeto SelectKBest\n",
    "    X_train_best = selector.fit_transform(X_train, y_train) # Seleccionamos las mejores caractersticas de los datos de entrenamiento\n",
    "    X_test_best = selector.transform(X_test) # Seleccionamos las mejores caractersticas de los datos de prueba\n",
    "    return X_train_best, X_test_best # Devolvemos los datos con las mejores caractersticas\n",
    "\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False, n_components=50, k=200): # Creamos la funcin run_adaboost_on_mnist\n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1) # Redimensionamos los datos para reducir la dimensin de las imagnes a 1D\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Redimensionamos los datos para reducir la dimensin de las imagnes a 1D\n",
    "\n",
    "    X_train_best, X_test_best = select_best_features(X_train, y_train, X_test, k=k) # Seleccionamos las mejores caractersticas\n",
    "\n",
    "\n",
    "    X_train_reduced, X_test_reduced = apply_pca(X_train_best, X_test_best, n_components=n_components) # Aplicamos PCA a los datos\n",
    "\n",
    "    y_train_binary = np.where(y_train == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "\n",
    "    adaboost = AdaBoost(T=T, A=A) # Creamos el clasificador AdaBoost\n",
    "    adaboost.fit(X_train_reduced, y_train_binary, verboseParam) # Ajustamos el clasificador AdaBoost\n",
    "    y_pred = adaboost.predict(X_test_reduced) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 3\n",
      "Classifier 1/5: error = 0.09578333333333311, alpha = 1.1224901549858723\n",
      "Classifier 2/5: error = 0.423811546699126, alpha = 0.15357294594849832\n",
      "Classifier 3/5: error = 0.44594286075021583, alpha = 0.10853849596112296\n",
      "Classifier 4/5: error = 0.43261482746443425, alpha = 0.13559530076075985\n",
      "Classifier 5/5: error = 0.47357464282143635, alpha = 0.05290000448255655\n",
      "Accuracy for digit 3: 0.9003\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_on_mnist(digit=3, T=5, A=20, verboseParam=True)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n",
      "Classifier 1/5: error = 0.06493333333333336, alpha = 1.3336283620106117\n",
      "Classifier 2/5: error = 0.40729086733956765, alpha = 0.18758809260424628\n",
      "Classifier 3/5: error = 0.45367364809500965, alpha = 0.09291920425006518\n",
      "Classifier 4/5: error = 0.36758716202838615, alpha = 0.2712909696472824\n",
      "Classifier 5/5: error = 0.45306292554869954, alpha = 0.09415136693421174\n",
      "Accuracy for digit 0: 0.934\n",
      "Running AdaBoost for digit: 1\n",
      "Classifier 1/5: error = 0.11243333333333305, alpha = 1.033061590861527\n",
      "Classifier 2/5: error = 0.4453157110817808, alpha = 0.10980780466445449\n",
      "Classifier 3/5: error = 0.1714455120615499, alpha = 0.7877085495093323\n",
      "Classifier 4/5: error = 0.2813040656471276, alpha = 0.46900109941991674\n",
      "Classifier 5/5: error = 0.4102413735063475, alpha = 0.18148382156901965\n",
      "Accuracy for digit 1: 0.8865\n",
      "Running AdaBoost for digit: 2\n",
      "Classifier 1/5: error = 0.09931666666666639, alpha = 1.1024201675356724\n",
      "Classifier 2/5: error = 0.40659765491248473, alpha = 0.18902426304933448\n",
      "Classifier 3/5: error = 0.37921790125569543, alpha = 0.24643457767282734\n",
      "Classifier 4/5: error = 0.3869060627791908, alpha = 0.23016811708369078\n",
      "Classifier 5/5: error = 0.43002896293659254, alpha = 0.14086649261262346\n",
      "Accuracy for digit 2: 0.8965\n",
      "Running AdaBoost for digit: 3\n",
      "Classifier 1/5: error = 0.10219999999999974, alpha = 1.08650782385557\n",
      "Classifier 2/5: error = 0.3392567786858214, alpha = 0.33330400715356173\n",
      "Classifier 3/5: error = 0.4018037495315872, alpha = 0.19897754694905645\n",
      "Classifier 4/5: error = 0.45816307580283977, alpha = 0.08386994841179553\n",
      "Classifier 5/5: error = 0.4404138790016704, alpha = 0.11974126095019975\n",
      "Accuracy for digit 3: 0.899\n",
      "Running AdaBoost for digit: 4\n",
      "Classifier 1/5: error = 0.09738333333333335, alpha = 1.1133214355743424\n",
      "Classifier 2/5: error = 0.4223246683662537, alpha = 0.15661881313152382\n",
      "Classifier 3/5: error = 0.23469215245170938, alpha = 0.5910017509445644\n",
      "Classifier 4/5: error = 0.42255997075733776, alpha = 0.15613660606383142\n",
      "Classifier 5/5: error = 0.4685230618983178, alpha = 0.06303724058271912\n",
      "Accuracy for digit 4: 0.9018\n",
      "Running AdaBoost for digit: 5\n",
      "Classifier 1/5: error = 0.09033333333333338, alpha = 1.154785849415778\n",
      "Classifier 2/5: error = 0.40890621963185436, alpha = 0.18424442383523368\n",
      "Classifier 3/5: error = 0.43706179582771343, alpha = 0.12654763303298114\n",
      "Classifier 4/5: error = 0.44099009882411255, alpha = 0.11857238085094904\n",
      "Classifier 5/5: error = 0.3699171721141806, alpha = 0.26628608101979395\n",
      "Accuracy for digit 5: 0.9108\n",
      "Running AdaBoost for digit: 6\n",
      "Classifier 1/5: error = 0.09865000000000004, alpha = 1.106157703038341\n",
      "Classifier 2/5: error = 0.44660665243817943, alpha = 0.10719540558518503\n",
      "Classifier 3/5: error = 0.4046580016358953, alpha = 0.1930468787727354\n",
      "Classifier 4/5: error = 0.3547516543645769, alpha = 0.299108647530328\n",
      "Classifier 5/5: error = 0.3839636209743459, alpha = 0.23637910374876583\n",
      "Accuracy for digit 6: 0.9042\n",
      "Running AdaBoost for digit: 7\n",
      "Classifier 1/5: error = 0.10443333333333304, alpha = 1.0744538774497296\n",
      "Classifier 2/5: error = 0.37481838141768886, alpha = 0.25580030235815276\n",
      "Classifier 3/5: error = 0.4424931577455386, alpha = 0.11552488735401109\n",
      "Classifier 4/5: error = 0.3778648765692736, alpha = 0.24931032348281731\n",
      "Classifier 5/5: error = 0.4434659988972084, alpha = 0.11355356675307499\n",
      "Accuracy for digit 7: 0.8972\n",
      "Running AdaBoost for digit: 8\n",
      "Classifier 1/5: error = 0.09753333333333303, alpha = 1.1124687771255912\n",
      "Classifier 2/5: error = 0.46229559280251675, alpha = 0.0755522411942153\n",
      "Classifier 3/5: error = 0.3548757528680084, alpha = 0.29883759651876357\n",
      "Classifier 4/5: error = 0.396799965914886, alpha = 0.2094082918019669\n",
      "Classifier 5/5: error = 0.43698193336451585, alpha = 0.1267099328433053\n",
      "Accuracy for digit 8: 0.9026\n",
      "Running AdaBoost for digit: 9\n",
      "Classifier 1/5: error = 0.09919999999999973, alpha = 1.103072621098775\n",
      "Classifier 2/5: error = 0.4691282481951643, alpha = 0.061822144323068706\n",
      "Classifier 3/5: error = 0.4574559232965292, alpha = 0.08529439595326087\n",
      "Classifier 4/5: error = 0.40427478418970286, alpha = 0.19384235386469156\n",
      "Classifier 5/5: error = 0.46933335255988473, alpha = 0.06141037623255637\n",
      "Accuracy for digit 9: 0.8991\n",
      "Accuracies for all digits: {0: 0.934, 1: 0.8865, 2: 0.8965, 3: 0.899, 4: 0.9018, 5: 0.9108, 6: 0.9042, 7: 0.8972, 8: 0.9026, 9: 0.8991}\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = run_adaboost_for_all_digits(T=5, A=20, verboseParam=True) # Ejecutamos AdaBoost para todos los dgitos\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Crislt\\anaconda3\\envs\\SIPrac2Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  0   1   2   3   4   5   6   7   8   9  10  11  16  17  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  52  53  54  55  56  57  82  83\n",
      "  84  85 111 112 140 141 168 476 560 644 645 671 672 673 699 700 701 727\n",
      " 728 729 730 754 755 756 757 758 759 780 781 782 783] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Crislt\\anaconda3\\envs\\SIPrac2Python310\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Accuracy: 0.8016\n"
     ]
    }
   ],
   "source": [
    "class AdaBoostMulticlass: # Creamos la clase AdaBoostMulticlass\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A# Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.models = [] # Inicializamos los modelos\n",
    "\n",
    "    def fit(self, X, y, verbose=False): # Creamos la funcin fit\n",
    "        for digit in range(10): # Para cada dgito\n",
    "            y_binary = np.where(y == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "            model = AdaBoost(T=self.T, A=self.A) # Creamos el clasificador AdaBoost\n",
    "            model.fit(X, y_binary, verbose) # Ajustamos el clasificador AdaBoost\n",
    "            self.models.append(model) # Aadimos el clasificador AdaBoost\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        model_preds = np.array([model.predict(X) for model in self.models]) # Realizamos las predicciones\n",
    "        return np.argmax(model_preds, axis=0) # Devolvemos el ndice del valor mximo\n",
    "\n",
    "def run_adaboost_multiclass_on_mnist(T=5, A=20, verboseParam=False, n_components=50, k=200): # Creamos la funcin run_adaboost_multiclass_on_mnist\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1) # Redimensionamos los datos\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Redimensionamos los datos\n",
    "\n",
    "    X_train_best, X_test_best = select_best_features(X_train, y_train, X_test, k=k) # Seleccionamos las mejores caractersticas\n",
    "\n",
    "    X_train_reduced, X_test_reduced = apply_pca(X_train_best, X_test_best, n_components=n_components) # Aplicamos PCA a los datos\n",
    "\n",
    "    adaboost_multiclass = AdaBoostMulticlass(T=T, A=A) # Creamos el clasificador AdaBoostMulticlass\n",
    "    adaboost_multiclass.fit(X_train_reduced, y_train, verboseParam) # Ajustamos el clasificador AdaBoostMulticlass\n",
    "    y_pred = adaboost_multiclass.predict(X_test_reduced) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test == y_pred) / len(y_test) # Calculamos la precisin\n",
    "    print(f\"Multiclass Accuracy: {accuracy}\") # Mostramos la precisin\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "\n",
    "accuracy = run_adaboost_multiclass_on_mnist(T=50, A=20, verboseParam=False) # Ejecutamos AdaBoostMulticlass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 1E: Implementacin de una versin de AdaboostBinario.fit que pare automticamente el entrenamiento \n",
    "cuando detecte sobreentrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "from sklearn.decomposition import PCA # importamos Principal Component Analysis\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, n_features): # Inicializamos la clase\n",
    "        self.feature_index = np.random.randint(0, n_features) # Elegimos un ndice de caracterstica aleatorio\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.n_features = n_features # Inicializamos el nmero de caractersticas\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "        \n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, verbose=False): # Creamos la funcin fit\n",
    "        n_samples, n_features = X.shape # Obtenemos el nmero de muestras y el nmero de caractersticas\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        for t in range(self.T): # Para cada clasificador dbil\n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): # Para cada pixel\n",
    "                clf = DecisionStump(n_features) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index]), max(X[:, clf.feature_index])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {t + 1}/{self.T}: error = {min_error}, alpha = {best_clf.alpha}') # Mostramos el error y el alpha\n",
    "\n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "    \n",
    "    def compute_optimal_number_of_weak_classificators(self, X_verification, y_verification, X_test, y_test, \n",
    "                                                      iterNumber = 100, numberOfTries = 10):\n",
    "        bestAccuracy = 0\n",
    "        newAccuracy = 0\n",
    "        optimalNumberOfWeakClassificators = 5\n",
    "        \n",
    "        while round(newAccuracy, 6) >= round(bestAccuracy, 6):\n",
    "            optimalNumberOfWeakClassificators += 1\n",
    "            bestAccuracy = newAccuracy\n",
    "            newAccuracy = 0\n",
    "            for i in range(iterNumber):\n",
    "                adaboost = AdaBoost(T=optimalNumberOfWeakClassificators, A=numberOfTries)\n",
    "                adaboost.fit(X_verification, y_verification)\n",
    "                y_pred = adaboost.predict(X_test)\n",
    "                partialAccuracy = np.sum(y_test == np.sign(y_pred)) / len(y_test)\n",
    "                newAccuracy += partialAccuracy\n",
    "            newAccuracy /= iterNumber\n",
    "        self.T = optimalNumberOfWeakClassificators\n",
    "        #return optimalNumberOfWeakClassificators\n",
    "\n",
    "    \n",
    "def apply_pca(X_train, X_test, n_components=50): # Creamos la funcin apply_pca\n",
    "    pca = PCA(n_components=n_components) # Creamos el objeto PCA\n",
    "    X_train_reduced = pca.fit_transform(X_train) # Aplicamos PCA a los datos de entrenamiento\n",
    "    X_test_reduced = pca.transform(X_test) # Aplicamos PCA a los datos de prueba\n",
    "    return X_train_reduced, X_test_reduced # Devolvemos los datos reducidos\n",
    "\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False, n_components=50): # Creamos la funcin run_adaboost_on_mnist\n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1) # Aplanamos los datos de entrenamiento reduciendo la dimensin a 1D\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Aplanamos los datos de prueba reduciendo la dimensin a 1D   \n",
    "\n",
    "\n",
    "    X_train_reduced, X_test_reduced = apply_pca(X_train, X_test, n_components=n_components) # Aplicamos PCA a los datos\n",
    "\n",
    "    y_train_binary = np.where(y_train == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) \n",
    "\n",
    "    adaboost = AdaBoost(T=T, A=A)  # Creamos el clasificador AdaBoost\n",
    "    adaboost.fit(X_train_reduced, y_train_binary, verboseParam) # Ajustamos el clasificador AdaBoost\n",
    "    y_pred = adaboost.predict(X_test_reduced) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "\n",
    "\n",
    "\n",
    "def run_adaboost_for_one_digit_with_computation_of_optimal_number_of_weak_classificators(\n",
    "    digit, A=20, verboseParam=False, n_components=50, \n",
    "    split_proportion = 0.90, iterNumber = 100, numberOfTries = 10):\n",
    "    \n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "    num_samples = len(X_train)\n",
    "    split_point = int(split_proportion * num_samples)\n",
    "    \n",
    "    X_True_Train = X_train[:split_point]\n",
    "    y_True_Train = y_train[:split_point]\n",
    "\n",
    "    X_Verification = X_train[split_point:]\n",
    "    y_verification = y_train[split_point:]\n",
    "\n",
    "    X_True_Train = X_True_Train.reshape(X_True_Train.shape[0], -1) \n",
    "    X_Verification = X_Verification.reshape(X_Verification.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Aplanamos los datos de prueba reduciendo la dimensin a 1D   \n",
    "\n",
    "    X_true_train_reduced, X_test_train_reduced = apply_pca(X_True_Train, X_test, n_components=n_components) # Aplicamos PCA a los datos\n",
    "    X_verification_reduced, X_test_verification_reduced = apply_pca(X_Verification, X_test, n_components=n_components) # Aplicamos PCA a los datos\n",
    "    \n",
    "    y_true_train_binary = np.where(y_True_Train == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "    y_verification_binary = np.where(y_verification == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) \n",
    "    \n",
    "    adaboost = AdaBoost(T=9, A=A)  # Creamos el clasificador AdaBoost\n",
    "    \n",
    "    adaboost.compute_optimal_number_of_weak_classificators(\n",
    "        X_verification_reduced, y_verification_binary, X_test_verification_reduced, y_test_binary,\n",
    "        iterNumber = iterNumber, numberOfTries = numberOfTries)\n",
    "    \n",
    "    print(\"The optimal number of weak classificators is: \", adaboost.T)\n",
    "    \n",
    "    adaboost.fit(X_true_train_reduced, y_true_train_binary, verboseParam)\n",
    "    y_pred = adaboost.predict(X_test_train_reduced)\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\")\n",
    "    \n",
    "    return accuracy \n",
    "\n",
    "def run_adaboost_for_all_digits_with_computation_of_optimal_number_of_weak_classificators(\n",
    "    A=20, verboseParam=False, n_components=50, \n",
    "    split_proportion = 0.90, iterNumber = 100, numberOfTries = 10):\n",
    "    \n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_for_one_digit_with_computation_of_optimal_number_of_weak_classificators(\n",
    "            digit, A, verboseParam, n_components, split_proportion, iterNumber, numberOfTries)\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 3\n",
      "Classifier 1/5: error = 0.10220000000000003, alpha = 1.0865078238555685\n",
      "Classifier 2/5: error = 0.45907977648290865, alpha = 0.08202390342839501\n",
      "Classifier 3/5: error = 0.45479312565178, alpha = 0.09066133095088648\n",
      "Classifier 4/5: error = 0.3101342671000804, alpha = 0.3997458325454976\n",
      "Classifier 5/5: error = 0.3633968464888695, alpha = 0.28032549513346844\n",
      "Accuracy for digit 3: 0.899\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_on_mnist(digit=3, T=5, A=20, verboseParam=True)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracies = run_adaboost_for_all_digits(T=5, A=20, verboseParam=True) # Ejecutamos AdaBoost para todos los dgitos\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 3\n",
      "The optimal number of weak classificators is:  8\n",
      "Classifier 1/8: error = 0.10196296296296303, alpha = 1.0878008356802709\n",
      "Classifier 2/8: error = 0.46049299123156895, alpha = 0.07917907007095394\n",
      "Classifier 3/8: error = 0.44313703792545045, alpha = 0.11422005906052599\n",
      "Classifier 4/8: error = 0.37680582081984193, alpha = 0.2515640817889374\n",
      "Classifier 5/8: error = 0.39856886431587335, alpha = 0.2057158745059474\n",
      "Classifier 6/8: error = 0.43957064799317835, alpha = 0.12145236971698917\n",
      "Classifier 7/8: error = 0.4304948700702459, alpha = 0.13991619149231785\n",
      "Classifier 8/8: error = 0.42123258426575716, alpha = 0.15885777952092933\n",
      "Accuracy for digit 3: 0.899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = run_adaboost_for_one_digit_with_computation_of_optimal_number_of_weak_classificators(\n",
    "    digit=3, A=20, verboseParam=True, \n",
    "    n_components=50, split_proportion=0.90,\n",
    "    iterNumber = 100, numberOfTries=10)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[209], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_accuracies \u001b[38;5;241m=\u001b[39m  \u001b[43mrun_adaboost_for_all_digits_with_computation_of_optimal_number_of_weak_classificators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverboseParam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_proportion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterNumber\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumberOfTries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracies for all digits:\u001b[39m\u001b[38;5;124m\"\u001b[39m, all_accuracies) \u001b[38;5;66;03m# Imprimimos las precisiones\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[208], line 175\u001b[0m, in \u001b[0;36mrun_adaboost_for_all_digits_with_computation_of_optimal_number_of_weak_classificators\u001b[1;34m(A, verboseParam, n_components, split_proportion, iterNumber, numberOfTries)\u001b[0m\n\u001b[0;32m    173\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m# Inicializamos las precisiones\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m digit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m): \u001b[38;5;66;03m# Para cada dgito\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_adaboost_for_one_digit_with_computation_of_optimal_number_of_weak_classificators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdigit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverboseParam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_proportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterNumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumberOfTries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     accuracies[digit] \u001b[38;5;241m=\u001b[39m accuracy \u001b[38;5;66;03m# Guardamos la precisin\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracies\n",
      "Cell \u001b[1;32mIn[208], line 156\u001b[0m, in \u001b[0;36mrun_adaboost_for_one_digit_with_computation_of_optimal_number_of_weak_classificators\u001b[1;34m(digit, A, verboseParam, n_components, split_proportion, iterNumber, numberOfTries)\u001b[0m\n\u001b[0;32m    152\u001b[0m y_test_binary \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_test \u001b[38;5;241m==\u001b[39m digit, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m    154\u001b[0m adaboost \u001b[38;5;241m=\u001b[39m AdaBoost(T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, A\u001b[38;5;241m=\u001b[39mA)  \u001b[38;5;66;03m# Creamos el clasificador AdaBoost\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[43madaboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_optimal_number_of_weak_classificators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_verification_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_verification_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_verification_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_binary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterNumber\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miterNumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumberOfTries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumberOfTries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe optimal number of weak classificators is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, adaboost\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    162\u001b[0m adaboost\u001b[38;5;241m.\u001b[39mfit(X_true_train_reduced, y_true_train_binary, verboseParam)\n",
      "Cell \u001b[1;32mIn[208], line 80\u001b[0m, in \u001b[0;36mAdaBoost.compute_optimal_number_of_weak_classificators\u001b[1;34m(self, X_verification, y_verification, X_test, y_test, iterNumber, numberOfTries)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterNumber):\n\u001b[0;32m     79\u001b[0m     adaboost \u001b[38;5;241m=\u001b[39m AdaBoost(T\u001b[38;5;241m=\u001b[39moptimalNumberOfWeakClassificators, A\u001b[38;5;241m=\u001b[39mnumberOfTries)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43madaboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_verification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_verification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m adaboost\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     82\u001b[0m     partialAccuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y_test \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39msign(y_pred)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_test)\n",
      "Cell \u001b[1;32mIn[208], line 41\u001b[0m, in \u001b[0;36mAdaBoost.fit\u001b[1;34m(self, X, Y, verbose)\u001b[0m\n\u001b[0;32m     39\u001b[0m clf\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;28mmin\u001b[39m(X[:, clf\u001b[38;5;241m.\u001b[39mfeature_index]), \u001b[38;5;28mmax\u001b[39m(X[:, clf\u001b[38;5;241m.\u001b[39mfeature_index])) \u001b[38;5;66;03m# Elegimos un umbral aleatorio\u001b[39;00m\n\u001b[0;32m     40\u001b[0m clf\u001b[38;5;241m.\u001b[39mpolarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Elegimos una polaridad\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Realizamos las predicciones\u001b[39;00m\n\u001b[0;32m     42\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(w[Y \u001b[38;5;241m!=\u001b[39m predictions]) \u001b[38;5;66;03m# Calculamos el error\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m: \u001b[38;5;66;03m# Si el error es mayor que 0.5\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_accuracies =  run_adaboost_for_all_digits_with_computation_of_optimal_number_of_weak_classificators(\n",
    "    A=100, verboseParam=True, \n",
    "    n_components=50, split_proportion=0.75,\n",
    "    iterNumber = 500, numberOfTries=20)\n",
    "print(\"Accuracies for all digits:\", all_accuracies) # Imprimimos las precisiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERSIN BUENA BUENSIMA TAREA 1E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # la libreera numpy sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # importamos el dataset MNIST\n",
    "from sklearn.decomposition import PCA # importamos Principal Component Analysis\n",
    "\n",
    "class DecisionStump: # Creamos la clase DecisionStump\n",
    "    def __init__(self, n_features): # Inicializamos la clase\n",
    "        self.feature_index = np.random.randint(0, n_features) # Elegimos un ndice de caracterstica aleatorio\n",
    "        self.threshold = None # Inicializamos el umbral\n",
    "        self.polarity = 1 # Inicializamos la polaridad\n",
    "        self.n_features = n_features # Inicializamos el nmero de caractersticas\n",
    "        self.alpha = None # Inicializamos el alpha\n",
    "        \n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        n_samples = X.shape[0] # Obtenemos el nmero de muestras\n",
    "        X_column = X[:, self.feature_index] # Obtenemos la columna de la caracterstica\n",
    "        predictions = np.ones(n_samples) # Inicializamos las predicciones\n",
    "        if self.polarity == 1: # Si la polaridad es 1\n",
    "            predictions[X_column < self.threshold] = -1 # Si la columna de la caracterstica es menor que el umbral, la prediccin es -1\n",
    "        else: # Si la polaridad no es 1\n",
    "            predictions[X_column >= self.threshold] = -1 # Si la columna de la caracterstica es mayor o igual que el umbral, la prediccin es -1\n",
    "        return predictions # Devolvemos las predicciones\n",
    "\n",
    "class AdaBoost: # Creamos la clase AdaBoost\n",
    "    def __init__(self, T=5, A=20): # Inicializamos la clase\n",
    "        self.T = T # Inicializamos el nmero de clasificadores dbiles\n",
    "        self.A = A # Inicializamos el nmero de pxeles mximos a probar por clasificador dbil\n",
    "        self.clfs = [] # Inicializamos los clasificadores dbiles\n",
    "\n",
    "    def fit(self, X, Y, X_Verification, Y_Verification, iter_number = 100, \n",
    "            verbose=False, round1 = 3, round2 = 3, \n",
    "            bestAccuracyBreak = 0.999 ,practicalAccuracyBreak=666): # Creamos la funcin fit\n",
    "        bestAccuracy = 0\n",
    "        newAccuracy = 0\n",
    "        practicalRepeatAccuracy = 0\n",
    "        t = 0\n",
    "        \n",
    "        n_samples, n_features = X.shape # Obtenemos el nmero de muestras y el nmero de caractersticas\n",
    "        w = np.full(n_samples, (1 / n_samples)) # Inicializamos los pesos\n",
    "\n",
    "        while (True):\n",
    "            if newAccuracy >= bestAccuracyBreak:\n",
    "                print(\"Se para el entrenamiento debido a que la precisin ha alcanzado el valor prctico buscado\")\n",
    "                print(f\"El nmero ptimo de clasificadores dbiles es: {len(self.clfs)} \")\n",
    "                print(f\"La precisin obtenida en el entrenamiento ha sido de: {round(newAccuracy, round2)}\")\n",
    "                break\n",
    "            \n",
    "            if practicalRepeatAccuracy == practicalAccuracyBreak:\n",
    "                print(\"Se para el entrenamiento debido a que la precisin se ha quedado estancada en un intervalo\")\n",
    "                print(\"Se para el entrenamiento debido a que la precisin ha alcanzado el valor prctico buscado\")\n",
    "                print(f\"El nmero ptimo de clasificadores dbiles es: {len(self.clfs)} \")\n",
    "                print(f\"La precisin obtenida en el entrenamiento ha sido de: {round(newAccuracy, round2)}\")\n",
    "                break\n",
    "            \n",
    "            if round(newAccuracy, round1) == round(bestAccuracy, round1):\n",
    "                practicalRepeatAccuracy += 1\n",
    "            else:\n",
    "                practicalRepeatAccuracy = 0\n",
    "                \n",
    "            bestAccuracy = newAccuracy\n",
    "            newAccuracy = 0\n",
    "            t += 1\n",
    "            \n",
    "            min_error = float('inf') # Inicializamos el error mnimo\n",
    "            best_clf = None # Inicializamos el mejor clasificador dbil\n",
    "\n",
    "            for _ in range(self.A): \n",
    "                clf = DecisionStump(n_features) # Creamos un clasificador dbil\n",
    "                clf.threshold = np.random.uniform(min(X[:, clf.feature_index]), max(X[:, clf.feature_index])) # Elegimos un umbral aleatorio\n",
    "                clf.polarity = 1 # Elegimos una polaridad\n",
    "                predictions = clf.predict(X) # Realizamos las predicciones\n",
    "                error = np.sum(w[Y != predictions]) # Calculamos el error\n",
    "                if error > 0.5: # Si el error es mayor que 0.5\n",
    "                    error = 1 - error # El error es 1 menos el error\n",
    "                    clf.polarity = -1 # La polaridad es -1\n",
    "\n",
    "                if error < min_error: # Si el error es menor que el error mnimo\n",
    "                    min_error = error # El error mnimo es el error\n",
    "                    best_clf = clf # El mejor clasificador dbil es el clasificador dbil\n",
    "\n",
    "            EPS = 1e-10 # Definimos un valor muy pequeo\n",
    "            best_clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS)) # Calculamos el alpha\n",
    "            predictions = best_clf.predict(X) # Realizamos las predicciones\n",
    "            w *= np.exp(-best_clf.alpha * Y * predictions) # Actualizamos los pesos\n",
    "            w /= np.sum(w)  # Normalizamos los pesos\n",
    "            self.clfs.append(best_clf) # Aadimos el mejor clasificador dbil\n",
    "            \n",
    "            for i in range(iter_number):\n",
    "                y_pred_verification = self.predict(X_Verification)\n",
    "                partialAccuracy = np.sum(Y_Verification == np.sign(y_pred_verification)) / len(Y_Verification)\n",
    "                newAccuracy += partialAccuracy\n",
    "            \n",
    "            newAccuracy /= iter_number\n",
    "            if t == 6:\n",
    "                print(\"\")\n",
    "            #if newAccuracy < bestAccuracy:\n",
    "            if round(newAccuracy, round2) < round(bestAccuracy, round2) and self.T > 10:\n",
    "                self.clfs.pop() # Borramos el ltimo clasificador dbil\n",
    "                t = t - 1\n",
    "                print(\"Se ha detectado sobreentrenamiento. El nmero ptimo de clasificadores dbiles es: \", t)\n",
    "                break\n",
    "\n",
    "            if verbose: # Si verbose es True\n",
    "                print(f'Classifier {len(self.clfs)}: error = {min_error}, alpha = {best_clf.alpha}, newAccuracy = {newAccuracy}, bestAccuracy = {bestAccuracy}') # Mostramos el error y el alpha\n",
    "        self.T = t\n",
    "        \n",
    "    def predict(self, X): # Creamos la funcin predict\n",
    "        clf_preds = np.zeros(X.shape[0]) # Inicializamos las predicciones\n",
    "        for clf in self.clfs: # Para cada clasificador dbil\n",
    "            predictions = clf.predict(X) # Realizamos las predicciones\n",
    "            clf_preds += clf.alpha * predictions # Actualizamos las predicciones\n",
    "        return clf_preds # Devolvemos las predicciones\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components=50): # Creamos la funcin apply_pca\n",
    "    pca = PCA(n_components=n_components) # Creamos el objeto PCA\n",
    "    X_train_reduced = pca.fit_transform(X_train) # Aplicamos PCA a los datos de entrenamiento\n",
    "    X_test_reduced = pca.transform(X_test) # Aplicamos PCA a los datos de prueba\n",
    "    return X_train_reduced, X_test_reduced # Devolvemos los datos reducidos\n",
    "\n",
    "\n",
    "def run_adaboost_on_mnist(digit, T=5, A=20, verboseParam=False, n_components=50): # Creamos la funcin run_adaboost_on_mnist\n",
    "    print(f\"Running AdaBoost for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data() # Cargamos los datos\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1) # Aplanamos los datos de entrenamiento reduciendo la dimensin a 1D\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1) # Aplanamos los datos de prueba reduciendo la dimensin a 1D   \n",
    "\n",
    "\n",
    "    X_train_reduced, X_test_reduced = apply_pca(X_train, X_test, n_components=n_components) # Aplicamos PCA a los datos\n",
    "\n",
    "    y_train_binary = np.where(y_train == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) \n",
    "\n",
    "    adaboost = AdaBoost(T=T, A=A)  # Creamos el clasificador AdaBoost\n",
    "    adaboost.fit(X_train_reduced, y_train_binary, verboseParam) # Ajustamos el clasificador AdaBoost\n",
    "    y_pred = adaboost.predict(X_test_reduced) # Realizamos las predicciones\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary) # Calculamos la precisin\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits(T=5, A=20, verboseParam=False): # Creamos la funcin run_adaboost_for_all_digits\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_on_mnist(digit, T, A, verboseParam) # Ejecutamos AdaBoost\n",
    "        accuracies[digit] = accuracy # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "\n",
    "def run_adaboost_for_one_digit_detecting_overfitting(digit, A=20, \n",
    "                                                     verboseParam=False, n_components=50,\n",
    "                                                     split_proportion=0.90, iter_number=100,\n",
    "                                                     round1=3, round2=3,\n",
    "                                                     bestAccuracyBreak=0.999, practicalAccuracyBreak=0.95):  # Adjust practicalAccuracyBreak default\n",
    "    print(f\"Running AdaBoost for digit: {digit}\")  # Display the digit\n",
    "\n",
    "    # Load MNIST data\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Balance the dataset for the specified digit\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train)\n",
    "\n",
    "    # Split the balanced dataset into training and verification sets\n",
    "    num_samples = len(X_train_balanced)\n",
    "    split_point = int(split_proportion * num_samples)\n",
    "    \n",
    "    X_True_Train = X_train_balanced[:split_point]\n",
    "    y_True_Train = Y_train_binary_balanced[:split_point]\n",
    "\n",
    "    X_Verification = X_train_balanced[split_point:]\n",
    "    y_verification_binary = Y_train_binary_balanced[split_point:]\n",
    "\n",
    "    # Reshape the datasets to flatten the images\n",
    "    X_True_Train = X_True_Train.reshape(X_True_Train.shape[0], -1)\n",
    "    X_Verification = X_Verification.reshape(X_Verification.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)  # Flatten test data\n",
    "    \n",
    "    # Initialize AdaBoost\n",
    "    adaboost = AdaBoost(T=0, A=A)  # Assuming AdaBoost is defined correctly\n",
    "    \n",
    "    # Train AdaBoost with added parameters for iterative training and validation\n",
    "    adaboost.fit(X_True_Train, y_True_Train, \n",
    "                 X_Verification, y_verification_binary, \n",
    "                 iter_number, verboseParam,\n",
    "                 round1=round1, round2=round2,\n",
    "                 bestAccuracyBreak=bestAccuracyBreak, practicalAccuracyBreak=practicalAccuracyBreak)\n",
    "    \n",
    "    # Predict on test data and calculate accuracy\n",
    "    y_pred = adaboost.predict(X_test)\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1)  # Convert test labels to binary\n",
    "    accuracy = np.sum(y_test_binary == np.sign(y_pred)) / len(y_test_binary)\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Classifier 1: error = 0.3113544101365482, alpha = 0.3968974546771549, newAccuracy = 0.6985239852398523, bestAccuracy = 0\n",
      "Classifier 2: error = 0.36757621005774654, alpha = 0.27131452577886744, newAccuracy = 0.6985239852398523, bestAccuracy = 0.6985239852398523\n",
      "Classifier 3: error = 0.3284689935590015, alpha = 0.3575588720568289, newAccuracy = 0.7531365313653139, bestAccuracy = 0.6985239852398523\n",
      "Classifier 4: error = 0.33439230327539404, alpha = 0.3441927942276345, newAccuracy = 0.7712177121771218, bestAccuracy = 0.7531365313653139\n",
      "Classifier 5: error = 0.3560250545799557, alpha = 0.2963293570927493, newAccuracy = 0.793726937269372, bestAccuracy = 0.7712177121771218\n",
      "\n",
      "Classifier 6: error = 0.4086826259012525, alpha = 0.1847070030882008, newAccuracy = 0.7933579335793363, bestAccuracy = 0.793726937269372\n",
      "Classifier 7: error = 0.4096153065291699, alpha = 0.1827779523496694, newAccuracy = 0.8018450184501846, bestAccuracy = 0.7933579335793363\n",
      "Classifier 8: error = 0.4106421001315417, alpha = 0.18065580317812072, newAccuracy = 0.8184501845018444, bestAccuracy = 0.8018450184501846\n",
      "Classifier 9: error = 0.3934965382014125, alpha = 0.21631908287220508, newAccuracy = 0.8092250922509221, bestAccuracy = 0.8184501845018444\n",
      "Classifier 10: error = 0.415498781596508, alpha = 0.17063959172542795, newAccuracy = 0.8081180811808126, bestAccuracy = 0.8092250922509221\n",
      "Classifier 11: error = 0.4031015670462138, alpha = 0.1962792060898821, newAccuracy = 0.8184501845018444, bestAccuracy = 0.8081180811808126\n",
      "Classifier 12: error = 0.4201117934609887, alpha = 0.1611572433919583, newAccuracy = 0.8202952029520296, bestAccuracy = 0.8184501845018444\n",
      "Classifier 13: error = 0.3917025132943629, alpha = 0.2200806962655684, newAccuracy = 0.8284132841328422, bestAccuracy = 0.8202952029520296\n",
      "Classifier 14: error = 0.4159988126278842, alpha = 0.16961030496557125, newAccuracy = 0.8350553505535053, bestAccuracy = 0.8284132841328422\n",
      "Classifier 15: error = 0.4380130546596249, alpha = 0.12461495277528621, newAccuracy = 0.8298892988929886, bestAccuracy = 0.8350553505535053\n",
      "Classifier 16: error = 0.4153247268222311, alpha = 0.17099795796532913, newAccuracy = 0.8409594095940963, bestAccuracy = 0.8298892988929886\n",
      "Classifier 17: error = 0.39192115568985053, alpha = 0.21962193274675798, newAccuracy = 0.8365313653136538, bestAccuracy = 0.8409594095940963\n",
      "Classifier 18: error = 0.42420369021315385, alpha = 0.15277011396393964, newAccuracy = 0.8394833948339483, bestAccuracy = 0.8365313653136538\n",
      "Classifier 19: error = 0.4185890304143629, alpha = 0.16428412558006142, newAccuracy = 0.8394833948339483, bestAccuracy = 0.8394833948339483\n",
      "Classifier 20: error = 0.43868337611388414, alpha = 0.12325361214040027, newAccuracy = 0.8464944649446486, bestAccuracy = 0.8394833948339483\n",
      "Classifier 21: error = 0.4267893624829455, alpha = 0.14748132931075567, newAccuracy = 0.8405904059040593, bestAccuracy = 0.8464944649446486\n",
      "Classifier 22: error = 0.44771273082892715, alpha = 0.10495826255864599, newAccuracy = 0.8461254612546131, bestAccuracy = 0.8405904059040593\n",
      "Classifier 23: error = 0.43923124478076203, alpha = 0.12214129579187179, newAccuracy = 0.8476014760147595, bestAccuracy = 0.8461254612546131\n",
      "Classifier 24: error = 0.4496907593571885, alpha = 0.1009601153943891, newAccuracy = 0.8494464944649444, bestAccuracy = 0.8476014760147595\n",
      "Classifier 25: error = 0.4323380969057318, alpha = 0.1361590432673456, newAccuracy = 0.8542435424354246, bestAccuracy = 0.8494464944649444\n",
      "Classifier 26: error = 0.4173110714907434, alpha = 0.16691077753866068, newAccuracy = 0.8575645756457558, bestAccuracy = 0.8542435424354246\n",
      "Classifier 27: error = 0.4401113273505721, alpha = 0.12035512673117328, newAccuracy = 0.8627306273062726, bestAccuracy = 0.8575645756457558\n",
      "Classifier 28: error = 0.43432177578442843, alpha = 0.13211986489555436, newAccuracy = 0.8557195571955709, bestAccuracy = 0.8627306273062726\n",
      "Classifier 29: error = 0.4337998603547161, alpha = 0.13318217138939026, newAccuracy = 0.8571955719557203, bestAccuracy = 0.8557195571955709\n",
      "Classifier 30: error = 0.4482920938585786, alpha = 0.10378686773184578, newAccuracy = 0.8601476014760151, bestAccuracy = 0.8571955719557203\n",
      "Classifier 31: error = 0.4527414730967323, alpha = 0.09480002730221024, newAccuracy = 0.8557195571955709, bestAccuracy = 0.8601476014760151\n",
      "Classifier 32: error = 0.4518021178914985, alpha = 0.09669601438450483, newAccuracy = 0.8616236162361617, bestAccuracy = 0.8557195571955709\n",
      "Classifier 33: error = 0.45747717688953704, alpha = 0.08525157892708468, newAccuracy = 0.862361623616237, bestAccuracy = 0.8616236162361617\n",
      "Classifier 34: error = 0.4375341965419757, alpha = 0.12558773602990597, newAccuracy = 0.8682656826568264, bestAccuracy = 0.862361623616237\n",
      "Classifier 35: error = 0.4415656498759488, alpha = 0.11740517922174393, newAccuracy = 0.8678966789667892, bestAccuracy = 0.8682656826568264\n",
      "Classifier 36: error = 0.44614775119405037, alpha = 0.10812388718205701, newAccuracy = 0.8704797047970486, bestAccuracy = 0.8678966789667892\n",
      "Classifier 37: error = 0.45453817309405503, alpha = 0.09117546265856694, newAccuracy = 0.8653136531365319, bestAccuracy = 0.8704797047970486\n",
      "Classifier 38: error = 0.44138400165666747, alpha = 0.1177735222528435, newAccuracy = 0.8686346863468637, bestAccuracy = 0.8653136531365319\n",
      "Classifier 39: error = 0.4638807118875653, alpha = 0.07236462800227415, newAccuracy = 0.8697416974169745, bestAccuracy = 0.8686346863468637\n",
      "Classifier 40: error = 0.4681079512558056, alpha = 0.06387080921819178, newAccuracy = 0.8675276752767538, bestAccuracy = 0.8697416974169745\n",
      "Classifier 41: error = 0.459786434504704, alpha = 0.08060122206919844, newAccuracy = 0.8682656826568264, bestAccuracy = 0.8675276752767538\n",
      "Classifier 42: error = 0.43430528803598556, alpha = 0.13215341950637652, newAccuracy = 0.8719557195571949, bestAccuracy = 0.8682656826568264\n",
      "Classifier 43: error = 0.45929833883380655, alpha = 0.08158384700548976, newAccuracy = 0.8738007380073803, bestAccuracy = 0.8719557195571949\n",
      "Classifier 44: error = 0.44396351144881463, alpha = 0.11254577065444797, newAccuracy = 0.8715867158671593, bestAccuracy = 0.8738007380073803\n",
      "Classifier 45: error = 0.441724825193037, alpha = 0.11708243241394956, newAccuracy = 0.8752767527675267, bestAccuracy = 0.8715867158671593\n",
      "Classifier 46: error = 0.4542797531707145, alpha = 0.09169663563818267, newAccuracy = 0.8738007380073803, bestAccuracy = 0.8752767527675267\n",
      "Classifier 47: error = 0.4551013340144081, alpha = 0.09003986854695609, newAccuracy = 0.8745387453874541, bestAccuracy = 0.8738007380073803\n",
      "Classifier 48: error = 0.46169739725258696, alpha = 0.07675558423232619, newAccuracy = 0.873062730627306, bestAccuracy = 0.8745387453874541\n",
      "Classifier 49: error = 0.44076921873422203, alpha = 0.11902040479796326, newAccuracy = 0.8763837638376378, bestAccuracy = 0.873062730627306\n",
      "Classifier 50: error = 0.461710164297483, alpha = 0.07672989946537918, newAccuracy = 0.8782287822878224, bestAccuracy = 0.8763837638376378\n",
      "Classifier 51: error = 0.4537368934091072, alpha = 0.09279161986530776, newAccuracy = 0.8771217712177116, bestAccuracy = 0.8782287822878224\n",
      "Classifier 52: error = 0.4621146365300877, alpha = 0.07591623352734592, newAccuracy = 0.8745387453874541, bestAccuracy = 0.8771217712177116\n",
      "Classifier 53: error = 0.45982599247073186, alpha = 0.080521591551821, newAccuracy = 0.8782287822878224, bestAccuracy = 0.8745387453874541\n",
      "Classifier 54: error = 0.45913054567332084, alpha = 0.08192168122682929, newAccuracy = 0.8804428044280435, bestAccuracy = 0.8782287822878224\n",
      "Classifier 55: error = 0.44698466890746946, alpha = 0.1064307141552736, newAccuracy = 0.8760147601476024, bestAccuracy = 0.8804428044280435\n",
      "Classifier 56: error = 0.4486083215340374, alpha = 0.10314761743221003, newAccuracy = 0.8774907749077486, bestAccuracy = 0.8760147601476024\n",
      "Classifier 57: error = 0.45839946491568717, alpha = 0.08339385571033496, newAccuracy = 0.8811808118081191, bestAccuracy = 0.8774907749077486\n",
      "Classifier 58: error = 0.46622636578410714, alpha = 0.06765028171540294, newAccuracy = 0.8800738007380079, bestAccuracy = 0.8811808118081191\n",
      "Classifier 59: error = 0.4612825504632221, alpha = 0.07759022904677793, newAccuracy = 0.8800738007380079, bestAccuracy = 0.8800738007380079\n",
      "Classifier 60: error = 0.46169023420498156, alpha = 0.07676999491036071, newAccuracy = 0.8808118081180817, bestAccuracy = 0.8800738007380079\n",
      "Classifier 61: error = 0.4621980653166765, alpha = 0.07574841459177029, newAccuracy = 0.8789667896678971, bestAccuracy = 0.8808118081180817\n",
      "Classifier 62: error = 0.46004503003059805, alpha = 0.0800806855202944, newAccuracy = 0.8808118081180817, bestAccuracy = 0.8789667896678971\n",
      "Classifier 63: error = 0.4620977714389294, alpha = 0.07595015856691394, newAccuracy = 0.8826568265682654, bestAccuracy = 0.8808118081180817\n",
      "Classifier 64: error = 0.45634295581489304, alpha = 0.08753699580679791, newAccuracy = 0.8808118081180817, bestAccuracy = 0.8826568265682654\n",
      "Classifier 65: error = 0.4563238399127053, alpha = 0.08757552144966077, newAccuracy = 0.8841328413284135, bestAccuracy = 0.8808118081180817\n",
      "Classifier 66: error = 0.4611448036442456, alpha = 0.07786739050984036, newAccuracy = 0.8815498154981546, bestAccuracy = 0.8841328413284135\n",
      "Classifier 67: error = 0.46992847066844445, alpha = 0.06021573268182989, newAccuracy = 0.8859778597785984, bestAccuracy = 0.8815498154981546\n",
      "Classifier 68: error = 0.4602480553424293, alpha = 0.07967203867901525, newAccuracy = 0.8848708487084876, bestAccuracy = 0.8859778597785984\n",
      "Classifier 69: error = 0.46365734815170123, alpha = 0.07281371350951545, newAccuracy = 0.8830258302583027, bestAccuracy = 0.8848708487084876\n",
      "Classifier 70: error = 0.4714876225808425, alpha = 0.05708668717105947, newAccuracy = 0.8841328413284135, bestAccuracy = 0.8830258302583027\n",
      "Classifier 71: error = 0.46910503267400916, alpha = 0.06186875318413, newAccuracy = 0.8837638376383764, bestAccuracy = 0.8841328413284135\n",
      "Classifier 72: error = 0.45177441052339484, alpha = 0.09675194917362732, newAccuracy = 0.8845018450184503, bestAccuracy = 0.8837638376383764\n",
      "Classifier 73: error = 0.45635572573376115, alpha = 0.0875112598217353, newAccuracy = 0.8859778597785984, bestAccuracy = 0.8845018450184503\n",
      "Classifier 74: error = 0.46670564566588896, alpha = 0.06668739068228767, newAccuracy = 0.8826568265682654, bestAccuracy = 0.8859778597785984\n",
      "Classifier 75: error = 0.47255472703993406, alpha = 0.05494577367659909, newAccuracy = 0.8852398523985247, bestAccuracy = 0.8826568265682654\n",
      "Classifier 76: error = 0.45177327122034083, alpha = 0.09675424917677854, newAccuracy = 0.8837638376383764, bestAccuracy = 0.8852398523985247\n",
      "Classifier 77: error = 0.4576495169228813, alpha = 0.08490439794633642, newAccuracy = 0.8845018450184503, bestAccuracy = 0.8837638376383764\n",
      "Classifier 78: error = 0.47031319961938717, alpha = 0.059443517114898196, newAccuracy = 0.887453874538745, bestAccuracy = 0.8845018450184503\n",
      "Classifier 79: error = 0.4596007743207833, alpha = 0.08097497122112043, newAccuracy = 0.8848708487084876, bestAccuracy = 0.887453874538745\n",
      "Classifier 80: error = 0.46892953887944233, alpha = 0.06222109366365147, newAccuracy = 0.8878228782287821, bestAccuracy = 0.8848708487084876\n",
      "Classifier 81: error = 0.4690387489153871, alpha = 0.062001829878496215, newAccuracy = 0.8856088560885602, bestAccuracy = 0.8878228782287821\n",
      "Classifier 82: error = 0.47122529917256123, alpha = 0.05761306145980329, newAccuracy = 0.887453874538745, bestAccuracy = 0.8856088560885602\n",
      "Classifier 83: error = 0.4636613599991527, alpha = 0.07280564720378793, newAccuracy = 0.8859778597785984, bestAccuracy = 0.887453874538745\n",
      "Classifier 84: error = 0.473938193900027, alpha = 0.05217089366396678, newAccuracy = 0.8867158671586709, bestAccuracy = 0.8859778597785984\n",
      "Classifier 85: error = 0.46052506925604364, alpha = 0.07911451129487446, newAccuracy = 0.8870848708487096, bestAccuracy = 0.8867158671586709\n",
      "Classifier 86: error = 0.46392539575177205, alpha = 0.0722747920526127, newAccuracy = 0.8863468634686339, bestAccuracy = 0.8870848708487096\n",
      "Classifier 87: error = 0.46426898783230386, alpha = 0.07158404634693036, newAccuracy = 0.887453874538745, bestAccuracy = 0.8863468634686339\n",
      "Classifier 88: error = 0.47326887277312457, alpha = 0.05351327746979684, newAccuracy = 0.887453874538745, bestAccuracy = 0.887453874538745\n",
      "Classifier 89: error = 0.46026975609817483, alpha = 0.07962836123886635, newAccuracy = 0.8885608856088558, bestAccuracy = 0.887453874538745\n",
      "Classifier 90: error = 0.4616647639566891, alpha = 0.07682123642297364, newAccuracy = 0.8863468634686339, bestAccuracy = 0.8885608856088558\n",
      "Classifier 91: error = 0.47493038929952225, alpha = 0.05018130057011744, newAccuracy = 0.8881918819188194, bestAccuracy = 0.8863468634686339\n",
      "Classifier 92: error = 0.4591169546142888, alpha = 0.08194904623815484, newAccuracy = 0.8900369003690044, bestAccuracy = 0.8881918819188194\n",
      "Classifier 93: error = 0.4722908953837477, alpha = 0.05547504705374922, newAccuracy = 0.8889298892988932, bestAccuracy = 0.8900369003690044\n",
      "Classifier 94: error = 0.47248694663990315, alpha = 0.05508174516753314, newAccuracy = 0.8926199261992618, bestAccuracy = 0.8889298892988932\n",
      "Classifier 95: error = 0.46240248316643306, alpha = 0.07533724133473628, newAccuracy = 0.8926199261992618, bestAccuracy = 0.8926199261992618\n",
      "Classifier 96: error = 0.4705073017694119, alpha = 0.05905394845752773, newAccuracy = 0.8889298892988932, bestAccuracy = 0.8926199261992618\n",
      "Classifier 97: error = 0.4669570422871514, alpha = 0.06618237503751036, newAccuracy = 0.8929889298892989, bestAccuracy = 0.8889298892988932\n",
      "Classifier 98: error = 0.4654249888093074, alpha = 0.06926055848389373, newAccuracy = 0.8915129151291505, bestAccuracy = 0.8929889298892989\n",
      "Classifier 99: error = 0.46733893117818903, alpha = 0.06541528567823433, newAccuracy = 0.8937269372693726, bestAccuracy = 0.8915129151291505\n",
      "Classifier 100: error = 0.46419809690968195, alpha = 0.07172655741553682, newAccuracy = 0.8911439114391152, bestAccuracy = 0.8937269372693726\n",
      "Classifier 101: error = 0.4556497694032403, alpha = 0.08893419052548654, newAccuracy = 0.8948339483394824, bestAccuracy = 0.8911439114391152\n",
      "Classifier 102: error = 0.47040181706080597, alpha = 0.05926565710540406, newAccuracy = 0.8926199261992618, bestAccuracy = 0.8948339483394824\n",
      "Classifier 103: error = 0.4670213555100159, alpha = 0.06605318547344187, newAccuracy = 0.8911439114391152, bestAccuracy = 0.8926199261992618\n",
      "Classifier 104: error = 0.46185618453167615, alpha = 0.07643614283843429, newAccuracy = 0.8918819188191877, bestAccuracy = 0.8911439114391152\n",
      "Classifier 105: error = 0.4764419966890726, alpha = 0.047150917682369405, newAccuracy = 0.8926199261992618, bestAccuracy = 0.8918819188191877\n",
      "Classifier 106: error = 0.4734340096757668, alpha = 0.053182062818913446, newAccuracy = 0.8907749077490769, bestAccuracy = 0.8926199261992618\n",
      "Classifier 107: error = 0.46833343878716016, alpha = 0.06341800495579995, newAccuracy = 0.8937269372693726, bestAccuracy = 0.8907749077490769\n",
      "Classifier 108: error = 0.47371882493720063, alpha = 0.05261083694785369, newAccuracy = 0.8915129151291505, bestAccuracy = 0.8937269372693726\n",
      "Classifier 109: error = 0.4707935793790354, alpha = 0.05847941361294837, newAccuracy = 0.8948339483394824, bestAccuracy = 0.8915129151291505\n",
      "Classifier 110: error = 0.46667365625021806, alpha = 0.06675165473791597, newAccuracy = 0.8933579335793362, bestAccuracy = 0.8948339483394824\n",
      "Classifier 111: error = 0.4723595725781695, alpha = 0.05533727057673623, newAccuracy = 0.8959409594095936, bestAccuracy = 0.8933579335793362\n",
      "Classifier 112: error = 0.47184974782548983, alpha = 0.05636010384236676, newAccuracy = 0.8915129151291505, bestAccuracy = 0.8959409594095936\n",
      "Classifier 113: error = 0.47256681970895775, alpha = 0.05492151528088817, newAccuracy = 0.8948339483394824, bestAccuracy = 0.8915129151291505\n",
      "Classifier 114: error = 0.4657614873381988, alpha = 0.0685843593939681, newAccuracy = 0.8948339483394824, bestAccuracy = 0.8948339483394824\n",
      "Classifier 115: error = 0.472109221231526, alpha = 0.05583952208097292, newAccuracy = 0.8970479704797044, bestAccuracy = 0.8948339483394824\n",
      "Classifier 116: error = 0.46954278236194225, alpha = 0.060989945840998795, newAccuracy = 0.8952029520295207, bestAccuracy = 0.8970479704797044\n",
      "Classifier 117: error = 0.4705569475439837, alpha = 0.05895431082470466, newAccuracy = 0.8955719557195582, bestAccuracy = 0.8952029520295207\n",
      "Classifier 118: error = 0.4771843719371327, alpha = 0.04566296705264956, newAccuracy = 0.8937269372693726, bestAccuracy = 0.8955719557195582\n",
      "Classifier 119: error = 0.4709419830102969, alpha = 0.058181595331238664, newAccuracy = 0.8955719557195582, bestAccuracy = 0.8937269372693726\n",
      "Classifier 120: error = 0.4748026563138865, alpha = 0.05043741368082497, newAccuracy = 0.8937269372693726, bestAccuracy = 0.8955719557195582\n",
      "Classifier 121: error = 0.4686022856892127, alpha = 0.06287816413612818, newAccuracy = 0.8970479704797044, bestAccuracy = 0.8937269372693726\n",
      "Classifier 122: error = 0.47225736101003246, alpha = 0.05554232266669611, newAccuracy = 0.8940959409594099, bestAccuracy = 0.8970479704797044\n",
      "Classifier 123: error = 0.47462673351746393, alpha = 0.05079016138954388, newAccuracy = 0.8955719557195582, bestAccuracy = 0.8940959409594099\n",
      "Classifier 124: error = 0.4619225814445447, alpha = 0.07630257301505719, newAccuracy = 0.894464944649447, bestAccuracy = 0.8955719557195582\n",
      "Classifier 125: error = 0.4683896491879228, alpha = 0.06330513221538155, newAccuracy = 0.896309963099632, bestAccuracy = 0.894464944649447\n",
      "Classifier 126: error = 0.47408226647814433, alpha = 0.05188196786508744, newAccuracy = 0.8970479704797044, bestAccuracy = 0.896309963099632\n",
      "Classifier 127: error = 0.4778314610603501, alpha = 0.0443661644463072, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8970479704797044\n",
      "Classifier 128: error = 0.4789939052008704, alpha = 0.042036933307779835, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8977859778597781\n",
      "Classifier 129: error = 0.4722971609537828, alpha = 0.05546247731851668, newAccuracy = 0.896309963099632, bestAccuracy = 0.8977859778597781\n",
      "Classifier 130: error = 0.47147932172178075, alpha = 0.05710334306696919, newAccuracy = 0.898523985239853, bestAccuracy = 0.896309963099632\n",
      "Classifier 131: error = 0.47023735649001885, alpha = 0.059595741370401814, newAccuracy = 0.8959409594095936, bestAccuracy = 0.898523985239853\n",
      "Classifier 132: error = 0.4702285363220672, alpha = 0.05961344445150806, newAccuracy = 0.8992619926199267, bestAccuracy = 0.8959409594095936\n",
      "Classifier 133: error = 0.4726312086424478, alpha = 0.054792349495821915, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8992619926199267\n",
      "Classifier 134: error = 0.47647834826070135, alpha = 0.04707805303504639, newAccuracy = 0.8981549815498155, bestAccuracy = 0.8977859778597781\n",
      "Classifier 135: error = 0.4686875351734535, alpha = 0.0627069920215246, newAccuracy = 0.8955719557195582, bestAccuracy = 0.8981549815498155\n",
      "Classifier 136: error = 0.4716190552040528, alpha = 0.056822968304711285, newAccuracy = 0.8970479704797044, bestAccuracy = 0.8955719557195582\n",
      "Classifier 137: error = 0.474066564042822, alpha = 0.051913457396712645, newAccuracy = 0.8966789667896673, bestAccuracy = 0.8970479704797044\n",
      "Classifier 138: error = 0.474265484069065, alpha = 0.05151455243136762, newAccuracy = 0.8974169741697418, bestAccuracy = 0.8966789667896673\n",
      "Classifier 139: error = 0.47036315466258677, alpha = 0.05934325417357231, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8974169741697418\n",
      "Classifier 140: error = 0.47630855484218615, alpha = 0.047418398531462826, newAccuracy = 0.8974169741697418, bestAccuracy = 0.8977859778597781\n",
      "Classifier 141: error = 0.4748933550512384, alpha = 0.050255556016421274, newAccuracy = 0.8974169741697418, bestAccuracy = 0.8974169741697418\n",
      "Classifier 142: error = 0.47751656319988367, alpha = 0.04499721838280697, newAccuracy = 0.8981549815498155, bestAccuracy = 0.8974169741697418\n",
      "Classifier 143: error = 0.4730311560191305, alpha = 0.05399008595315564, newAccuracy = 0.8996309963099638, bestAccuracy = 0.8981549815498155\n",
      "Classifier 144: error = 0.4623008639904993, alpha = 0.07554163853477162, newAccuracy = 0.898523985239853, bestAccuracy = 0.8996309963099638\n",
      "Classifier 145: error = 0.4706828515581555, alpha = 0.05870163034971571, newAccuracy = 0.8996309963099638, bestAccuracy = 0.898523985239853\n",
      "Classifier 146: error = 0.47535237738537306, alpha = 0.0493352330353521, newAccuracy = 0.898523985239853, bestAccuracy = 0.8996309963099638\n",
      "Classifier 147: error = 0.47175480552577664, alpha = 0.05655059428698393, newAccuracy = 0.8981549815498155, bestAccuracy = 0.898523985239853\n",
      "Classifier 148: error = 0.47467967038544734, alpha = 0.05068401487386351, newAccuracy = 0.8996309963099638, bestAccuracy = 0.8981549815498155\n",
      "Classifier 149: error = 0.4715589399678757, alpha = 0.0569435882275863, newAccuracy = 0.8981549815498155, bestAccuracy = 0.8996309963099638\n",
      "Classifier 150: error = 0.47524714892527054, alpha = 0.049546204813262745, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8981549815498155\n",
      "Classifier 151: error = 0.47519374823168115, alpha = 0.04965326916176974, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8977859778597781\n",
      "Classifier 152: error = 0.477505958857231, alpha = 0.04501847005968847, newAccuracy = 0.898523985239853, bestAccuracy = 0.8977859778597781\n",
      "Classifier 153: error = 0.47210041191985763, alpha = 0.055857195714640706, newAccuracy = 0.8959409594095936, bestAccuracy = 0.898523985239853\n",
      "Classifier 154: error = 0.4775466850529221, alpha = 0.044936852779757924, newAccuracy = 0.8970479704797044, bestAccuracy = 0.8959409594095936\n",
      "Classifier 155: error = 0.4737847076269206, alpha = 0.05247870743528567, newAccuracy = 0.8959409594095936, bestAccuracy = 0.8970479704797044\n",
      "Classifier 156: error = 0.4744403032638625, alpha = 0.05116399167915231, newAccuracy = 0.8988929889298893, bestAccuracy = 0.8959409594095936\n",
      "Classifier 157: error = 0.47178645622364246, alpha = 0.05648709046715811, newAccuracy = 0.896309963099632, bestAccuracy = 0.8988929889298893\n",
      "Classifier 158: error = 0.4665583311917736, alpha = 0.06698333769087872, newAccuracy = 0.898523985239853, bestAccuracy = 0.896309963099632\n",
      "Classifier 159: error = 0.47490157041125614, alpha = 0.05023908377729461, newAccuracy = 0.8970479704797044, bestAccuracy = 0.898523985239853\n",
      "Classifier 160: error = 0.4782909562423785, alpha = 0.04344540132505735, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8970479704797044\n",
      "Classifier 161: error = 0.46860788787720176, alpha = 0.06286691541135392, newAccuracy = 0.898523985239853, bestAccuracy = 0.8977859778597781\n",
      "Classifier 162: error = 0.4711915590992239, alpha = 0.057680766102778454, newAccuracy = 0.8981549815498155, bestAccuracy = 0.898523985239853\n",
      "Classifier 163: error = 0.4669247635921624, alpha = 0.066247215886766, newAccuracy = 0.8988929889298893, bestAccuracy = 0.8981549815498155\n",
      "Classifier 164: error = 0.47245371912546985, alpha = 0.0551484022694343, newAccuracy = 0.8988929889298893, bestAccuracy = 0.8988929889298893\n",
      "Classifier 165: error = 0.4702017776506481, alpha = 0.05966715237948168, newAccuracy = 0.8966789667896673, bestAccuracy = 0.8988929889298893\n",
      "Classifier 166: error = 0.47924328685561246, alpha = 0.04153729855894837, newAccuracy = 0.8977859778597781, bestAccuracy = 0.8966789667896673\n",
      "Classifier 167: error = 0.4724470136537016, alpha = 0.05516185405162734, newAccuracy = 0.8974169741697418, bestAccuracy = 0.8977859778597781\n",
      "Classifier 168: error = 0.47411825788479456, alpha = 0.05180979138888288, newAccuracy = 0.8988929889298893, bestAccuracy = 0.8974169741697418\n",
      "Classifier 169: error = 0.47532087613168406, alpha = 0.049398389209789825, newAccuracy = 0.8981549815498155, bestAccuracy = 0.8988929889298893\n",
      "Classifier 170: error = 0.47638912315407034, alpha = 0.047256900554088634, newAccuracy = 0.8999999999999991, bestAccuracy = 0.8981549815498155\n",
      "Classifier 171: error = 0.47935688918480934, alpha = 0.04130970381464384, newAccuracy = 0.8999999999999991, bestAccuracy = 0.8999999999999991\n",
      "Classifier 172: error = 0.480726058149344, alpha = 0.038566994006807166, newAccuracy = 0.898523985239853, bestAccuracy = 0.8999999999999991\n",
      "Classifier 173: error = 0.47416775311837683, alpha = 0.051710535477935166, newAccuracy = 0.8988929889298893, bestAccuracy = 0.898523985239853\n",
      "Classifier 174: error = 0.4763398990195257, alpha = 0.04735556930303204, newAccuracy = 0.9029520295202949, bestAccuracy = 0.8988929889298893\n",
      "Classifier 175: error = 0.475584843523045, alpha = 0.048869178886448386, newAccuracy = 0.8996309963099638, bestAccuracy = 0.9029520295202949\n",
      "Classifier 176: error = 0.47757041733926764, alpha = 0.04488929239789096, newAccuracy = 0.8988929889298893, bestAccuracy = 0.8996309963099638\n",
      "Classifier 177: error = 0.4760203828201742, alpha = 0.04799605533402675, newAccuracy = 0.8996309963099638, bestAccuracy = 0.8988929889298893\n",
      "Classifier 178: error = 0.4757922547607675, alpha = 0.04845337336323342, newAccuracy = 0.8999999999999991, bestAccuracy = 0.8996309963099638\n",
      "Classifier 179: error = 0.47531395904602564, alpha = 0.0494122571762219, newAccuracy = 0.8999999999999991, bestAccuracy = 0.8999999999999991\n",
      "Classifier 180: error = 0.4715508159459936, alpha = 0.056959889028888926, newAccuracy = 0.9007380073800728, bestAccuracy = 0.8999999999999991\n",
      "Classifier 181: error = 0.47808359462917815, alpha = 0.0438609153552896, newAccuracy = 0.9014760147601487, bestAccuracy = 0.9007380073800728\n",
      "Classifier 182: error = 0.48184442915803427, alpha = 0.036327113048299636, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9014760147601487\n",
      "Classifier 183: error = 0.47244376547849787, alpha = 0.05516837019172189, newAccuracy = 0.901845018450184, bestAccuracy = 0.9011070110701099\n",
      "Classifier 184: error = 0.48161695411358907, alpha = 0.036782671347450245, newAccuracy = 0.9003690036900375, bestAccuracy = 0.901845018450184\n",
      "Classifier 185: error = 0.46883712153116475, alpha = 0.06240664700668003, newAccuracy = 0.9007380073800728, bestAccuracy = 0.9003690036900375\n",
      "Classifier 186: error = 0.4793232166426954, alpha = 0.04137716407605856, newAccuracy = 0.9007380073800728, bestAccuracy = 0.9007380073800728\n",
      "Classifier 187: error = 0.4793732503469539, alpha = 0.04127692566256441, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9007380073800728\n",
      "Classifier 188: error = 0.47286048529524893, alpha = 0.05433242968892525, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9011070110701099\n",
      "Classifier 189: error = 0.475820635663589, alpha = 0.04839647834858454, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9011070110701099\n",
      "Classifier 190: error = 0.4715382115259752, alpha = 0.05698517978210046, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9011070110701099\n",
      "Classifier 191: error = 0.4769922255542074, alpha = 0.04604806845304491, newAccuracy = 0.8988929889298893, bestAccuracy = 0.9029520295202949\n",
      "Classifier 192: error = 0.4759898412576574, alpha = 0.04805727945936629, newAccuracy = 0.9014760147601487, bestAccuracy = 0.8988929889298893\n",
      "Classifier 193: error = 0.46851713173269993, alpha = 0.06304914811466165, newAccuracy = 0.8992619926199267, bestAccuracy = 0.9014760147601487\n",
      "Classifier 194: error = 0.475122219124686, alpha = 0.049796681389506936, newAccuracy = 0.901845018450184, bestAccuracy = 0.8992619926199267\n",
      "Classifier 195: error = 0.48129550235369634, alpha = 0.037426460412175094, newAccuracy = 0.9007380073800728, bestAccuracy = 0.901845018450184\n",
      "Classifier 196: error = 0.4689766693695052, alpha = 0.06212646784046179, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9007380073800728\n",
      "Classifier 197: error = 0.4737298857307842, alpha = 0.052588654099693585, newAccuracy = 0.9014760147601487, bestAccuracy = 0.9011070110701099\n",
      "Classifier 198: error = 0.47346929085424283, alpha = 0.05311130096591996, newAccuracy = 0.8999999999999991, bestAccuracy = 0.9014760147601487\n",
      "Classifier 199: error = 0.47668491321788403, alpha = 0.04666401484750091, newAccuracy = 0.901845018450184, bestAccuracy = 0.8999999999999991\n",
      "Classifier 200: error = 0.4745922339929596, alpha = 0.05085933882734257, newAccuracy = 0.901845018450184, bestAccuracy = 0.901845018450184\n",
      "Classifier 201: error = 0.48096860235437, alpha = 0.03808119277158713, newAccuracy = 0.9011070110701099, bestAccuracy = 0.901845018450184\n",
      "Classifier 202: error = 0.4737082805499899, alpha = 0.05263198417127785, newAccuracy = 0.9014760147601487, bestAccuracy = 0.9011070110701099\n",
      "Classifier 203: error = 0.4675572227643604, alpha = 0.06497684415979839, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9014760147601487\n",
      "Classifier 204: error = 0.4798712143705462, alpha = 0.04027934053004621, newAccuracy = 0.8999999999999991, bestAccuracy = 0.9011070110701099\n",
      "Classifier 205: error = 0.46789483057660464, alpha = 0.0642988034952586, newAccuracy = 0.9014760147601487, bestAccuracy = 0.8999999999999991\n",
      "Classifier 206: error = 0.4790150763221741, alpha = 0.04199451627352399, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9014760147601487\n",
      "Classifier 207: error = 0.4767092003545818, alpha = 0.04661533483583106, newAccuracy = 0.901845018450184, bestAccuracy = 0.9011070110701099\n",
      "Classifier 208: error = 0.4734131220439753, alpha = 0.053223956441505, newAccuracy = 0.9029520295202949, bestAccuracy = 0.901845018450184\n",
      "Classifier 209: error = 0.47587806889255857, alpha = 0.04828134327867928, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9029520295202949\n",
      "Classifier 210: error = 0.47660606660482197, alpha = 0.04682205287062542, newAccuracy = 0.9025830258302585, bestAccuracy = 0.9029520295202949\n",
      "Classifier 211: error = 0.4742515442395512, alpha = 0.05154250618170532, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9025830258302585\n",
      "Classifier 212: error = 0.4783794210685808, alpha = 0.04326813886972624, newAccuracy = 0.8999999999999991, bestAccuracy = 0.9029520295202949\n",
      "Classifier 213: error = 0.4764621382309808, alpha = 0.047110545051231724, newAccuracy = 0.9014760147601487, bestAccuracy = 0.8999999999999991\n",
      "Classifier 214: error = 0.47723124580826926, alpha = 0.04556902410289753, newAccuracy = 0.9025830258302585, bestAccuracy = 0.9014760147601487\n",
      "Classifier 215: error = 0.4809695673107757, alpha = 0.03807926005884952, newAccuracy = 0.9025830258302585, bestAccuracy = 0.9025830258302585\n",
      "Classifier 216: error = 0.47381071258107044, alpha = 0.0524265543019646, newAccuracy = 0.9022140221402212, bestAccuracy = 0.9025830258302585\n",
      "Classifier 217: error = 0.47744112456868415, alpha = 0.04514840236903148, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9022140221402212\n",
      "Classifier 218: error = 0.4822444256952848, alpha = 0.0355260869194346, newAccuracy = 0.9011070110701099, bestAccuracy = 0.9011070110701099\n",
      "Classifier 219: error = 0.47533037541870415, alpha = 0.04937934425559542, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9011070110701099\n",
      "Classifier 220: error = 0.48193585676076767, alpha = 0.036144017645413716, newAccuracy = 0.9033210332103322, bestAccuracy = 0.9029520295202949\n",
      "Classifier 221: error = 0.479084006120096, alpha = 0.04185641421351103, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9033210332103322\n",
      "Classifier 222: error = 0.4771377652548727, alpha = 0.045756375310480615, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9036900369003693\n",
      "Classifier 223: error = 0.4770814204385086, alpha = 0.045869301623642056, newAccuracy = 0.9040590405904048, bestAccuracy = 0.9029520295202949\n",
      "Classifier 224: error = 0.47504478341235934, alpha = 0.0499519383683889, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9040590405904048\n",
      "Classifier 225: error = 0.4741399102486425, alpha = 0.05176637041380896, newAccuracy = 0.9040590405904048, bestAccuracy = 0.9036900369003693\n",
      "Classifier 226: error = 0.47576735135196757, alpha = 0.04850329732600237, newAccuracy = 0.9033210332103322, bestAccuracy = 0.9040590405904048\n",
      "Classifier 227: error = 0.4782302832116173, alpha = 0.04356697721408467, newAccuracy = 0.9033210332103322, bestAccuracy = 0.9033210332103322\n",
      "Classifier 228: error = 0.478849676788656, alpha = 0.04232590368179287, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9033210332103322\n",
      "Classifier 229: error = 0.47902092023852644, alpha = 0.0419828078225017, newAccuracy = 0.9040590405904048, bestAccuracy = 0.9044280442804434\n",
      "Classifier 230: error = 0.47296560885418476, alpha = 0.054121563718313344, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9040590405904048\n",
      "Classifier 231: error = 0.4755645796067185, alpha = 0.048909803665212095, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9044280442804434\n",
      "Classifier 232: error = 0.4755057411883068, alpha = 0.049027762909970435, newAccuracy = 0.9022140221402212, bestAccuracy = 0.9036900369003693\n",
      "Classifier 233: error = 0.4775785400038157, alpha = 0.044873014323562506, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9022140221402212\n",
      "Classifier 234: error = 0.4748049787423013, alpha = 0.05043275699886264, newAccuracy = 0.9059040590405896, bestAccuracy = 0.9044280442804434\n",
      "Classifier 235: error = 0.4768684048195073, alpha = 0.04629623823779378, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9059040590405896\n",
      "Classifier 236: error = 0.4777281815100255, alpha = 0.04457313229785656, newAccuracy = 0.9051660516605159, bestAccuracy = 0.9036900369003693\n",
      "Classifier 237: error = 0.4766537158431505, alpha = 0.04672654574446848, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9051660516605159\n",
      "Classifier 238: error = 0.48390991153742685, alpha = 0.03219129203439518, newAccuracy = 0.9051660516605159, bestAccuracy = 0.9044280442804434\n",
      "Classifier 239: error = 0.4728722925245492, alpha = 0.054308745481963516, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9051660516605159\n",
      "Classifier 240: error = 0.4845411953188363, alpha = 0.030927466376321506, newAccuracy = 0.9047970479704806, bestAccuracy = 0.9036900369003693\n",
      "Classifier 241: error = 0.47693584248563003, alpha = 0.046161074459436416, newAccuracy = 0.9029520295202949, bestAccuracy = 0.9047970479704806\n",
      "Classifier 242: error = 0.4703647205530939, alpha = 0.05934011135124318, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9029520295202949\n",
      "Classifier 243: error = 0.47979011209492706, alpha = 0.04044180945243536, newAccuracy = 0.9062730627306267, bestAccuracy = 0.9044280442804434\n",
      "Classifier 244: error = 0.4750195281804641, alpha = 0.05000257509856205, newAccuracy = 0.9040590405904048, bestAccuracy = 0.9062730627306267\n",
      "Classifier 245: error = 0.476372222105212, alpha = 0.0472907782495574, newAccuracy = 0.9047970479704806, bestAccuracy = 0.9040590405904048\n",
      "Classifier 246: error = 0.4811310033861578, alpha = 0.037755923475410326, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9047970479704806\n",
      "Classifier 247: error = 0.48182862579264507, alpha = 0.03635876154391454, newAccuracy = 0.9036900369003693, bestAccuracy = 0.9044280442804434\n",
      "Classifier 248: error = 0.4751998468027225, alpha = 0.04964104193097578, newAccuracy = 0.9047970479704806, bestAccuracy = 0.9036900369003693\n",
      "Classifier 249: error = 0.4763361031456259, alpha = 0.047363178091173665, newAccuracy = 0.9047970479704806, bestAccuracy = 0.9047970479704806\n",
      "Classifier 250: error = 0.47147961689440554, alpha = 0.05710275079465355, newAccuracy = 0.9044280442804434, bestAccuracy = 0.9047970479704806\n",
      "Classifier 251: error = 0.4695180284411148, alpha = 0.061039638219514546, newAccuracy = 0.9062730627306267, bestAccuracy = 0.9044280442804434\n",
      "Classifier 252: error = 0.473598201827344, alpha = 0.05285275461012868, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9062730627306267\n",
      "Classifier 253: error = 0.4742373502184942, alpha = 0.05157096974887365, newAccuracy = 0.9059040590405896, bestAccuracy = 0.9066420664206654\n",
      "Classifier 254: error = 0.4797848438012876, alpha = 0.04045236328662119, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9059040590405896\n",
      "Classifier 255: error = 0.4785305331921499, alpha = 0.04296535242096985, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9073800738007379\n",
      "Classifier 256: error = 0.47047333983370493, alpha = 0.059122109754153954, newAccuracy = 0.9062730627306267, bestAccuracy = 0.9066420664206654\n",
      "Classifier 257: error = 0.4743081228357183, alpha = 0.051429048768720134, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9062730627306267\n",
      "Classifier 258: error = 0.4806084576375751, alpha = 0.038802547188029356, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9073800738007379\n",
      "Classifier 259: error = 0.47992926020204807, alpha = 0.04016306095893282, newAccuracy = 0.9088560885608861, bestAccuracy = 0.9073800738007379\n",
      "Classifier 260: error = 0.47418864592434296, alpha = 0.051668638123182495, newAccuracy = 0.9070110701107008, bestAccuracy = 0.9088560885608861\n",
      "Classifier 261: error = 0.476783248163389, alpha = 0.04646691819986196, newAccuracy = 0.9088560885608861, bestAccuracy = 0.9070110701107008\n",
      "Classifier 262: error = 0.47840850789649547, alpha = 0.04320985638399228, newAccuracy = 0.9055350553505542, bestAccuracy = 0.9088560885608861\n",
      "Classifier 263: error = 0.4797557084899541, alpha = 0.040510729452775826, newAccuracy = 0.9077490774907753, bestAccuracy = 0.9055350553505542\n",
      "Classifier 264: error = 0.4760934399877283, alpha = 0.047849605175882624, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9077490774907753\n",
      "Classifier 265: error = 0.47702206995740926, alpha = 0.04598825315612309, newAccuracy = 0.9070110701107008, bestAccuracy = 0.9066420664206654\n",
      "Classifier 266: error = 0.4793448959258433, alpha = 0.04133373131249236, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9070110701107008\n",
      "Classifier 267: error = 0.4745301008368048, alpha = 0.05098392764252369, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9073800738007379\n",
      "Classifier 268: error = 0.47759659329562154, alpha = 0.04483683504606512, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9066420664206654\n",
      "Classifier 269: error = 0.4854830162218108, alpha = 0.029042129946218322, newAccuracy = 0.9051660516605159, bestAccuracy = 0.9066420664206654\n",
      "Classifier 270: error = 0.48082477432949, alpha = 0.03836926934192759, newAccuracy = 0.9070110701107008, bestAccuracy = 0.9051660516605159\n",
      "Classifier 271: error = 0.47701879249421647, alpha = 0.0459948219574075, newAccuracy = 0.9059040590405896, bestAccuracy = 0.9070110701107008\n",
      "Classifier 272: error = 0.47389983375781874, alpha = 0.05224782326395125, newAccuracy = 0.9070110701107008, bestAccuracy = 0.9059040590405896\n",
      "Classifier 273: error = 0.47748854577283784, alpha = 0.045053366911857524, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9070110701107008\n",
      "Classifier 274: error = 0.4817194902201032, alpha = 0.036577323101277086, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9066420664206654\n",
      "Classifier 275: error = 0.47923980798843197, alpha = 0.04154426830673761, newAccuracy = 0.9059040590405896, bestAccuracy = 0.9073800738007379\n",
      "Classifier 276: error = 0.4740468953722814, alpha = 0.05195290092818296, newAccuracy = 0.9081180811808116, bestAccuracy = 0.9059040590405896\n",
      "Classifier 277: error = 0.4729614168641674, alpha = 0.0541299722840385, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9081180811808116\n",
      "Classifier 278: error = 0.47974032667393934, alpha = 0.04054154363766484, newAccuracy = 0.908487084870849, bestAccuracy = 0.9066420664206654\n",
      "Classifier 279: error = 0.47958931303879426, alpha = 0.0408440713146465, newAccuracy = 0.9066420664206654, bestAccuracy = 0.908487084870849\n",
      "Classifier 280: error = 0.4814894216028889, alpha = 0.03703808402247577, newAccuracy = 0.9077490774907753, bestAccuracy = 0.9066420664206654\n",
      "Classifier 281: error = 0.47991440624816817, alpha = 0.040192816848987796, newAccuracy = 0.9062730627306267, bestAccuracy = 0.9077490774907753\n",
      "Classifier 282: error = 0.47936755772373085, alpha = 0.0412883303234011, newAccuracy = 0.9062730627306267, bestAccuracy = 0.9062730627306267\n",
      "Classifier 283: error = 0.4855926673708121, alpha = 0.028822644021923593, newAccuracy = 0.9066420664206654, bestAccuracy = 0.9062730627306267\n",
      "Classifier 284: error = 0.48275066118679993, alpha = 0.034512373702236074, newAccuracy = 0.9059040590405896, bestAccuracy = 0.9066420664206654\n",
      "Classifier 285: error = 0.4793670807021556, alpha = 0.041289285993895766, newAccuracy = 0.9070110701107008, bestAccuracy = 0.9059040590405896\n",
      "Classifier 286: error = 0.4797121892050764, alpha = 0.04059791124929826, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9070110701107008\n",
      "Classifier 287: error = 0.48263475803802325, alpha = 0.034744458077137566, newAccuracy = 0.908487084870849, bestAccuracy = 0.9073800738007379\n",
      "Classifier 288: error = 0.48290597663604845, alpha = 0.034201375989897656, newAccuracy = 0.9099630996309973, bestAccuracy = 0.908487084870849\n",
      "Classifier 289: error = 0.47654946822487576, alpha = 0.046935498576318256, newAccuracy = 0.9099630996309973, bestAccuracy = 0.9099630996309973\n",
      "Classifier 290: error = 0.4795831279622337, alpha = 0.04085646212187275, newAccuracy = 0.9095940959409602, bestAccuracy = 0.9099630996309973\n",
      "Classifier 291: error = 0.477489465397684, alpha = 0.04505152392647195, newAccuracy = 0.9095940959409602, bestAccuracy = 0.9095940959409602\n",
      "Classifier 292: error = 0.47835983699133316, alpha = 0.04330738046454135, newAccuracy = 0.9095940959409602, bestAccuracy = 0.9095940959409602\n",
      "Classifier 293: error = 0.47653591255769734, alpha = 0.04696266971384231, newAccuracy = 0.9095940959409602, bestAccuracy = 0.9095940959409602\n",
      "Classifier 294: error = 0.4800247211161453, alpha = 0.039971832460182474, newAccuracy = 0.9099630996309973, bestAccuracy = 0.9095940959409602\n",
      "Classifier 295: error = 0.4742992396363761, alpha = 0.05144686221633623, newAccuracy = 0.9073800738007379, bestAccuracy = 0.9099630996309973\n",
      "Classifier 296: error = 0.4821405320737737, alpha = 0.03573413806173449, newAccuracy = 0.908487084870849, bestAccuracy = 0.9073800738007379\n",
      "Classifier 297: error = 0.48447780508546967, alpha = 0.031054368646833787, newAccuracy = 0.9077490774907753, bestAccuracy = 0.908487084870849\n",
      "Classifier 298: error = 0.4791526927788816, alpha = 0.04171880087423486, newAccuracy = 0.908487084870849, bestAccuracy = 0.9077490774907753\n",
      "Classifier 299: error = 0.4787123551347543, alpha = 0.04260104251112409, newAccuracy = 0.908487084870849, bestAccuracy = 0.908487084870849\n",
      "Classifier 300: error = 0.4801850595758377, alpha = 0.03965064701752958, newAccuracy = 0.9095940959409602, bestAccuracy = 0.908487084870849\n",
      "Classifier 301: error = 0.4815449709885613, alpha = 0.0369268332317131, newAccuracy = 0.908487084870849, bestAccuracy = 0.9095940959409602\n",
      "Classifier 302: error = 0.4763527100175925, alpha = 0.04732988983653262, newAccuracy = 0.9092250922509214, bestAccuracy = 0.908487084870849\n",
      "Classifier 303: error = 0.4747910146521681, alpha = 0.05046075631317199, newAccuracy = 0.910701107011071, bestAccuracy = 0.9092250922509214\n",
      "Se para el entrenamiento debido a que la precisin ha alcanzado el valor prctico buscado\n",
      "El nmero ptimo de clasificadores dbiles es: 303 \n",
      "La precisin obtenida en el entrenamiento ha sido de: 0.9107\n",
      "Accuracy for digit 5: 0.9166\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_adaboost_for_one_digit_detecting_overfitting(digit=5, A=200, \n",
    "                                                            verboseParam=True, n_components=50, \n",
    "                                                            split_proportion=0.75, iter_number=50,\n",
    "                                                            round1 = 4,\n",
    "                                                            round2 = 4,\n",
    "                                                            bestAccuracyBreak = 0.91,\n",
    "                                                            practicalAccuracyBreak = 6666)  # Ejecutamos AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 2A: AdaboostClassifier de la librera sklearn utilizando como clasificador dbil la clase \n",
    "DecisionTreeClassifier con profundidad 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solucin Minimalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost with sklearn for digit: 0\n",
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Accuracy for digit 0 with sklearn: 0.9641\n",
      "Running AdaBoost with sklearn for digit: 1\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Accuracy for digit 1 with sklearn: 0.967\n",
      "Running AdaBoost with sklearn for digit: 2\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Accuracy for digit 2 with sklearn: 0.9355\n",
      "Running AdaBoost with sklearn for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Accuracy for digit 3 with sklearn: 0.8944\n",
      "Running AdaBoost with sklearn for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Accuracy for digit 4 with sklearn: 0.9005\n",
      "Running AdaBoost with sklearn for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Accuracy for digit 5 with sklearn: 0.8848\n",
      "Running AdaBoost with sklearn for digit: 6\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Accuracy for digit 6 with sklearn: 0.9457\n",
      "Running AdaBoost with sklearn for digit: 7\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Accuracy for digit 7 with sklearn: 0.9391\n",
      "Running AdaBoost with sklearn for digit: 8\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Accuracy for digit 8 with sklearn: 0.8889\n",
      "Running AdaBoost with sklearn for digit: 9\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Accuracy for digit 9 with sklearn: 0.8799\n",
      "Accuracies for all digits: {0: 0.9641, 1: 0.967, 2: 0.9355, 3: 0.8944, 4: 0.9005, 5: 0.8848, 6: 0.9457, 7: 0.9391, 8: 0.8889, 9: 0.8799}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #Importamos la librera numpy que sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # Importamos el dataset MNIST que contiene imgenes de dgitos escritos a mano\n",
    "from sklearn.ensemble import AdaBoostClassifier # Importamos el clasificador AdaBoost de la librera scikit-learn que se utilizar como clasificador fuerte\n",
    "from sklearn.tree import DecisionTreeClassifier # Importamos el clasificador DecisionTree de la librera scikit-learn que se utilizar como clasificador dbil\n",
    "from sklearn.metrics import accuracy_score # Importamos la funcin accuracy_score de la librera scikit-learn que se utilizar para calcular la precisin\n",
    "\n",
    "def run_adaboost_with_sklearn(digit, T=50, A=20): # Creamos la funcin run_adaboost_with_sklearn\n",
    "    print(f\"Running AdaBoost with sklearn for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()  # Cargamos los datos\n",
    "\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train)\n",
    "\n",
    "    X_train_balanced = X_train_balanced.reshape(X_train_balanced.shape[0], -1)  # Aplanamos los datos de entrenamiento reduciendo la dimensin a 1D\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)  # Aplanamos los datos de prueba reduciendo la dimensin a 1D\n",
    "\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "\n",
    "\n",
    "    weak_clf = DecisionTreeClassifier(max_depth=1, random_state=42) # Creamos un clasificador dbil DecisionTree con profundidad 1\n",
    "\n",
    "\n",
    "    adaboost = AdaBoostClassifier(estimator=weak_clf, n_estimators=T, algorithm='SAMME', random_state=42) # Creamos el clasificador AdaBoost con el clasificador dbil y el nmero de iteraciones\n",
    "\n",
    "    adaboost.fit(X_train_balanced, Y_train_binary_balanced) # Ajustamos el clasificador AdaBoost\n",
    "    \n",
    "    y_pred = adaboost.predict(X_test) # Realizamos las predicciones\n",
    "\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred) # Calculamos la precisin\n",
    "    \n",
    "    print(f\"Accuracy for digit {digit} with sklearn: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits_sklearn(T=50, A=20): # Creamos la funcin run_adaboost_for_all_digits_sklearn\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito\n",
    "        accuracy = run_adaboost_with_sklearn(digit, T, A) # Ejecutamos AdaBoost con sklearn\n",
    "        accuracies[digit] = accuracy  # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "\n",
    "if __name__ == \"__main__\": # Si el script se ejecuta de forma independiente\n",
    "    accuracies = run_adaboost_for_all_digits_sklearn(T=50, A=20)  # Ejecutamos AdaBoost con sklearn para todos los dgitos\n",
    "    print(\"Accuracies for all digits:\", accuracies) # Imprimimos las precisiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 2B: clasificador dbil rboles de decisin de \n",
    "profundidad mayor que 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solucin Minimalista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoost with sklearn for digit: 0\n",
      "Total elements for target digit 0: 5923\n",
      "Each non-target digit will have 658 samples.\n",
      "Collected 658 samples for digit 1.\n",
      "Collected 658 samples for digit 2.\n",
      "Collected 658 samples for digit 3.\n",
      "Collected 658 samples for digit 4.\n",
      "Collected 658 samples for digit 5.\n",
      "Collected 658 samples for digit 6.\n",
      "Collected 658 samples for digit 7.\n",
      "Collected 658 samples for digit 8.\n",
      "Collected 658 samples for digit 9.\n",
      "Accuracy for digit 0 with sklearn: 0.9804\n",
      "Running AdaBoost with sklearn for digit: 1\n",
      "Total elements for target digit 1: 6742\n",
      "Each non-target digit will have 749 samples.\n",
      "Collected 749 samples for digit 0.\n",
      "Collected 749 samples for digit 2.\n",
      "Collected 749 samples for digit 3.\n",
      "Collected 749 samples for digit 4.\n",
      "Collected 749 samples for digit 5.\n",
      "Collected 749 samples for digit 6.\n",
      "Collected 749 samples for digit 7.\n",
      "Collected 749 samples for digit 8.\n",
      "Collected 749 samples for digit 9.\n",
      "Accuracy for digit 1 with sklearn: 0.983\n",
      "Running AdaBoost with sklearn for digit: 2\n",
      "Total elements for target digit 2: 5958\n",
      "Each non-target digit will have 662 samples.\n",
      "Collected 662 samples for digit 0.\n",
      "Collected 662 samples for digit 1.\n",
      "Collected 662 samples for digit 3.\n",
      "Collected 662 samples for digit 4.\n",
      "Collected 662 samples for digit 5.\n",
      "Collected 662 samples for digit 6.\n",
      "Collected 662 samples for digit 7.\n",
      "Collected 662 samples for digit 8.\n",
      "Collected 662 samples for digit 9.\n",
      "Accuracy for digit 2 with sklearn: 0.9548\n",
      "Running AdaBoost with sklearn for digit: 3\n",
      "Total elements for target digit 3: 6131\n",
      "Each non-target digit will have 681 samples.\n",
      "Collected 681 samples for digit 0.\n",
      "Collected 681 samples for digit 1.\n",
      "Collected 681 samples for digit 2.\n",
      "Collected 681 samples for digit 4.\n",
      "Collected 681 samples for digit 5.\n",
      "Collected 681 samples for digit 6.\n",
      "Collected 681 samples for digit 7.\n",
      "Collected 681 samples for digit 8.\n",
      "Collected 681 samples for digit 9.\n",
      "Accuracy for digit 3 with sklearn: 0.9303\n",
      "Running AdaBoost with sklearn for digit: 4\n",
      "Total elements for target digit 4: 5842\n",
      "Each non-target digit will have 649 samples.\n",
      "Collected 649 samples for digit 0.\n",
      "Collected 649 samples for digit 1.\n",
      "Collected 649 samples for digit 2.\n",
      "Collected 649 samples for digit 3.\n",
      "Collected 649 samples for digit 5.\n",
      "Collected 649 samples for digit 6.\n",
      "Collected 649 samples for digit 7.\n",
      "Collected 649 samples for digit 8.\n",
      "Collected 649 samples for digit 9.\n",
      "Accuracy for digit 4 with sklearn: 0.9508\n",
      "Running AdaBoost with sklearn for digit: 5\n",
      "Total elements for target digit 5: 5421\n",
      "Each non-target digit will have 602 samples.\n",
      "Collected 602 samples for digit 0.\n",
      "Collected 602 samples for digit 1.\n",
      "Collected 602 samples for digit 2.\n",
      "Collected 602 samples for digit 3.\n",
      "Collected 602 samples for digit 4.\n",
      "Collected 602 samples for digit 6.\n",
      "Collected 602 samples for digit 7.\n",
      "Collected 602 samples for digit 8.\n",
      "Collected 602 samples for digit 9.\n",
      "Accuracy for digit 5 with sklearn: 0.9494\n",
      "Running AdaBoost with sklearn for digit: 6\n",
      "Total elements for target digit 6: 5918\n",
      "Each non-target digit will have 657 samples.\n",
      "Collected 657 samples for digit 0.\n",
      "Collected 657 samples for digit 1.\n",
      "Collected 657 samples for digit 2.\n",
      "Collected 657 samples for digit 3.\n",
      "Collected 657 samples for digit 4.\n",
      "Collected 657 samples for digit 5.\n",
      "Collected 657 samples for digit 7.\n",
      "Collected 657 samples for digit 8.\n",
      "Collected 657 samples for digit 9.\n",
      "Accuracy for digit 6 with sklearn: 0.977\n",
      "Running AdaBoost with sklearn for digit: 7\n",
      "Total elements for target digit 7: 6265\n",
      "Each non-target digit will have 696 samples.\n",
      "Collected 696 samples for digit 0.\n",
      "Collected 696 samples for digit 1.\n",
      "Collected 696 samples for digit 2.\n",
      "Collected 696 samples for digit 3.\n",
      "Collected 696 samples for digit 4.\n",
      "Collected 696 samples for digit 5.\n",
      "Collected 696 samples for digit 6.\n",
      "Collected 696 samples for digit 8.\n",
      "Collected 696 samples for digit 9.\n",
      "Accuracy for digit 7 with sklearn: 0.9636\n",
      "Running AdaBoost with sklearn for digit: 8\n",
      "Total elements for target digit 8: 5851\n",
      "Each non-target digit will have 650 samples.\n",
      "Collected 650 samples for digit 0.\n",
      "Collected 650 samples for digit 1.\n",
      "Collected 650 samples for digit 2.\n",
      "Collected 650 samples for digit 3.\n",
      "Collected 650 samples for digit 4.\n",
      "Collected 650 samples for digit 5.\n",
      "Collected 650 samples for digit 6.\n",
      "Collected 650 samples for digit 7.\n",
      "Collected 650 samples for digit 9.\n",
      "Accuracy for digit 8 with sklearn: 0.9468\n",
      "Running AdaBoost with sklearn for digit: 9\n",
      "Total elements for target digit 9: 5949\n",
      "Each non-target digit will have 661 samples.\n",
      "Collected 661 samples for digit 0.\n",
      "Collected 661 samples for digit 1.\n",
      "Collected 661 samples for digit 2.\n",
      "Collected 661 samples for digit 3.\n",
      "Collected 661 samples for digit 4.\n",
      "Collected 661 samples for digit 5.\n",
      "Collected 661 samples for digit 6.\n",
      "Collected 661 samples for digit 7.\n",
      "Collected 661 samples for digit 8.\n",
      "Accuracy for digit 9 with sklearn: 0.9232\n",
      "Accuracies for all digits: {0: 0.9804, 1: 0.983, 2: 0.9548, 3: 0.9303, 4: 0.9508, 5: 0.9494, 6: 0.977, 7: 0.9636, 8: 0.9468, 9: 0.9232}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #Importamos la librera numpy que sirve para trabajar con matrices\n",
    "from tensorflow.keras.datasets import mnist # Importamos el dataset MNIST que contiene imgenes de dgitos escritos a mano\n",
    "from sklearn.ensemble import AdaBoostClassifier # Importamos el clasificador AdaBoost de la librera scikit-learn que se utilizar como clasificador fuerte\n",
    "from sklearn.tree import DecisionTreeClassifier # Importamos el clasificador DecisionTree de la librera scikit-learn que se utilizar como clasificador dbil\n",
    "from sklearn.metrics import accuracy_score # Importamos la funcin accuracy_score de la librera scikit-learn que se utilizar para calcular la precisin\n",
    "\n",
    "def run_adaboost_with_sklearn(digit, T=50, A=20, max_depth = 1): # Creamos la funcin run_adaboost_with_sklearn\n",
    "    print(f\"Running AdaBoost with sklearn for digit: {digit}\") # Mostramos el dgito\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()  # Cargamos los datos\n",
    "\n",
    "    X_train_balanced, Y_train_binary_balanced = balance_training_dataset(digit, X_train, y_train)\n",
    "\n",
    "    X_train_balanced = X_train_balanced.reshape(X_train_balanced.shape[0], -1)  # Aplanamos los datos de entrenamiento reduciendo la dimensin a 1D\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)  # Aplanamos los datos de prueba reduciendo la dimensin a 1D\n",
    "\n",
    "      # Convertimos las etiquetas a binarias\n",
    "    y_test_binary = np.where(y_test == digit, 1, -1) # Convertimos las etiquetas a binarias\n",
    "\n",
    "\n",
    "    weak_clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42) # Creamos un clasificador dbil DecisionTree con profundidad 1\n",
    "\n",
    "\n",
    "    adaboost = AdaBoostClassifier(estimator=weak_clf, n_estimators=T, algorithm='SAMME', random_state=42) # Creamos el clasificador AdaBoost con el clasificador dbil y el nmero de iteraciones\n",
    "\n",
    "    adaboost.fit(X_train_balanced, Y_train_binary_balanced) # Ajustamos el clasificador AdaBoost\n",
    "    \n",
    "    y_pred = adaboost.predict(X_test) # Realizamos las predicciones\n",
    "\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred) # Calculamos la precisin\n",
    "    \n",
    "    print(f\"Accuracy for digit {digit} with sklearn: {accuracy}\") # Mostramos la precisin\n",
    "\n",
    "    return accuracy # Devolvemos la precisin\n",
    "\n",
    "def run_adaboost_for_all_digits_sklearn(T=50, A=20, max_depth = 1): # Creamos la funcin run_adaboost_for_all_digits_sklearn\n",
    "    accuracies = {} # Inicializamos las precisiones\n",
    "    for digit in range(10): # Para cada dgito \n",
    "        accuracy = run_adaboost_with_sklearn(digit, T, A, max_depth=max_depth) # Ejecutamos AdaBoost con sklearn\n",
    "        accuracies[digit] = accuracy  # Guardamos la precisin\n",
    "    return accuracies # Devolvemos las precisiones\n",
    "\n",
    "if __name__ == \"__main__\": # Si el script se ejecuta de forma independiente\n",
    "    accuracies = run_adaboost_for_all_digits_sklearn(T=50, A=20, max_depth=2)  # Ejecutamos AdaBoost con sklearn para todos los dgitos\n",
    "    print(\"Accuracies for all digits:\", accuracies) # Imprimimos las precisiones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 2C:  Utilizacin de la librera Keras para implementar un Multi-Layer \n",
    "Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1 (less fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    Y_train = to_categorical(Y_train, 10)\n",
    "    Y_test = to_categorical(Y_test, 10)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def create_mlp_model(input_shape, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    X_train, Y_train, X_test, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    model = create_mlp_model(input_shape, learning_rate)\n",
    "    \n",
    "    batch_size = 32\n",
    "    epochs = 10\n",
    "    validation_split = 0.1\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
    "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2 (Faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.4463 - val_accuracy: 0.9682 - val_loss: 0.1007\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.0994 - val_accuracy: 0.9740 - val_loss: 0.0834\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0667 - val_accuracy: 0.9775 - val_loss: 0.0707\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0505 - val_accuracy: 0.9769 - val_loss: 0.0736\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0419 - val_accuracy: 0.9804 - val_loss: 0.0677\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0355 - val_accuracy: 0.9815 - val_loss: 0.0644\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0339 - val_accuracy: 0.9823 - val_loss: 0.0678\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0262 - val_accuracy: 0.9837 - val_loss: 0.0632\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0278 - val_accuracy: 0.9830 - val_loss: 0.0681\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0238 - val_accuracy: 0.9818 - val_loss: 0.0720\n",
      "Test loss: 0.0720\n",
      "Test accuracy:  0.9818\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    \n",
    "    Y_train = to_categorical(Y_train, 10)\n",
    "    Y_test = to_categorical(Y_test, 10)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def create_mlp_model(input_shape, learning_rate, num_layers):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    X_train, Y_train, X_test, Y_test = load_and_preprocess_data()\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    learning_rate = 0.001\n",
    "    num_layers = 2  # Specify the number of layers here\n",
    "    \n",
    "    model = create_mlp_model(input_shape, learning_rate, num_layers)\n",
    "    \n",
    "    batch_size = 128  # Updated to match the image's batch size\n",
    "    epochs = 10\n",
    "    validation_split = 0.1\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=validation_split, verbose=True, validation_data=(X_test, Y_test))\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, verbose=False)\n",
    "    print(f'Test loss: {score[0]:.4f}')\n",
    "    print(f'Test accuracy: {score[1]: .4f}')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tarea 2D:  Modelado de un clasificador mediante CNN para MNIST \n",
    "con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - accuracy: 0.8324 - loss: 0.5472 - val_accuracy: 0.5864 - val_loss: 1.3409\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9659 - loss: 0.1171 - val_accuracy: 0.9799 - val_loss: 0.0595\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9735 - loss: 0.0866 - val_accuracy: 0.9881 - val_loss: 0.0352\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9790 - loss: 0.0731 - val_accuracy: 0.9910 - val_loss: 0.0288\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.0603 - val_accuracy: 0.9915 - val_loss: 0.0265\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.0575 - val_accuracy: 0.9903 - val_loss: 0.0278\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9844 - loss: 0.0524 - val_accuracy: 0.9912 - val_loss: 0.0242\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - accuracy: 0.9852 - loss: 0.0478 - val_accuracy: 0.9927 - val_loss: 0.0225\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9862 - loss: 0.0462 - val_accuracy: 0.9909 - val_loss: 0.0258\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9878 - loss: 0.0391 - val_accuracy: 0.9918 - val_loss: 0.0263\n",
      "Test loss: 0.0263\n",
      "Test accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    # Load the MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Reshape the data to fit the model\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "    \n",
    "    # Normalize the data to the range [0, 1]\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    # One-hot encode the labels\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def build_cnn_model(num_conv_layers=2, num_dense_layers=1, conv_filters=[32, 64], dense_units=[128], input_shape=(28, 28, 1)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add convolutional layers\n",
    "    for i in range(num_conv_layers):\n",
    "        if i == 0:\n",
    "            # First layer needs to specify the input shape\n",
    "            model.add(Conv2D(conv_filters[i], kernel_size=(3, 3), input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv2D(conv_filters[i], kernel_size=(3, 3)))\n",
    "        \n",
    "        # Add batch normalization\n",
    "        model.add(BatchNormalization())\n",
    "        # Add a LeakyReLU activation function with negative_slope\n",
    "        model.add(LeakyReLU(negative_slope=0.1))\n",
    "        # Add a max pooling layer\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        # Add a dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "    # Flatten the layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layers\n",
    "    for units in dense_units:\n",
    "        model.add(Dense(units))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(negative_slope=0.1))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # Add the output layer with 10 units and softmax activation function\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss: {:.4f}'.format(score[0]))\n",
    "    print('Test accuracy: {:.4f}'.format(score[1]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess the data\n",
    "    (x_train, y_train), (x_test, y_test) = load_and_preprocess_data()\n",
    "    \n",
    "    # Build the CNN model\n",
    "    model = build_cnn_model(num_conv_layers=2, num_dense_layers=1, conv_filters=[32, 64], dense_units=[128])\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    train_and_evaluate_model(model, x_train, y_train, x_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIPrac2Python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
